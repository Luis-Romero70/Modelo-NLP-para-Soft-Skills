We’re looking for a Data Engineer. Headquartered in Los Angeles, California, the company applies the latest technology and best engineering practices to help businesses grow. We’re in the top 50 companies to watch in LA.
We’re a digital platform for total well-being. We help our community feel their best in body and mind through on-demand yoga, meditation, Pilates, and fitness classes with world-class teachers. Data Engineer plays an important role in our mission and vision to connect people through self care so that, together, we can heal ourselves and our planet.
Support the company’s data strategy and work with the Data Team implementing data pipelines, dashboards, models, and AI/ML projects as needed. This role will be responsible for enabling data-driven decisions across the company by sourcing accurate data, building scalable infrastructure, and delivering analytics with predictive modeling. Use various methods to transform raw data into useful data systems, ultimately supporting the team to implement methods to improve data reliability, quality, and relevance.

What’s in it for you?
Learn and evolve your skills using the latest and greatest technology tools in a rapidly growing company.
Learn from the best engineers. We constantly challenge the status quo and invent new ways of building a great product.
Flexible hours. Just join daily standups, sprint planning, and retrospective meetings. Other than that, you’re in control of your own schedule.
100% remote. Work anywhere, whether it is remotely in the comfort of your home, in a shared co-working space, in an RV on the beach, or while being a nomad in another country.
Work on challenging problems, innovate, impacting lots of people’s lives for the better while having fun doing it.
Required qualifications:
Upper-intermediate to fluent speaking and writing English. Able to have a real-time conversation.
5+ years of full-time hands-on Data Engineering experience.
4+ years of full-time hands-on SQL experience.
4+ years of full-time hands-on Python experience.
Experience designing, developing, and maintaining Extract, Transform, Load (ETL) pipelines, ensuring data quality and integrity throughout the ETL process.
Experience managing and maintaining data warehouse performance to meet organizational requirements.
Deep understanding of conversion, retention, and engagement metrics.
Experience with data visualization tools such as Tableau, MixPanel, Google Looker.
Knowledge of data engineering and data warehousing concepts, including RedShift, Redshift Spectrum, AWS Glue, AWS Lambda.
Excellent communication and presentation skills to convey technical concepts to non-technical stakeholders.
Ability to work collaboratively in cross-functional teams and lead projects from ideation to implementation.
Experience mentoring junior data engineers and guiding best practices in modeling and analysis.
Ability to communicate clearly, and proactively with the team.
Always strives to support colleagues through positive collaboration.
Nice to have:
PySpark experience.
Experience in user subscription data.
Bachelor’s or Master’s degree in Computer Science, Statistics, Mathematics, or a related field.
Experience in Data Science, Machine Learning, and Statistical Modeling.
SAS experience.
Knowledge and experience in utilizing advanced table formatting such as Delta, Hudi, or Iceberg.
Experience building ML Models for new Product Features & Fraud.
Experience with Open Source Data Visualization tools.
Experience with Databricks, Reverse ETL.
Bachelor’s degree in Computer Science or equivalent demonstrated ability.
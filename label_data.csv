file_number;language;text;soft_skills
01;es;Buscamos un Data Scientist altamente motivado con experiencia en análisis de datos y modelado predictivo. Deberás poseer habilidades blandas como comunicación efectiva y capacidad de trabajo en equipo.;['comunicación', 'trabajo en equipo', 'habilidades analíticas', 'proactividad']
02;es;"Como Data Scientist en nuestro equipo, participarás en la identificación de patrones y tendencias a partir de grandes conjuntos de datos. Se valora la capacidad de presentar resultados de manera clara y persuasiva.
";['comunicación']
03;es;"Estamos en busca de un Data Scientist apasionado por convertir datos en conocimiento. Las habilidades blandas, como la adaptabilidad y la resolución de problemas, son esenciales para tener éxito en este rol.
";['resolución de problemas', 'adaptabilidad', 'proactividad']
04;es;"Únete a nuestro equipo como Data Scientist y contribuye al desarrollo de modelos predictivos avanzados. Habilidades blandas, incluyendo la capacidad de colaborar en entornos multidisciplinarios, son fundamentales.

";['comunicación', 'trabajo en equipo']
05;es;"Estamos contratando un Data Scientist con habilidades excepcionales en análisis de datos y visualización. La capacidad de comunicar hallazgos de manera efectiva a partes interesadas no técnicas es esencial.


";['comunicación', 'habilidades analíticas']
06;es;"Buscamos un profesional de Data Science para liderar iniciativas analíticas. Se requiere una sólida ética de trabajo, así como habilidades blandas que faciliten la colaboración con equipos interdisciplinarios.


";['comunicación', 'trabajo en equipo']
07;es;"Únete a nuestro equipo dinámico como Data Scientist. Buscamos a alguien con habilidades analíticas avanzadas y la capacidad de trabajar de manera efectiva en un entorno ágil y colaborativo.


";['trabajo en equipo', 'gestión de proyectos']
08;es;"Estamos contratando un Data Scientist experimentado para aplicar técnicas estadísticas y de machine learning. Habilidades blandas como la resiliencia y la empatía son esenciales para el éxito en este rol.



";['habilidades interpersonales']
09;es;"Como Data Scientist, trabajarás en proyectos desafiantes y colaborarás estrechamente con equipos de ingeniería y negocio. Se espera que tengas habilidades blandas destacadas, incluyendo la capacidad de trabajar bajo presión.




";['adaptabilidad']
10;es;"Buscamos un Data Scientist con una sólida base en modelado estadístico y machine learning. La capacidad de comunicar resultados de manera efectiva y trabajar en equipo son atributos clave para este rol.





";['comunicación', 'trabajo en equipo']
11;en;"Join our innovative team as a Data Scientist and contribute to groundbreaking projects in machine learning and predictive analytics. Strong soft skills, including effective communication, are essential for success in this role.





";['communication', 'problem solving', 'creativity']
12;en;"Seeking a highly skilled Data Scientist with a passion for uncovering insights from data. Excellent teamwork and interpersonal skills are crucial for collaborating with cross-functional teams.






";['interpersonal skills', 'teamwork', 'analytical skills']
13;en;"We are hiring a Data Scientist to drive data-driven decision-making. Strong analytical abilities and soft skills such as adaptability and creativity are key attributes we value.







";['problem solving', 'creativity', 'adaptability']
14;en;"As a Data Scientist, you will play a key role in developing advanced analytics solutions. Effective problem-solving and communication skills, both written and verbal, are prerequisites for this position.







";['communication', 'problem solving']
15;en;"Are you a Data Scientist with expertise in statistical modeling? Join our team and bring your soft skills, including teamwork and a positive attitude, to contribute to our success.







";['teamwork']
16;en;"We're looking for an experienced Data Scientist who can apply machine learning techniques to complex datasets. Strong interpersonal skills and the ability to collaborate with diverse teams are essential.







";['communication', 'interpersonal skills', 'teamwork']
17;en;"Join us as a Data Scientist and apply your expertise in data analysis and modeling. Effective communication and the ability to distill complex concepts for non-technical stakeholders are highly valued.






";['communication', 'analytical skills']
18;en;"Seeking a Data Scientist with a track record of success in predictive modeling. Soft skills like effective time management and the ability to work autonomously in a fast-paced environment are crucial.







";['proactivity', 'time management', 'fast-paced environment']
19;en;"As a Data Scientist, you will be responsible for developing and deploying machine learning models. Excellent communication skills and the ability to collaborate across departments are key to excelling in this role.








";['communication', 'teamwork']
20;en;"We are hiring a skilled Data Scientist to drive data insights for strategic decision-making. Strong problem-solving abilities and soft skills such as empathy and adaptability are critical for this position.








";['interpersonal skills', 'adaptability']
21;es;"Unirse a nuestro equipo como Data Scientist y contribuir a proyectos innovadores en machine learning y análisis predictivo. Se valoran habilidades interpersonales sólidas y comunicación efectiva.







";['comunicación', 'habilidades interpersonales', 'creatividad']
22;es;"We are seeking a passionate Data Scientist para descubrir conocimientos a partir de datos. Excelentes habilidades de trabajo en equipo y personales son cruciales para colaborar con equipos multidisciplinarios.







";['comunicación', 'trabajo en equipo']
23;es;"Estamos contratando un Data Scientist altamente calificado para impulsar la toma de decisiones basada en datos. Se valoran habilidades analíticas sólidas y habilidades blandas como la adaptabilidad y la creatividad.






";['creatividad', 'adaptabilidad']
24;es;"Como Data Scientist, jugarás un papel clave en el desarrollo de soluciones de análisis avanzado. Habilidades efectivas de resolución de problemas y comunicación, tanto escrita como verbal, son requisitos previos para este puesto.





";['comunicación', 'resolución de problemas']
25;es;"Are you a Data Scientist with expertise in statistical modeling? Únete a nuestro equipo y aporta tus habilidades interpersonales, incluido el trabajo en equipo y una actitud positiva, para contribuir a nuestro éxito.





";['habilidades interpersonales', 'trabajo en equipo']
26;es;"We're looking for an experienced Data Scientist que pueda aplicar técnicas de machine learning a conjuntos de datos complejos. Habilidades interpersonales sólidas y la capacidad de colaborar con equipos diversos son esenciales.





";['habilidades interpersonales', 'trabajo en equipo']
27;es;"Join us as a Data Scientist y aplica tu experiencia en análisis y modelado de datos. Se valoran habilidades efectivas de comunicación y la capacidad de simplificar conceptos complejos para stakeholders no técnicos.





";['comunicación']
28;es;"Buscamos un Data Scientist con un historial de éxito en modelado predictivo. Habilidades blandas como una gestión efectiva del tiempo y la capacidad de trabajar de manera autónoma en un entorno rápido son cruciales.




";['gestión efectiva del tiempo']
29;es;"Como Data Scientist, serás responsable del desarrollo e implementación de modelos de machine learning. Habilidades excelentes de comunicación y la capacidad de colaborar entre departamentos son clave para sobresalir en este rol.




";['comunicación', 'trabajo en equipo']
30;es;"Estamos contratando un Data Scientist calificado para impulsar conocimientos de datos para la toma estratégica de decisiones. Fuertes habilidades de resolución de problemas y habilidades blandas como la empatía y la adaptabilidad son críticas para este puesto.




";['habilidades interpersonales', 'resolución de problemas', 'adaptabilidad']
31;es;"Estamos en busca de un QA Tester apasionado por garantizar la calidad de nuestro software. Si tienes habilidades analíticas, atención al detalle y una mentalidad proactiva, ¡únete a nuestro equipo!




";['atención al detalle', 'proactividad']
32;en;"We are hiring a QA Tester who is enthusiastic about ensuring the quality of our software. If you have analytical skills, attention to detail, and a proactive mindset, join our team!




";['problem solving', 'attention to detail', 'proactivity']
33;es;"Buscamos un Especialista en Inteligencia Artificial para liderar proyectos innovadores. Si tienes experiencia en aprendizaje profundo, procesamiento del lenguaje natural y resolución de problemas complejos, ¡queremos conocerte!




";['resolución de problemas', 'creatividad']
34;en;"We are seeking an Artificial Intelligence Specialist to lead innovative projects. If you have expertise in deep learning, natural language processing, and solving complex problems, we want to meet you!




";['creativity']
35;es;"Únete a nuestro equipo como Diseñador UX/UI y crea experiencias de usuario excepcionales. Buscamos a alguien creativo, orientado al detalle y apasionado por el diseño centrado en el usuario.




";['creatividad', 'atención al detalle', 'proactividad']
36;en;"Join our team as a UX/UI Designer and create exceptional user experiences. We are looking for someone creative, detail-oriented, and passionate about user-centered design.




";['creativity', 'attention to detail', 'proactivity']
37;es;"Estamos contratando a un Diseñador Gráfico con habilidades creativas y experiencia en software de diseño. Si puedes transformar ideas en imágenes impactantes, ¡queremos conocerte!



";['creatividad']
38;en;"We are hiring a Graphic Designer with creative skills and experience in design software. If you can transform ideas into stunning visuals, we want to meet you!



";['creativity']
39;es;"En nuestro equipo de QA, estamos en búsqueda de un Tester que comparta nuestra pasión por la calidad del software. Si te apasiona encontrar defectos y garantizar la mejor experiencia para el usuario, ¡te queremos en nuestro equipo!


";['atención al detalle']
40;en;"In our QA team, we are looking for a Tester who shares our passion for software quality. If you enjoy finding defects and ensuring the best user experience, we want you on our team!


";['attention to detail']
41;es;"Buscamos un Especialista en Inteligencia Artificial para liderar proyectos innovadores en nuestra empresa. Si tienes experiencia en modelos predictivos y aprendizaje automático, ¡únete a nosotros para dar forma al futuro!

";['creatividad']
42;en;"We are looking for an Artificial Intelligence Specialist to lead innovative projects in our company. If you have experience in predictive modeling and machine learning, join us to shape the future!

";['creativity']
43;es;"¿QUÉ DESAFÍOS TE ESPERAN?
Participar en el análisis, diseño y desarrollo de soluciones técnicas.

¿QUÉ VALORAMOS DE TU PERFIL?
Experiencia con Angular 14 y superiores.
Experiencia trabajando con Docker.
Conocimientos sólidos de GitFlow, GitHub, Gitlab, Copilot.
Experiencia trabajando con FireBase y FireStore HTML/CSS/Wordpress/JavaScript.
APIs REST (Postman, OpenAPI / Swagger).
Excelentes habilidades en resolución de problemas y análisis de índole técnico.

";['resolución de problemas']
44;en;"What we're looking for:

We are looking for a Senior Frontend engineer to join our engineering team, specifically our CMP Squad. Our main office is in Paris and we are a very distributed team with people working remotely in Europe and the Americas.


Responsibilities:

Leveraging your experience in building and maintaining complex frontend applications, you will drive the development of our user-facing web applications, primarily our Web SDK.
We are looking for someone who is eager to:
Collaborate with designers, product, and other developers to ship new features
Be in charge of the overall architecture of web applications
Ensure that we have the right tests and structure in place to make sure that we can move quickly without breaking everything
Share your knowledge of software development principles and best practices with the team
Keep learning new technologies and be on the look-out for new ideas that we should try out


Qualifications:

Solid knowledge of JavaScript and Typescript
Experience with modern JavaScript and Typescript tooling and libraries
Experience with front-end applications built in React and best practices and patterns
Quality-oriented mindset: testing, code reviews, code quality, etc.
A passion for simple, maintainable, and readable code that balances pragmatism and performance
Knowledgeable of accessibility concepts and developing WCAG-compliant features
Obsession with performance considerations and experience with optimizing metrics related to Google Core Web Vitals";['communication', 'teamwork', 'adaptability']
45;en;"Launchpad, a people-first technology company, is a leader in North America´s rapidly growing tech sector. Through two solutions, Launchpad supports its clients with digital transformation:

PaasportTM, our iPaaS solution, streamlines software integration and automates workflows. 
Nearshore Staff Augmentation, our managed IT staffing service, connects top IT talent across various geographical regions, bringing industry expertise to leading clients. 

Based in Vancouver, Canada, our operational footprint spans across North and South America, with a second headquarters in Santiago, Chile.

In 2023, our unwavering dedication to innovation garnered recognition as a Deloitte Technology Fast 50™ Program Company. Our clientele boasts industry leaders such as Walmart, GM, TIME Magazine, Salesforce, Tableau, Splunk, Bolt.com, Freedom House, and more.

At Launchpad, we genuinely care about our people as individuals. If you are looking for a team that values growth, drive, and passion for your craft, if you’re seeking a place to achieve your goals and dreams with fairness and integrity, then we’d love to hear from you.

Are you a skilled RPA developer eager to explore new opportunities? We want to introduce you to our RPA developer talent pool. While we may not have an immediate opening, we are building a selected pool of professionals for upcoming projects. At Launchpad, we value innovation and expertise. By being part of our Talent Pool, you're positioning yourself for exciting opportunities in the future.

Why join our Talent Pool?

Stay ahead: By becoming a part of our Talent Pool, you'll be first in line for consideration when a suitable role opens up. 
Showcase your expertise: Share your skills, projects, and experience with us, so we can match you with the right role. 

Responsibilities:

Collaborate with business analysts and stakeholders to understand and document business processes. 
Design, develop, and deploy robotic process automation solutions using RPA tools. 
Analyze and evaluate automation workflows to identify opportunities for improvement. 
Develop and maintain RPA scripts, workflows, and automation configurations. 
Test and debug automation solutions to ensure functionality and reliability. 
Provide technical support and troubleshoot issues related to RPA implementations. 
Collaborate with cross-functional teams to integrate RPA solutions with existing systems. 
Stay updated on RPA technologies, industry trends, and best practices. 
Document RPA processes, configurations, and troubleshooting steps. 

Qualifications:

Bachelor's degree in Computer Science, Information Technology, or a related field. 
Proven experience as an RPA Developer or in a similar role. 
Proficiency in RPA tools such as UiPath, Automation Anywhere, or Blue Prism. 
Strong programming skills in languages such as C#, Java, or Python. 
Solid understanding of business processes and workflow automation. 
Excellent problem-solving and analytical skills. 
Ability to work independently and collaboratively in a team. 
Strong communication and documentation skills. 

Preferred Skills:

Certification in RPA technologies. 
Experience with cognitive automation and machine learning integration. 
Familiarity with process mining tools. 
Knowledge of API integrations and web services. 
Previous experience with business process analysis and improvement. 
100% remote
People first culture
Excellent compensation in US Dollars
Hardware setup for working from home
Work with global teams and prominent brands based in North America, Europe, and Asia
Training allowances
Personal time off (PTO) for vacations, study leave, personal time, etc. 
...and more!

At Launchpad, we genuinely care about our people as individuals. If you are looking for a team that values growth, drive, and passion for your craft, if you’re seeking a place to achieve your goals and dreams with fairness and integrity, then you are the future of Launchpad. Launchpad is committed to fostering a diverse and representative workforce and an inclusive work environment where all employees are respected and treated equally.

Are you ready to elevate your career at Launchpad? We want to hear your story! Contact us today.
";['communication', 'teamwork', 'problem solving', 'creativity', 'proactivity']
46;en;"Launchpad, a people-first technology company, is a leader in North America´s rapidly growing tech sector. Through two solutions, Launchpad supports its clients with digital transformation:

PaasportTM, our iPaaS solution, streamlines software integration and automates workflows. 
Nearshore Staff Augmentation, our managed IT staffing service, connects top IT talent across various geographical regions, bringing industry expertise to leading clients. 

Based in Vancouver, Canada, our operational footprint spans across North and South America, with a second headquarters in Santiago, Chile.

In 2023, our unwavering dedication to innovation garnered recognition as a Deloitte Technology Fast 50™ Program Company. Our clientele boasts industry leaders such as Walmart, GM, TIME Magazine, Salesforce, Tableau, Splunk, Bolt.com, Freedom House, and more.

At Launchpad, we genuinely care about our people as individuals. If you are looking for a team that values growth, drive, and passion for your craft, if you’re seeking a place to achieve your goals and dreams with fairness and integrity, then we’d love to hear from you.

Are you a skilled Augmented Reality Developer eager to explore new opportunities? We want to introduce you to our Augmented Reality Developer talent pool. While we may not have an immediate opening, we are building a selected pool of developers for upcoming projects. At Launchpad, we value innovation and expertise. By being part of our Talent Pool, you're positioning yourself for exciting opportunities in the future.

Why join our Talent Pool?

Stay ahead: By becoming a part of our Talent Pool, you'll be first in line for consideration when a suitable role opens up. 
Showcase your expertise: Share your skills, projects, and experience with us, so we can match you with the right role. 

Responsibilities:

Collaborate with cross-functional teams to conceptualize and design augmented reality applications. 
Develop AR applications for various platforms, including mobile devices and AR glasses. 
Implement interactive and visually appealing AR experiences using AR development tools and frameworks. 
Integrate AR functionality with existing applications and systems. 
Collaborate with designers and 3D artists to incorporate virtual elements into the real world. 
Optimize AR applications for performance and user experience. 
Stay updated on emerging AR technologies and industry trends. 
Test and debug AR applications to ensure functionality and performance. 
Provide technical support and troubleshooting for AR applications. 

Qualifications:

Bachelor's degree in Computer Science, Software Engineering, or a related field. 
Proven experience as an Augmented Reality Developer or in a similar role. 
Proficiency in AR development tools and frameworks (e.g., Unity, ARKit, ARCore). 
Strong programming skills in languages such as C# or C++. 
Experience with 3D modeling and animation tools. 
Solid understanding of computer vision and tracking technologies. 
Excellent problem-solving and debugging skills. 
Ability to work independently and collaboratively in a team. 
Passion for exploring and implementing innovative AR solutions. 

Preferred Skills:

Experience with virtual reality (VR) development. 
Knowledge of AR cloud technologies. 
Familiarity with IoT integration in AR applications. 
Understanding of UX/UI design principles. 
Published AR applications in app stores. 

Why work for Launchpad?

100% remote
People first culture
Excellent compensation in US Dollars
Hardware setup for working from home
Work with global teams and prominent brands based in North America, Europe, and Asia
Training allowances
Personal time off (PTO) for vacations, study leave, personal time, etc. 
...and more!

At Launchpad, we genuinely care about our people as individuals. If you are looking for a team that values growth, drive, and passion for your craft, if you’re seeking a place to achieve your goals and dreams with fairness and integrity, then you are the future of Launchpad. Launchpad is committed to fostering a diverse and representative workforce and an inclusive work environment where all employees are respected and treated equally.

Are you ready to elevate your career at Launchpad? We want to hear your story! Contact us today.";['communication', 'teamwork', 'creativity', 'proactivity']
47;en;"Be part of a revolutionary change

We’re totally transforming our business, and building our future on smoke-free products with the power to improve the lives of a billion smokers worldwide.

With huge change, comes huge opportunity. So, wherever you join us, you’ll enjoy the freedom to dream up and deliver better, brighter solutions and the space to move your career forward in different directions.

Who we are looking for?


 An agile person able to learn on the fly within changing environment and growing department
 An action-oriented, fast learning problem solver with a university degree in Logistics or Finance
 A person with at least 1 – 2 years of relevant business experience in Master Data, Supply Chain, Procurement or Finance area
 A candidate with fluent English, with a strong attention to details and very good knowledge of Microsoft Office and Excel
 You should have solid understanding of Master Data Management and Finance implications. Knowledge and experience of using SAP MDG would be an asset.


'Your day to day':


 Be responsible for calculating, validating and consolidated maintenance of selling and purchasing conditions - - - Be responsible for material master extension process
 Ensure on time data completeness in SAP to enable sales of goods, and work with various resources to achieve it
 Ensure correctness and accuracy of various pricing models and calculation schemes used in PMI pricing process flows
 Identify, investigate, and correct master data quality issues
 Identify areas for improvement of processes where applicable
 Contact with different groups among PMI Company including SCE and Affiliates Management team
 Participate in projects and initiatives impacting finance, selling or purchasing processes


What we offer:

Our success depends on the men and women who come to work every single day with a sense of purpose and an appetite for progress. Join PMI and you too can:


 Seize the freedom to define your future and ours. We’ll empower you to take risks, experiment and explore.
 Be part of an inclusive, diverse culture, where everyone’s contribution is respected; collaborate with some of the world’s best people and feel like you belong.
 Pursue your ambitions and develop your skills with a global business – our staggering size and scale provides endless opportunities to progress.
 Take pride in delivering our promise to society: to improve the lives of a billion smokers.
";['communication', 'teamwork', 'project management', 'proactivity']
48;en;"Launchpad, a people-first technology company, is a leader in North America´s rapidly growing tech sector. Through two solutions, Launchpad supports its clients with digital transformation:

PaasportTM, our iPaaS solution, streamlines software integration and automates workflows. 
Nearshore Staff Augmentation, our managed IT staffing service, connects top IT talent across various geographical regions, bringing industry expertise to leading clients. 

Based in Vancouver, Canada, our operational footprint spans across North and South America, with a second headquarters in Santiago, Chile.

In 2023, our unwavering dedication to innovation garnered recognition as a Deloitte Technology Fast 50™ Program Company. Our clientele boasts industry leaders such as Walmart, GM, TIME Magazine, Salesforce, Tableau, Splunk, Bolt.com, Freedom House, and more.

At Launchpad, we genuinely care about our people as individuals. If you are looking for a team that values growth, drive, and passion for your craft, if you’re seeking a place to achieve your goals and dreams with fairness and integrity, then we’d love to hear from you.

Are you a skilled Augmented Reality Architect eager to explore new opportunities? We want to introduce you to our Augmented Reality Architect talent pool. While we may not have an immediate opening, we are building a selected pool of developers for upcoming projects. At Launchpad, we value innovation and expertise. By being part of our Talent Pool, you're positioning yourself for exciting opportunities in the future.

Why join our Talent Pool?

Stay ahead: By becoming a part of our Talent Pool, you'll be first in line for consideration when a suitable role opens up. 
Showcase your expertise: Share your skills, projects, and experience with us, so we can match you with the right role. 

Responsibilities:

Lead the design and architecture of augmented reality applications and experiences. 
Collaborate with cross-functional teams to define AR project requirements. 
Evaluate and recommend AR technologies, frameworks, and hardware. 
Design and implement AR solutions that align with project goals and user experience. 
Develop strategies for AR content creation, interaction, and integration. 
Optimize AR applications for performance and user engagement. 
Stay updated on emerging AR technologies, hardware, and software. 
Collaborate with developers and artists to integrate AR elements seamlessly. 
Provide technical leadership and mentorship to AR development teams. 
Participate in the planning and execution of AR projects. 

Qualifications:

Bachelor's or Master's degree in Computer Science, Information Technology, or a related field. 
Proven experience as an AR Architect or in a similar senior AR role. 
Extensive expertise in AR design, development, and implementation. 
In-depth knowledge of AR hardware, sensors, and tracking technologies. 
Proficiency in AR development tools and frameworks (e.g., Unity, ARKit, ARCore). 
Strong programming skills in languages such as C# or C++. 
Experience with 3D modeling, animation, and rendering. 
Excellent problem-solving and analytical skills. 
Ability to work independently and collaboratively in a team. 

Preferred Skills:

Certification in AR development or related field. 
Experience with virtual reality (VR) development. 
Familiarity with AR cloud technologies and services. 
Knowledge of computer vision and image recognition. 
Previous experience with AR in gaming, retail, or industrial applications. 

Why work for Launchpad?

100% remote
People first culture
Excellent compensation in US Dollars
Hardware setup for working from home
Work with global teams and prominent brands based in North America, Europe, and Asia
Training allowances
Personal time off (PTO) for vacations, study leave, personal time, etc. 
...and more!

At Launchpad, we genuinely care about our people as individuals. If you are looking for a team that values growth, drive, and passion for your craft, if you’re seeking a place to achieve your goals and dreams with fairness and integrity, then you are the future of Launchpad. Launchpad is committed to fostering a diverse and representative workforce and an inclusive work environment where all employees are respected and treated equally.

Are you ready to elevate your career at Launchpad? We want to hear your story! Contact us today.";['communication', 'teamwork', 'problem solving', 'creativity', 'leadership', 'proactivity', 'mentoring/teaching']
49;es;"Description

Amazon Web Services (AWS) ofrece un conjunto completo de servicios en la nube que permiten que todas las empresas, desde startups hasta empresas, ejecuten prácticamente todo en la nube, incluidas aplicaciones móviles, análisis de big data, plataformas de IA/ML e infraestructuras sin servidor y microservicios/infraestructuras sin servidor. Las startups, que ahora nacen principalmente en la nube, representan un subconjunto de clientes de importancia crítica y creciente para AWS. Las startups tienen necesidades, prioridades y trayectorias de crecimiento únicas que las distinguen de los negocios tradicionales y requieren diferentes estrategias de participación y movimientos de ventas de los vendedores para adquirirlos, crecer y retenerlos de manera efectiva a largo plazo en la plataforma de AWS.

A medida que AWS continúa creciendo rápidamente, buscamos un Gerente de Cuentas Startup de LATAM para ayudar a impulsar el crecimiento de startups de alto potencial temprano, medio y tardío. Sus responsabilidades incluirán impulsar los ingresos y la adopción de los usuarios, las migraciones y garantizar que las nuevas empresas seleccionen AWS como su principal proveedor de nube. Se alineará estrechamente con sus contrapartes en desarrollo de negocios, marketing, arquitectura de soluciones y equipos de socios para liderar la ejecución de estrategias coordinadas de salida al mercado y juegos de ventas. También trabajará en estrecha colaboración con los equipos de desarrollo de negocios que están impulsando el soporte estratégico, la coprogramación global y la participación de la cartera para ayudar a impulsar la adquisición de clientes de primer nivel y acelerar los ciclos de vendedores en el campo.

Estarás en el corazón de las últimas tendencias como inteligencia artificial (IA), aprendizaje automático (ML), serverless e IoT. Sus clientes aprovechan las tecnologías de vanguardia en AWS para innovar y convertirse en los próximos disruptores, como AirBnB, Slack, DoorDash y Lyft actuales. Te apasionan las startups, un emprendedor con un fuerte espíritu emprendedor que está preparado para trabajar en un entorno acelerado, a menudo ambiguo, ejecutar en contra de objetivos ambiciosos y abrazar consistentemente la Cultura Amazónica.

Key job responsibilities

 Asegurar el éxito del cliente con nuevas empresas en etapas tempranas, medias y tardías
 Impulsar los ingresos y la cuota de mercado en un territorio definido o vertical de la industria
 Acelere la adopción del cliente a través de contratos de ventas bien desarrollados y una estrategia GTM exitosa
 Cumplir o superar los objetivos trimestrales de ingresos y metas.
 Desarrollar y ejecutar contra un plan integral de cuenta/territorio.
 Cree y articule propuestas de valor convincentes en torno a los servicios de AWS.
 Acelere la adopción de los clientes mediante la participación de fundadores, CxO, Junta Directiva e influencers de VC
 Trabajar con los asociados de negocios para ampliar el alcance e impulsar la adopción.
 Desarrollar relaciones estratégicas a largo plazo con cuentas clave.
 Asegurar la satisfacción del cliente.
 Espere un viaje moderado.

We are open to hiring candidates to work out of one of the following locations:

Buenos Aires, ARG

Basic Qualifications

 7+ years of direct sales or business development in software, cloud or SaaS markets selling to C-level executives experience
 10+ years of business development, partner development, sales or alliances management experience

Preferred Qualifications

 5+ years of building profitable partner ecosystems experience
 Experience developing detailed go to market plans


Company - Amazon Web Services Argentina S.R.L.
";['comunicación', 'trabajo en equipo']
50;es;"About The Position

Estamos enfocados en crear soluciones que brinden los mejores servicios financieros con una experiencia WOW para nuestros clientes. En todo momento investigamos y nos capacitamos sobre las nuevas tendencias tecnologías que hay en el mundo para adaptarlas a nuestra Transformación Digital. Trabajamos de la mano con el negocio para realizar entregas de productos y servicios de calidad.

Responsabilidades:

Diseñar, desarrollar, proponer arquitecturas a nivel de infraestructura cloud. 
Mejorar, proponer soluciones de automatización a nivel de tubería pipeline. 
Aprovisionar recursos a través de Infrastructure As Code IAC. 
Evaluar, diseñar, implementar y evolucionar las plataformas devops. 
Crear artefactos, librerías de código, plantillas que puedan ser utilizados en la construcción de automatizaciones CI/CD. 
Proponer planes de acción frente a riesgos en la plataforma y/o herramientas. 
Asegurar la inclusión de componentes de costos en el análisis de alternativas de solución en la evaluación de herramientas. 
Atender en el soporte de pipelines de Testing y estabilidad de la plataforma. 
Asegurar la adopción de componentes desarrollados. 
Asegurar implementaciones alineadas a métricas de valor. 
Garantizar integración, despliegue y entrega continua mediante flujos automatizados. 

Requirements

Bachiller en la carrera de Ingeniería de Sistemas, computación, informática, software y electrónica o carreras aﬁnes. 
3+ años de experiencia en el rol. 
Conocimiento sobre scripts con Groovy. 
Sólido dominio de Cloud AWS. 
Conocimiento sobre Linux (shell scripting). 
Conocimiento en Ansible / Playbooks. 
Conocimiento en lenguajes de programación java, react native, ios, android y python. 
Conocimiento de herramientas Git/BitBucket, Jenkins, Jira, Artifactory, Sonarqube, SonarCloud Snyk, MS AppCenter, Confluence (o similares). 
Sólidos conocimiento sobre contenedores (Docker) y orquestación de contenedor AWS EKS. 
Conocimiento sobre base de datos relacionales y no relacionales rds, aurora, dynamo, MySQL, SQL Server, MongoDB). 
Sólidos conocimiento sobre DevOps, CI/CD pipelines Github Actions, aws code pipeline y aws code build. 
Sólidos conocimiento en tuberías e infraestructura como código PAC / IAC. 
Sólidos conocimiento de Terraform / Terraform Cloud. 
Distribución de aplicaciones móviles en ms appcenter. 
Conocimiento de Frameworks de agilidad (Scrum, Kanban, etc.). 
Conocimiento en automatización de pruebas unitarias. 
Uso de framework para Testing Continuo (Deseable). 
Previa experiencia en entornos cloud donde se trabajen en la automatización de modelos ML usando Databricks (deseable). 
Conocimiento del flujo Data Ops (deseable). 

Benefits

Vacaciones / Flexibilidad de Trabajo

22 dias de vacaciones
Trabajo Remoto: Remoto

Salud / Seguros

Seguro de Salud

Beneficios salariales

Esquema 100% vía nómina
Bono desempeño
30 días de aguinaldo

Beneficios Extras + Educación

Plan de capacitación
Plan de carrera
Certificaciones en plataformas
";['adaptabilidad', 'gestión de proyectos']
51;es;"¡Sumate a Huumit!



En Huumit Recruitment estamos buscando un Analista programador Sr/Ssr para ERP interno con el objetivo de unirse a este fantástico equipo de trabajo. 👥💼


Estamos en búsqueda de un Programador Senior/Ssr altamente calificado y con sólida experiencia para unirse a nuestro equipo de desarrollo va a ser parte del proceso de desarrollo de nuevas funcionalidades y mantenimiento de los sistemas.


A su vez participará activamente de los proyectos del área tanto en la parte de análisis, desarrollo, revisiones como de implementaciones.


Conocimientos técnicos requeridos



Experiencia como programador Sr en python o typescript 3años (Excluyente).
Experiencia mínima de 3 años en base de datos SQL (Excluyente).
Experiencia con Azure (deseable).
Experiencia desarrollando FrontEnd (deseable) / Backend (Excluyente).
Estudios avanzados o culminados en carreras de sistemas o afines | Deseable.


Conocimientos no técnicos 



Excelentes habilidades de comunicación verbal y escrita, en español e inglés.
Habilidad para colaborar y trabajar en equipo con otros departamentos.
Habilidad para tomar la iniciativa y trabajar de manera autónoma.
Habilidad para aprender rápidamente y adaptarse a los cambios.


Es un plus para nosotros:



- Experiencia deseable en un puesto similar de más de 3 años.
- Buena predisposición para el trabajo en equipo.


Nos preocupamos sinceramente por tu salud, bienestar y crecimiento profesional. ¡También cuidamos tus ingresos! ¡Nos aseguramos de mantenerlos actualizados! 💪💼💰


Estas son nuestras propuestas de valor para ti:



Bonos por rendimiento (hasta 2 salarios) 💰💰
Cobertura de seguro médico privado 🏥💊
Premios en la plataforma CuponStar con múltiples beneficios 🎁🛍️
Capacitación en el idioma inglés incluida 🇺🇸📚
Trabajo híbrido (presencial y desde casa) 🏠👨‍💼👩‍💼


Horario laboral:



Híbrido presencial/home office de lunes a viernes (3 días presenciales, 2 días desde casa).


Ubicación: Vicente López 📍🗺️



Si crees que cumples con los requisitos, no dudes en postularte. ¡Queremos saber de vos! ¡Te estamos esperando! 🙌🏼💼👨‍💻
";['comunicación', 'trabajo en equipo', 'adaptabilidad']
52;en;"At Inmind Software we are blockchain & mobile software development experts. Our main goal is to deliver quality solutions for our customers' needs. We work with US clients in end-to-end projects and staff augmentation.
We are writing blockchain history together with leading companies in the industry, are you joining us?
In this opportunity, we are looking for an AWS data engineer with relational database experience.


Project:
This is a major AI project and we are looking for someone who possesses data transformation skills and work with existing datasets.
The IA project uncovers hidden growth opportunities by transforming fragmented data into actionable intelligence, driving efficient decision making and profitability across the entire business ecosystem.
The project is very challenging, so we are looking for someone who is highly motivated and with solid knowledge.


Daily tasks:
Analyze and organize raw data 
Build data systems and pipelines
Evaluate business needs and objectives
Interpret trends and patterns
Conduct complex data analysis and report on results 
Prepare data for prescriptive and predictive modeling
Build algorithms and prototypes
Combine raw information from different sources
Explore ways to enhance data quality and reliability
Identify opportunities for data acquisition
Develop analytical tools and programs
Collaborate with data scientists and architects on several projects
 Requirements (Must)
Previous experience as a data engineer or in a similar role
Technical expertise with data models, data mining, and segmentation techniques
Hands-on experience with SQL database design
Experience in Python 
Different services and concepts of AWS data engineering (AWS RDS - Postgre SQL)
Serverless data using S3, Glue and Athena
Sftp server
Great numerical and analytical skills
Full time availability


Plus
AWS Certified Data Engineer Associate 
English level: B2 or higher 


Benefits
Payment in USD by Let´s Deel
Remote
15 business days of vacation per year
Local bank holidays";['communication', 'teamwork', 'problem solving', 'analytical skills', 'proactivity']
53;es;"ÚNETE A NUESTRO EQUIPO! Experto en Chatbots
Buscamos un experto en chatbots para incorporarse a nuestro equipo. 

Requisitos: 

Experiencia comprobada en diseño e implementación de chatbots.
Conocimiento sólido de la plataforma BOTPRESS.
Capacidad para crear flujos de conversación intuitivos y efectivos.
Habilidad para analizar datos y mejorar continuamente el rendimiento del chatbot. 



Envía tu CV y una breve carta de presentación a [info@spectrumagencylab.com] o contactanos con un mensaje por aqui!
";['comunicación', 'habilidades analíticas']
54;en;"About The Role

The Team:You will report to the Head of Infrastructure, Latin America, and be working closely with a number of highly experienced industry specialists, not only in Latin America but globally.

The Global Infrastructure Practice was established by S&P Global Ratings to expand our ratings franchise in an area of strong growth and to leverage our significant global infrastructure expertise across the full range of infrastructure and energy asset classes. Analytical team members reside in 16 locations globally and work on a diverse range of transactions applying different ratings criteria.

As important as the pure professional background is the personal and cultural fit. S&P Global's culture can be described as highly integrated & collegiate, as a firm we work supporting each other to deliver the best solutions to clients.

Responsibilities And Impact

At S&P Global Ratings, your analytical opinion truly matters and each person who works here has an essential role in our reputation of integrity, transparency, and ratings excellence. S&P Global Ratings plays a vital role in bringing transparency and comparability to the financial markets and helps investors and others measure and manage credit risk. By supporting capital markets, S&P Global Ratings helps people grow businesses, cities and states to build highways and hospitals, and manufacturers to build factories and create jobs.

The successful applicant will have the opportunity to further expand analytical excellence on an ongoing basis as we aim to encompass achievement within a working environment that is rewarding, stimulating and where there is a constant focus on building skills and competencies through learning.

With the mentorship of senior analysts, you will work closely with the sector team on its ongoing surveillance of a portfolio of rated issuers. You will perform basic fundamental credit analysis, forecasting, and industry analysis. You are likely to be considered for providing input to financial models and written analysis used for reviews and external publications.

This team environment stimulates continuous innovation and highest customer service standards.

What We're Looking For

Basic Required Qualifications:

Bachelor degree holder of Business, Economics, Finance, Engineering, Mathematics, or a related subject.

Analytical skills with an understanding of financial statement analysis and accounting concepts.

Ability to quickly absorb, analyze, and act upon information, while demonstrating strong proficiency with figures

Aptitude for expanding, learning, and passion for contributing.

Highly organized with the ability to multitask and work under time pressure.

StrongExcel/Word/PowerPointand database application skills.

Additional Preferred Qualifications

Strong proficiency with VBA, financial models and financial data.

Knowledge of programming languages (e.g. C++, MATLAB, Python, R or VBA)

Prior experience with data analysis. Knowledge of SQL and experience in databases such as Oracle, Sybase, or Access would be helpful

Return To Work

Have you taken time out for caring responsibilities and are now looking to return to work? As part of our Return to Work initiative, Restart, we are encouraging enthusiastic and talented returners to apply, and will actively support your return to the workplace.

What's In It For You

Infrastructure finance is one of the fastest growing sectors of the capital markets and is a key funding source and growth driver for many areas of the economy. If you are interested in helping to facilitate this growth while challenging yourself in a fast-paced environment, this is the right position for you. It offers the opportunity to work in a collegial culture with great potential for professional development and career growth. To succeed, you must be comfortable with quantitative analysis and have a knack for problem solving. In addition, this role provides a great opportunity to be exposed to a range of markets and asset types; it encompasses compelling analytical expertise and effective management skills.

In the position, you will be working as part of the Global Infrastructure Ratings group at S&P Global Ratings. With the guidance of a senior analyst, a qualified Associate typically maintains direct analytical responsibility for a portfolio of rated issuers within the transportation, energy, power, renewables and utilities asset classes.
";['problem solving', 'creativity', 'leadership', 'analytical skills', 'customer service', 'fast-paced environment', 'mentoring/teaching']
55;en;"The Position:

We're looking to hire an Artificial Intelligence/Machine Learning Engineer to join our team. You'll work with our incredible clients in one of two ways:

Team Augmentation: You will integrate yourself directly into our client's team and work alongside their existing designers and engineers on a daily basis.
Design & Build: You will work on a FullStack product team to build and deliver a product to our clients.

What We're Looking For:

4+ years of professional software development experience.
3+ years of professional experience in designing and implementing machine learning algorithms.
Meaningful experience in programming languages such as Python, R, or Java.
Proficiency in working with machine learning frameworks such as TensorFlow or PyTorch.
Proficiency in working with data analysis and visualization tools such as Pandas, NumPy, or Matplotlib.
Advanced English is required.
Successful completion of a four-year college degree is required.
Ability to work through new and difficult issues and contribute to libraries as needed.
Ability to create and maintain continuous integration and delivery of applications.
Forensic attention to detail.
A positive mindset and a can-do attitude.
Experience working on Agile / Scrum teams.
Meaningful experience working on large, complex systems.
Ability to take extreme ownership over your work. Every day is a challenge to ensure you are performing to the expectations you and your team have agreed upon.
Ability to identify with the goals of FullStack's clients, and dedicate yourself to delivering on the commitments you and your team make to them.
Ability to consistently work 40 hours per week.";['attention to detail', 'analytical skills', 'project management']
56;en;"Concord isn't your typical consulting firm; we are an execution company with a passion for making things happen. Our mission is to help clients enhance customer experiences, optimize operations, and revolutionize their product offerings through seamless integration, optimization, and activation of technology and data.


We are seeking a highly skilled and experienced Machine Learning/AI Engineer to join our dynamic team. Our portfolio offers software tools coupled with content and services that customers need to make decisions with confidence.


Responsibilities

• Develop predictive models using supervised and unsupervised machine learning/deep learning
• Build models for legal predictive analytics, natural language understanding, conversational AI, robotic accounting, forecasting and anomaly detection
• Provide expertise in data wrangling, exploratory data analysis and feature engineering with large data sets
• Support the development of proofs of concept to demonstrate the application of AI/ML capabilities in solving customer problems in collaboration with product and other development teams
• Collaborate effectively with other teams across the organization
• A self-starter who can align the technology solution with a business goal


Qualifications

3+ years’ experience in supporting the development of production-ready solutions leveraging AI technologies: NLP, Deep Learning, Machine Learning
Strong hands-on expertise in Python and open source libraries/frameworks/tools such as NumPy, SciPy, scikit-learn, pandas, matplotlib, spaCy, NLTK, jupyter, anaconda, transformers, etc.
Experience with deep learning frameworks such as TensorFlow, Keras, PyTorch
Experience in applying deep learning to NLP
Experience with designing, building, and optimizing data and model training pipelines
Experience with cloud-based platforms (AWS or Azure) for solution delivery
Experience working with agile and Software Development Lifecycle tools (e.g. JIRA, Confluence, Git) and Test-Driven Development (TDD)
Undergraduate or Graduate degree (MS or PhD) in Computer Science, Engineering, Mathematics or equivalent, specializing in machine learning or a related field
Advanced English skills (B2 or higher)


Nice to have

Experience in SageMaker or Azure ML Studio a plus
Computer vision modeling a plus
Experience in the healthcare industry is a big plus


Job specifications

Contract type: contractor (6 to 12 months)
Location: Latin America (remote)
Timezone: US timezone
";['communication', 'teamwork', 'problem solving', 'analytical skills', 'project management']
57;en;"Data Engineer/Machine Learning Engineer 



Position Summary:



Our partner is looking for a saavy Data Engineer/Machine Learning Engineer to join a cutting-edge development team and develop top of the industry fintech applications partnering with quantum teams and Data Science teams! In this role you play a crucial role in designing, building and maintaining data pipelines that enable efficient data processing, storage, and analysis. You will be a part of a team that’s building innovative analytical tools and frameworks to exploit advantages in the latest fintech developments in cloud computing. Finally, you will be a crucial part in shaping future highly functional applications to deliver successful high quality, and sustainability of solutions.


Experience and Education:



BS in Computer Engineering or Computer Science, Statistics, Informatics or related experience/field
5+ years of experience with data management, data management tools and data quality
Strong understanding of machine learning concepts, algorithms, and deep learning architectures
Experience managing data streams with varied files format such as EDI, XML, Flat Files, others
Familiar with stream-processing systems: Apache Kafka, Spark-Streaming, others


Technology Skills and Strengths:



Kafka
Airflow
Spark
Python
AWS
AWS services (S3, AWS Lambda, AWS Glue, others)
Data warehousing
Data pipelines
Data architecture
Data management
Data security
ETL processes
Machine Learning operations (MLOps)
ML model evaluation and optimization
Metadata dependency
Workload management
SQL and NoSQL DB (such us NumPy, Pandas, MongoDB, others)
SQL (development, implementation and optimization)
Automation (Terraform, ARM Template)
LifeCycle Data Development
API (development and integration)
Distributed Data Processing
User stories
Databricks (a plus)
Kubernetes (a plus)


Primary Job Responsibilities:



Create and maintain an optimal data pipeline architecture to move, transform, and cleanse datafrom various sources into the correct data storage or processing systems
Design, develop and implement data packages for data warehousing or applications
Integrate data from various sources, both structured and unstructured, including databases, APIs, logs, and external datasets
Design, develop, and fine-tune machine learning models, including supervised, unsupervised, and deep learning models
Collect, clean, and preprocess data for model training, ensuring data quality and integrity
Deploy machine learning models into production environments, ensuring scalability and reliability.
Work with a team of developers with deep experience in data, distributed microservices, and full stack systems
Work with data management, data access (big data, data marts, etc.), programming, and data modeling; and familiar with analytic algorithms and applications
Provide technical support and problem resolution for related data service teams
Architect, deploy and maintain data models and schema to support analytics and reporting requirements
Develop and test scripts and exception handling processes based upon design
Create and maintain technical documentation to support the business application and data related processes
Troubleshoot to resolve operational and/or system problems";['communication', 'problem solving', 'creativity']
58;en;"Job Description

We have an exciting and rewarding opportunity for you to take your software engineering career to the next level.

As a Software Engineer III at JPMorgan Chase within the Infrastructure Platforms Team, you serve as a seasoned member of an agile team to design and deliver trusted market-leading technology products in a secure, stable, and scalable way. You are responsible for carrying out critical technology solutions across multiple technical areas within various business functions in support of the firm’s business objectives.

Job Responsibilities

Builds relationships with internal teams and clients and is passionate about unlocking value using AI and Machine learning
Demonstrates intellectual curiosity for solving difficult problems
Is a self-starter with technical knowledge and a hands on approach to using our data assets both efficiently and effectively
Develop approaches for understanding each individual client and their behavior to deliver highly impactful ML models
Develop, plan and execute analytical projects as an individual contributor and in teams.
Executes software solutions, design, development, and technical troubleshooting with ability to think beyond routine or conventional approaches to build solutions or break down technical problems
Creates secure and high-quality production code and maintains algorithms that run synchronously with appropriate systems

Required Qualifications, Capabilities, And Skills

Formal training or certification on data mining, quantitative research techniques, theories, principles, and practices and 3+ years applied experience.
Experience in: SQL; Python; AWS, GCP or Azure
Working with relational and non-relational databases; ML techniques including: regression, classification, time series, clustering, deep learning, hypothesis testing, cross validation, feature selection and feature extraction; NLP techniques including: topic modeling, entity extraction, summarization, and sentiment analysis;
Working with machine learning and natural language processing libraries such as: scikit-learn, tensor flow, pandas, nltk,; and Building data pipelines and deploying ML models and data visualization techniques.
Analytical thought leader - You can define the analytical agenda for projects, frame ambiguous business questions into analytical plans (e.g., assess data needs, source files, prepare data, create new features, evaluate quality, etc.), and execute.
Leadership - Primary focus of building something of significance. Willingness to roll up sleeves and do whatever it takes to achieve the goals.
Experience in developing, debugging, and maintaining code in a large corporate environment with one or more modern programming languages and database querying languages.

Preferred Qualifications, Capabilities, And Skills

Fluent in English
";['problem solving', 'leadership', 'project management', 'proactivity']
59;en;"Lean Tech is a fast-growing company located in Medellín, Colombia. We currently have one of the most prominent networks within the entertainment, financial, and logistics industries. Our corporate projections represent hundreds of opportunities for our professionals to grow and boost their careers. Working with us means collaborating with large engineering teams across Latin America and the United States.

We are currently looking for an experienced, dynamic, and highly motivated Machine Learning Engineer with a mix of strong technical expertise, engineering best practices, business engagement, hands-on architecture, project delivery, and cross-team collaboration. In addition, the candidate ought to have a passion for inspiring and mentoring junior engineers with varying levels of experience.
In particular, as a Python engineer in the Data Science team, you should possess an in-depth knowledge of object-relational mapping, experience with server-side logic, and knowledge of Python programming/scripting. You should have a good understanding of machine learning models and data science concepts. You also will be responsible for writing and testing scalable code, developing back-end components, and integrating user-facing elements in collaboration with other developers.
If you understand how to balance speed, long-term scalability, and performance, want to contribute ideas, and be part of a small team building a lot of things from scratch, this may be the opportunity for you.⚡ What you'll do
Build services that are part of our proprietary decision engine—the core of Company's product

Develop statistical machine learning models and data pipelines to serve Company's decision engine

Collaborate with the development team to design, develop, and maintain high-quality software solutions in Python

Write clean, efficient, and maintainable code, following best practices and coding standards

Work on database design and interact with relational databases using ORMs, such as SQLAlchemy and Django

Understand, analyze, and implement business needs, feature modification requests and conversion into software components

Implement and maintain unit tests using frameworks like Unittest, pytest, and Behave to ensure code reliability

Write technical documentation, lead code reviews and pair programming sessions

Be a technical leader within the team you work with and within Company in general

Engage in discussions to provide insights into business, and technical decisions and project updates

🎯 What we're looking for
6+ years of experience as a Python Developer

English Level Required B2+
Experience using various Python libraries, like Pandas, SciPy, and tools, such as Jupyter

Experience in developing AI/ML and data science modules

Strong understanding of relational databases and experience with ORMs (SQLAlchemy and Django)

Proficiency in unit testing frameworks such as Unittest, pytest, and Behave

Proficient understanding of code versioning tools such as GitHub

Excellent problem-solving and critical-thinking skills

A responsible and dedicated individual with a keen attention to detail

Strong communication and collaboration skills

Bachelor's degree in Computer Science, Computer Engineering, or related field

👍🏼 Nice to have
Experience working with Docker

Familiarity with AWS services, like ECS, EC2, RDS, SQS, S3, etc., and experience using boto

Experience in developing data engineering pipelines & ETL jobs

Preference for candidates with startup experience and a diverse range of roles in their career

🤗 Who you are
Excellent verbal communication skills

Strong attention to detail

Have an extreme ownership mindset

Being a team player

Comfortable with working unsupervised";['communication', 'teamwork', 'attention to detail', 'leadership', 'proactivity', 'mentoring/teaching']
60;en;"Dive into a world where code meets creativity and each line you write has the potential to spark digital life into the most advanced AIs. We're not just a company, we're a global tech phenomenon, piecing together the future of engrossing chatbots straight out of science fiction. We're on the hunt for a Python Developer — a sharp coder with a taste for agility, scalability, and all things AI. If you’re a modern-day tech artisan eager to embark on projects peppered with AI, ML, and collaborative innovation, you've found your arena.


Your Adventure Awaits:



Craft high-caliber, resilient code that adapts like AI and scales like cloud infrastructure.
Engage in rigorous code reviews keeping an eye out for the pristine standard of clean and efficient codebases.
Deploy cutting-edge Python libraries to deconstruct and streamline complex challenges with grace.
Be the guardian of your code, ensuring it's not just functional but is a beacon of industry best practices for data-driven AI development.


Your Toolkit and Talents:



Proudly holding a tech decree, supplemented by continuous skill upgrades in the tech sphere.
With 3+ years as a software sage, Python is your staff of power with which you weave backend magic.
You've got fine-tuned expertise in Python, firing up data models, machine learning wizardry, and seamless API concoctions.
Adept in SQL with the QA acumen that places you at the heart of the DevSecOps revolution.
Familiarity with CI/CD, unit testing, and a history of conquered bugs will set you apart as a candidate of legend.
You thrive on solving algorithmic puzzles, transforming towering data sets into digestible insights.
If cloud platforms and container orchestration sing your song, consider us already charmed.
Your software development achievements aren't just noted; they echo in the valleys of tech lore.
You're so well-versed in English, you're unofficially the Rosetta Stone between geeks and mortals.


Unique Perks and Opportunities:



Collaborate with illustrious researchers and innovators from every corner of the globe, building a network that’s as expansive as your ambitions.
This is more than a job; it’s a digital nomad's dream with full remote flexibility. Work where you thrive.
Enjoy a competitive salary paid in USD, ensuring you benefit from a global standard.
Work on breakthrough projects that bend the boundaries of tech, consistently pushing you to the vanguard of industry innovation.
Rise with Us: Answer the call to invent the intelligence that will define tomorrow’s conversational AI. Let's turn what if into what is together! 🚀
";['communication', 'teamwork', 'creativity', 'adaptability']
61;en;"Python Developer Wanted: Help Us Engineer the Conversational Bots of the Future!



Are you intrigued by the potential of artificial intelligence to unlock new ways we interact with technology? We’re a cutting-edge company on a mission to develop intelligent chatbots that aren't just innovative but are a leap forward in how we experience learning and entertainment through conversation. We're scouting for a talented Python Developer who thrives in an inventive and fast-evolving landscape, someone ready to leave their mark on the AI world.


The Role Awaits:



Develop durable, clear-cut code that will be a backbone for our AI-driven products.
Take part in detailed code reviews ensuring we uphold the high bar for quality and functionality.
Leverage Python to devise solutions to intricate challenges, showcasing your coding finesse.
Produce code that’s not just functional but is carefully documented and constructed with future expansion in focus.


Your Credentials:



Completed a Bachelor's or Master's degree in Engineering or Computer Science, or demonstrate equivalent professional experience.
Have a minimum of 3 years of shaping software with a focus on Python development.
Proficient in Python with expertise in its application to data science and machine learning initiatives.
Adept in SQL and have an understanding of the essentials of QA.
Bonus points for hands-on experience with software testing strategies and frameworks.
Known for your aptitude in problem-solving, particularly in crafting algorithms.
Background in data science or data engineering is massively favorable.
A proven track record of building sleek, operable software applications.
The fluent, articulate communicator in English, both verbal and written.


Why You'll Love Working With Us:



Engage and learn from top-tier researchers and developers from every part of the world, all from the comfort of your home.
Revel in the freedom of remote work — find productivity in your personal haven.
Receive a competitive salary that matches global standards, with the assurance of US dollars.
Dive into boundary-pushing projects that will routinely challenge and excite you, keeping you at the cutting edge of tech advancements.
Join Our Journey: If you’re driven to shape the way we interact with machines and eager to contribute to the next wave of AI advancements, we're waiting for you.";['creativity']
62;en;"Who we are?

Clip is changing the way payments work in Mexico! We are empowering people to exchange value directly from a mobile device. Clip enables anyone to accept card payments, at any time, and anywhere by turning your smartphone or tablet into a card terminal. We're a well-funded quickly growing FinTech startup. We are the leaders in our market and are accelerating to extend our lead and move into new markets.

The Role:

We are looking for a Data Engineer to be part of this amazing and fast – growing fintech and will be part of the team responsible for all of the data in the company used to support and implement Clip's mission. This Data Engineer work will be focused closely with product managers within the Product & Technology department as well as other leaders throughout the company to turn data into critical information and knowledge, he/she needs to be a creative thinker with a strong desire to learn and improve. A successful Data Engineer at Clip would propose innovative ways to look at problems by using data manipulation and engineering techniques, while proving that their projects bring value to the company, and they will directly impact business and product decisions for the future of Clip. This candidate must have strong written and verbal communications skills in both English and Spanish and be willing to continue learning and loving technology.

What will I do?

Work as part of a team developing in Python using Agile development methods.
Contribute to team and organizational improvements in process and infrastructure.
Work in the Data team and with the Architecture and DevOps teams to design and build efficient and fault tolerant data pipelines.
Create and populate data lakes and a data warehouse to facilitate data analysis and data science projects. 
Effectively use tools and ingenuity to identify and fix defects before they become a problem.
Invent new things and create world-changing software

Ideal Candidate:

Skills and experience in using Spark and Databricks.
Proficient in Python.
Proficient in OO methodologies, Agile development, design patterns, unit testing, and other software engineering principles and processes. 
Experience with AWS tools such as Redshift, Athena, Lambda, and Kinesis is a plus.
Experience with developing data pipelines, data lakes, and data warehousing solutions.

In Clip, we are committed to a diverse and inclusive workplace. Clip does not discriminate under any basis of origin, gender, gender identity, sexual orientation, race, disability, age or other legal status. Clip is an equal opportunity employer.If you are unstoppable, creative and have the skills we need, we want to hear from you!";['creativity', 'attention to detail', 'analytical skills', 'project management']
63;en;"Caylent is a cloud native services company that helps organizations bring the best out of their people and technology using Amazon Web Services (AWS). We provide a full-range of AWS services including: workload migrations & modernization, cloud native application development, DevOps, data engineering, security & compliance and everything in between. At Caylent, our people always come first.


We are a fully remote global company with employees in Canada, the United States and Latin America. We celebrate the culture of each of our team members and foster a community of technological curiosity. Come talk to us to learn more about what it means to be a Caylien!


The Mission


At Caylent, a Senior Machine Learning Architect works as an integral part of a cross-functional delivery team to design and document machine learning solutions on the AWS cloud for our customers. We are looking for someone that has a strong understanding of the various model types and tools, and can help our customers connect their business goals with the details of feature design, model training and inference. You will also have a weekly 1:1 with your manager to help guide you in your career and make the most of your time at Caylent.


Your Assignment


Work with a team to deliver machine learning solutions on AWS for customers
Decompose business goals into architecture and Sprint-level tasks
Having had thorough hands on experience, lead engineers in building solutions
Participate in daily standup meetings and address technical issues
Design and document ML models, MLOps, and analytics
Big data processing and preparation of training data for models


Your Qualifications


At least 7 years of hands on experience in most of these ML tools/techniques:
Build ML models in SageMaker
Build ML models in frameworks like Tensorflow & PyTorch and deploy in SageMaker
Train and deploy AWS pre-trained AI Services and Foundational Models
Build and optimize models using feature definition, activation functions, hyperparameter tuning and other techniques
Integrate ML models into real-time applications and batch workflows, recommend better infrastructure design and optimization
Monitor, evaluate and continuously improve model performance, as well as automate these tasks using one or more tools for MLOps
Hands on experience in these data engineering tools/techniques:
Data integration, cleansing, transformation, and visualization using Python packages, SQL, PySpark etc.
AWS services such as Glue, EMR, Athena, DynamoDB, StepFunctions, EKS etc
Experience with an IaC tool such as CloudFormation, CDK or Terraform
Excellent written and verbal communication skills


Benefits


Pay in USD
100% remote work
Generous holidays and flexible PTO
Competitive phantom equity
Paid for exams and certifications
Peer bonus awards
State of the art laptop and tools
Equipment & Office Stipend
Individual professional development plan
Annual stipend for Learning and Development
Work with an amazing worldwide team and in an incredible corporate culture


Caylent is a place where everyone belongs. We celebrate diversity and are committed to creating an inclusive environment for all employees. Our approach helps us to build a winning team that represents a variety of backgrounds, perspectives, and abilities. So, regardless of how your diversity expresses itself, you can find a home here at Caylent.


We are proud to be an equal opportunity employer. We prohibit discrimination and harassment of any kind based on race, color, religion, national origin, sex (including pregnancy), sexual orientation, gender identity, gender expression, age, veteran status, genetic information, disability, or other applicable legally protected characteristics. If you would like to request an accommodation due to a disability, please contact us at hr@caylent.com.";['communication', 'problem solving']
64;en;"About NCR

NCR Corporation (NYSE: NCR) is a leader in transforming, connecting and running technology platforms for self-directed banking, stores and restaurants. NCR is headquartered in Atlanta, Ga., with 38,000 employees globally. NCR is a trademark of NCR Corporation in the United States and other countries.

Título: Data Systems Engineer

Localidad: Argentina - Virtual

Grado: 10

Resumen De La Posición

Será responsable de diseñar, implementar, optimizar y administrar bases de datos. Automatización de procesos y reportes.

Tareas Laborales Diarias

Análisis de datos recurrentes y/o específicos. 
Creación y automatización de reportes. 
Trabajo en conjunto con áreas de desarrollo y Analytics. 

Requisitos Básicos

Experiencia en base de datos SQL y NoSQL. 
 Experiencia en puestos similares. 
Nivel de inglés B2/C1 (deseable)
Experiencia en Python. (deseable)
Experiencia en Estructura de Azure (deseable)
Experiencia en Databrick. (desable)
Experiencia de Reporting Services (deseable)
Experiencia en Administración de Servidores Windows / Linux. (desable)

Offers of employment are conditional upon passage of screening criteria applicable to the job.

EEO Statement

Integrated into our shared values is NCR's commitment to diversity and equal employment opportunity. All qualified applicants will receive consideration for employment without regard to sex, age, race, color, creed, religion, national origin, disability, sexual orientation, gender identity, veteran status, military service, genetic information, or any other characteristic or conduct protected by law. NCR is committed to being a globally inclusive company where all people are treated fairly, recognized for their individuality, promoted based on performance and encouraged to strive to reach their full potential. We believe in understanding and respecting differences among all people. Every individual at NCR has an ongoing responsibility to respect and support a globally diverse environment.

Statement to Third Party Agencies

To ALL recruitment agencies: NCR only accepts resumes from agencies on the NCR preferred supplier list. Please do not forward resumes to our applicant tracking system, NCR employees, or any NCR facility. NCR is not responsible for any fees or charges associated with unsolicited resumes.";['problem solving']
65;es;"En Mercado Libre estamos democratizando el comercio, el dinero y los pagos en América Latina.
 
Imagínate emprendiendo proyectos desafiantes, dinámicos e innovadores y siendo responsable de:

 
Crear, desarrollar e implementar soluciones nuevas y escalables para problemáticas transversales a la organización, con base en técnicas de estadística, Data Science y Machine Learning.
Obtener, procesar y analizar grandes volúmenes de datos provenientes de diversas fuentes y extraer insights de interés.
Diseñar, entrenar y evaluar modelos de Machine Learning capaces de adaptarse a entornos productivos complejos y establecer las mejores prácticas de desarrollo de software, a fin de asegurar procesos eficientes y automatizados.
Participar de reuniones con diferentes stakeholders, interpretar los requerimientos y proveer herramientas de visualización que simplifiquen la comunicación con interlocutores, tanto técnicos como de negocio.
Interactuar con los equipos de ingeniería al momento de desplegar, monitorear y mantener los modelos en producción.
 
Requisitos:

 
Contar con 4 años de experiencia trabajando en proyectos de Machine Learning o Data Science. 
Haber participado en la implementación de soluciones con Machine Learning en entornos productivos. 
Poseer conocimientos en tecnologías vinculadas a Machine Learning; librerías del stack, como Python, Numpy, Pandas, Scikit-Learn, Matplotlib; frameworks de Deep Learning, como TensorFlow, Keras, PyTorch, y bases de datos relacionales y distribuidos, como Redshift, Teradata, Hive, Presto y BigQuery, entre otros. 
Residir en cualquier localidad de Argentina.
 
Tecnología es la esencia de nuestro producto. Nuestros equipos de desarrollo, arquitectura, base de datos, user experience, seguridad informática y data & analytics co-crean y son responsables de la plataforma líder de e-commerce de América Latina y de uno de los sitios de mayor tráfico en todo el mundo. En una industria que se reinventa día a día, nuestros equipos son reconocidos por su visión y liderazgo. Desde aplicaciones móviles a machine learning, nuestra innovación tiene un claro foco: simplificarle la vida a quien utiliza nuestros productos.
 
Te proponemos:

 
Ser parte de una compañía con espíritu emprendedor en la que nos encanta pensar en grande y a largo plazo.
Ser protagonista de tu desarrollo en un ambiente de oportunidades, aprendizaje, crecimiento, expansión y proyectos desafiantes. 
Compartir y aprender en equipo junto a grandes profesionales y especialistas.
Un excelente clima de trabajo, con todo lo necesario para que vivas una gran experiencia. :)
 
 *La tarea puede llevarse a cabo de manera remota, con opción de presencialidad.

 
 
En Mercado Libre trabajamos para promover una cultura inclusiva, que busca la equidad y valora las diferentes perspectivas. Esto se traduce en género, religión, personas con discapacidad, LGBTQ+, etnia y diversidad de experiencias. Trabajamos todas nuestras búsquedas con base en esta premisa. ¡Súmate a nuestro equipo!";['comunicación', 'creatividad', 'adaptabilidad', 'liderazgo', 'habilidades analíticas']
66;en;"At Kin + Carta, we’ve got opportunities to offer you — for growth, for leadership, for big, world-changing impact and for, dare we say it, fun. We are a global workforce that is committed to building a world that works better for everyone. And that starts with our Kin. That’s why we’re proud of:


The life we create within our virtual walls, every day
Our B Corp certification
Our ranking in Consulting Magazine's 2022 “Best Large Firms to Work For”
The work we’ve done with some of the world’s most innovative companies


The role

Ideal candidates will have strong quantitative backgrounds and analytical discipline. While they will have some demonstrated ability to write code, they will not have learned programming languages for the sake of building their resume, but rather as a means to express their intellectual curiosity and analytical voice. Kin + Carta will provide a platform and training to help them reach their full potential.

Kin + Carta is looking to hire a Data Engineer to join our growing capabilities team. If you are innovative, passionate about data and AI technologies, and look to continually learn and enjoy sharing expertise, read on!

Role responsibilities


Analyze a collection of raw data sets to create meaningful impact to large enterprise clients while maintaining a high degree of scientific rigor and discipline.
Engineer data pipelines and products to help stakeholders make and execute data driven decisions.
Communicate analytical findings in an intuitive and visually compelling way.
Creating highly visual and interactive dashboards via Tableau, PowerBI, or custom web applications
Conducting deep dive analysis and designing KPIs to help guide business decisions and measure success
Engineering data infrastructure, software libraries, and APIs supporting BI and ML data pipelines
Architecting cloud data platform components enabling the above
Building and tracking project timelines, dependences, and risks
Gathering stakeholder requirements and conducting technical due diligence toward designing pragmatic data-driven business solutions


Minimum Qualifications

We want all new hires to succeed in their roles at Kin + Carta. That's why we've outlined the job requirements below. To be considered for this role, it's important that you meet all Minimum Qualifications. If you do not meet all of the Preferred Qualifications, we still encourage you to apply.


Proven industry experience executing data engineering, analytics and/or data science projects or Bachelors/Masters degree in quantitative studies including Engineering, Mathematics, Statistics, Computer Science or computation-intensive Sciences and Humanities.
Proficiency (can execute data ingestion to insight) in programmatic languages such as SQL, Python, R
5 years of experience working in similar roles. 


Preferred Qualifications


Proficiency in visualization/reporting tools such as Tableau and PowerBI or programmatic visualization library such as R ggplot2, Python matplotlib/seaborn/bokeh, Javascript D3.
Proficiency scripting in UNIX environment
Proficiency in big data environments and tools such as Spark, Hive, Impala, Pig, etc. 
Proficiency with cloud architecture components (AWS, Azure, Google)
Proficiency with data pipeline software such as Airflow, Luigi, or Prefect
Ability to turn raw data and ambiguous business questions into distilled findings and recommendations for action
Experience with statistical and machine learning libraries along with the ability to apply them appropriately to business problems
Proficiency in front and back-end web application development stacks and frameworks (Javascript, HTML, CSS, React/Vue/AngularJS) including API design (REST/GraphQL) and library development 
Experience leading and managing technical data/analytics/machine learning projects


About Kin + Carta

Kin + Carta is a global digital transformation consultancy committed to working alongside our clients to build a world that works better #ForEveryone. We build digital solutions that connect people, data and technology for some of the world’s most influential companies. As a Certified B Corp, we are committed to Inclusion, Diversity, Equity and Awareness, and our triple bottom line focus of people, the planet and profit.

If you need accommodations at any point in the application or interview process, please let us know.";['communication', 'problem solving', 'creativity', 'leadership', 'proactivity']
67;es;"Hola! 🙋


¿Todavía no conoces HIBERUS TECNOLOGÍA? Somos una empresa de #tecnología construida con un ingrediente diferencial, la HIPERESPECIALIZACIÓN.


Formar parte de Hiberus significa crecimiento, pasión por la tecnología, interés por la innovación, ambiente laboral flexible y colaborativo, compañerismo, aprendizaje, formación continua, motivación y superación ante nuevos retos...y esto es solo el principio.
Somos más de 2.500 profesionales y no paramos de crecer!🙌
Actualmente contamos con más de 20 delegaciones en puntos estratégicos de España, tenemos presencia en 10 países europeos, sede en Marruecos, Argentina, Colombia, Ecuador, Mexico y en EEUU.


Trabajamos muy duro, para transformar nuestra vida a través de la tecnología y queremos contar contigo para seguir creciendo. Si lo tuyo es el mundo IT, te gusta estar al día en las últimas tecnologías y quieres asumir un nuevo reto profesional ¡Sigue leyendo, te estamos buscando!


🔎¿Qué estamos buscando?

Buscamos especialistas en procesamiento de datos con Spark y Scala que quieran incorporarse al equipo y ser parte de grandes proyectos nacionales e internacionales.
Buscamos una persona que nos ayude a seguir creciendo, con ganas de aportar y seguir evolucionando de la mano de los mejores profesionales, pero sobre todo... ¡en Hiberus buscamos buena gente!😉


📋🖋️Habilidades y requisitos

Al menos 2 años de experiencia en big data (spark, hadoop, hive, kafka)
Amplia experiencia programando con Spark/Scala
Experiencia con BBDD (SQL, Postgres, mysql...)
Experiencia trabajando con herramientas devops (git, jenkins, sonar, nexus, jira, splunk)


Y además sería un plus si tienes experiencia con...
AWS
Visualización de datos
Flink, hbase
Machine learning


🙌¿Qué te ofrecemos?

💼 Contrato indefinido en una compañía puramente tecnológica, que forma parte de un gran grupo, solvente y en crecimiento.
💰 Salario fijo competitivo + bonificación
🏡 100% Remoto desde nuestras sedes en Argentina, México, España, UK, Alemania, Italia, USA.
🏖️ Ambiente familiar, cercano, ¡como una gran familia!
⏰ Conciliación con nuestra vida personal y laboral mediante horario flexible, acuerdos de teletrabajo, desconexión digital, jornada intensiva viernes y verano.
🤙 Cultura “techie”, nos gusta estar en contacto con la tecnología, herramientas, y últimas novedades!
📚 ¡Formación! Siempre que quieras, disfrutarás de un amplio catálogo de cursos formativos, adaptados a tu perfil profesional, inquietudes y novedades del sector. Para ello, pondremos a tu disposición todo el potencial de nuestra Hiberus University y los acuerdos con los principales fabricantes.
💳 ¡Benefíciate! Programa de retribución flexible a medida: seguro médico, tarjeta de transporte público, cheques guardería, tarjeta restaurante, etc.


En Hiberus estamos viviendo un crecimiento explosivo 💥 y queremos que formes parte de nuestro equipo.
Suena bien, ¿verdad? Si quieres saber más, ¡inscríbete y te contamos!
Si quieres saber más busca nuestros hashtag #somoshiberus #lascosasocurrenaquí y conoce todo lo que hacemos.
";['trabajo en equipo', 'creatividad']
68;en;"We are seeking a skilled AWS Developer with a strong background in Python and JSON to join our team. The ideal candidate will be responsible for developing and implementing innovative chatbot solutions using AWS services, with a focus on text-to-speech capabilities.
This role involves leveraging a variety of AWS tools and technologies to create efficient, scalable, and effective chatbot applications.


Candidates must be fluent in English and Spanish, both written and spoken. Only resumes in English will be considered.



Responsibilities:
Design and develop chatbot solutions using Amazon Lex, integrating voice and text functionalities.
Implement text-to-speech features using Amazon Polly and other relevant AWS services.
Work with AWS Lambda for serverless application development.
Utilize AWS AI services such as Transcribe, Kendra, Textract, Rekognition, Comprehend, and Cognito for enhanced chatbot functionalities.
Develop and maintain Lex intents and enhance chatbot designs using tools like Streamlit and OpenChatkit.
Apply machine learning techniques using Amazon SageMaker, Anthropic, and OpenAI GPT for natural language understanding (NLU) and processing.
Collaborate with cross-functional teams to integrate chatbot solutions into broader systems.
Optimize applications for maximum speed and scalability, ensuring best practices in security and data protection.
Provide innovative solutions to complex technical problems, demonstrating excellent problem-solving skills.


Requirements

2+ years of experience working with AWS cloud services.
Proficiency in Python programming and JSON data format.
Demonstrated experience in developing chatbot solutions.
Strong understanding of AI, ML, and NLU principles.
Excellent problem-solving abilities and a results-oriented mindset.


Desirable Experience



Experience with Amazon Lex V1/V2, Amazon Polly, Amazon Lambda, AWS Transcribe, Kendra, Textract, Rekognition, Comprehend, and Cognito.
Familiarity with chatbot design, modeling, and implementation using Streamlit, OpenChatkit, and similar tools.
Knowledge of AWS Machine Learning, IBM Watson, VoiceFlow, and other relevant technologies.
Understanding of confidence scoring in AI applications.
Knowledge of contact center environment / operations.
Realtime application development such as voice and video
Education
Bachelor's degree in Computer Science, Information Technology, or related field (preferred but not mandatory).
Strong communication and teamwork skills.
Eagerness to learn new technologies and stay updated with the latest industry trends.
AWS certification is a plus but not a requirement.";['communication', 'teamwork', 'creativity']
69;en;"TrovaTrip is a trip management platform dedicated to making travel safer and more accessible to all. Our mission is to enhance lives via meaningful connections, learning, and exploration. Our team of travel enthusiasts lives out our mission daily.

We are determined to make TrovaTrip one of the best places to work by building trust, respecting personal boundaries, valuing work-life balance, and promoting diversity and inclusiveness. Our commitment to instilling a true sense of ownership and belonging among every employee that will transcend from delighting customers to creating true market value. We believe in an environment where creativity, curiosity, and continuous improvement are encouraged and nurtured.

If you seek to develop your career and thrive off a fast-paced, collaborative culture where you can make an impact, you may be a fit for this position within the TrovaTrip Analytics Team.

About this position:

TrovaTrip is searching for a Data Engineer to be a member of our Analytics Team! We are looking for an experienced data practitioner who is driven to increase the impact of analytics and insights across the organization. You’ll have the opportunity to help the organization level up on the data maturity curve and build models using our best-in-class data stack and leadership support, including FiveTran, Snowflake, dbt, and Sigma.

Your work will directly support Analytics projects and have a measurable impact on the organization. Through ongoing operational learning, you’ll develop an expert understanding of the organization’s data, and partner closely with the Product Engineering, Sales, Marketing, and Trip Experience departments and report to the Director of Analytics.

Essential Functions:

Establish a best-in-class analytics program and further our data-driven philosophy for growth and expansion
Mature the department using data modeling best practices, version control, and documentation for async collaboration
Design and build new ELT-based data models using SQL and dbt
Write reusable SQL queries and transformations to support iterative analytics and data science development
Collaborate with analysts and stakeholders to understand business requirements
Guide the ongoing development of data technical needs and data architecture
Join data from disparate sources to enable better dashboarding, in particular sales/marketing data and events data for product analytics
Design and build internal and consumer facing dashboards for sales, marketing, trip experience, and product engineering. 
Design and build centralized reporting data model (Kimball, Inman, lakehouse, vault, etc) that is agile and self-service oriented. 
Build automations for manual data processes and improve data literacy amongst department groups. 

Qualifications:

Advanced SQL abilities and experience with python, R, etc.
Understanding of the modern data stack and experience managing it - from Insights tools like Sigma, Looker, QuickSight to more under-the-hood infrastructure like BigQuery, Segment, dbt, FiveTran, Airbyte, Snowflake, etc.
A passion for travel, learning and exploration
Strong work ethic and works well independently
Efficiency and ability to succeed in a fast-paced environment
Experience working cross-functionally with various teams internally
Integrity and a dedication to excellence
Exceptional async and collaborative communication skills
Track record of achieving success
Tenacity and resilience

Perks And Benefits

Direct contractor mode with Trovatrip Inc. - Payment 100% in USD.
Stock options.
Opportunities to grow your career along with the company.
Flexible hours 
USD$1,000 for equipment 
Multicultural work environment.";['communication', 'interpersonal skills', 'teamwork', 'problem solving', 'creativity', 'leadership', 'project management', 'fast-paced environment']
70;es;"🚀 Cuando pensamos en que VOS seas parte de nuestro equipo global en el “HUB de Datos” en Accenture Argentina, lo asociamos claramente a la canción: 🎵 “We (you)! will rock you” 🎵

🚀¿Por qué? Porque queremos que te conviertas en el próximo experto en Ingeniería de Datos & Big Data. Tendrás el desafío de participar en proyectos de data en empresas de primer nivel local, regional y global.


Si tenés experiencia a un nivel de liderazgo principal y un background técnico para hacer que las cosas funcionen ¡Sé parte de nuestro gran Equipo!


🚀 ¿Qué desafíos te esperan?

Como Data Engineering Consultant, vas a tener el desafío de desarrollarte y hacer crecer a nuestros clientes desde la arquitectura y la gestión de los datos tanto en la nube como on-premise; ¡tendrás la oportunidad de aprender todo lo necesario en el ciclo de vida de los datos con las mejores experiencias, metodologías y capacitaciones del mercado!

🚀 ¿Qué tipo de perfil nos imaginamos?


Profesionales de las carreras de Ingeniería Informática, Ingeniería en Sistemas, Licenciados en Ciencia de la Computación, y/o afines.

+4 años de experiencia en bases de datos relacionales: SQL Server, Oracle y/o Teradata, etc.

+ 2 años de experiencia en herramientas de ETL: SSIS, Talend, Informatica, Scripting: Unix Bash, y/o Python, etc.

+ 4 años de experiencia hands on en plataformas de big data: Hadoop, Cloudera, Hortonworks

Tecnologías cloud: AWS, GCP y/o Azure.

Teradata, Informatica y/o IBM Infosphere.

Power BI, Qlik, y/oTableau

Python y/o Java.

Inglés avanzado.


🚀 Un súper nice to have será contar con experiencia en:


Proyectos relacionados a datos: BI, Analytics, Data integration, Data Migration, Data Governance y/o Data Quality, etc.

Arquitecturas para BI: Analytics

Gobierno y calidad de datos.

Herramientas de data management: Informatica, Infosphere, Collibra y/o Talend.


🚀 Ok… si llegaste a leer hasta acá, te adelantamos lo que también es necesario que sepas: parte de nuestros grandes beneficios.

🍔 Pedidos Ya 👩‍⚕️ Prepaga Swiss Medical sin costo para vos y tu grupo familiar primario 💻 Reintegro de Conectividad 💪 Gimnasio 100% Bonificado 🌎 Vacaciones Flex 💯 Jornada Flex 📚 Certificaciones bonificadas 🎂 Día de cumpleaños libre 🏆 Bonos 🗓 Accenture Days 🤟🏽Paquete de beneficios flexibles 👨‍👩‍👦‍👦 Licencias de Paternidad & Maternidad Extendida 💰 Ayuda Económica para Guardería y muchos ➕!

🌎 Trabajá desde cualquier parte de la Argentina de forma 100% remota. También ¡tenemos oficinas a disposición en CABA, La Plata, Mar del Plata y Rosario!";['liderazgo']
71;en;"About us:

e2f helps people and machines communicate naturally regardless of language, content, or culture.

With expertise in data science - and deep roots providing agile translation in 200+ languages and dialects - e2f uniquely provides high-quality linguistic datasets of multilingual speech, text, annotation, and quality data required to help machines understand people.

e2f customers include several of the world’s most successful artificial intelligence (AI) and natural language processing (NLP) deployments.

About the Position:

The AI Prompt Engineer and Fine-Tuner is responsible for optimizing the interactions with AI language models. This role involves crafting effective prompts to elicit desired responses from the model and fine-tuning the model's responses for specific use cases. The ideal candidate will have a strong understanding of AI language models, natural language processing, and user experience design.

Key Responsibilities:

 Prompt Engineering:
Design and test prompts that effectively guide AI language models to generate accurate, relevant, and coherent responses.
Analyze different prompting strategies and their outcomes to continually improve model interactions.
 Model Fine-Tuning:
Customize the model's responses for specific applications, ensuring they meet user requirements and business objectives.
Collaborate with data scientists and engineers to fine-tune the model based on feedback and performance metrics.
 Quality Assurance:
Conduct rigorous testing to identify any biases or inaccuracies in the model's responses.
Implement strategies to mitigate any identified issues, ensuring ethical and responsible use of AI technology.
 User Experience Design:
Work closely with UX designers to ensure that prompts and responses enhance user interaction with the AI model.
Develop guidelines and best practices for prompt creation and model interaction.
 Documentation and Training:
Create comprehensive documentation on prompt engineering and fine-tuning processes.
Train other team members on best practices and methodologies.

Qualifications:

Strong understanding of AI language models, particularly GPT-4 or similar technologies.
Experience in natural language processing, machine learning, and data analysis.
Excellent problem-solving skills and creativity in prompt design.
Strong communication and teamwork abilities.
Familiarity with programming languages such as Python is a plus.

Desired Qualifications:

Bachelor’s or Master’s degree in Computer Science, Linguistics, AI, or a related field.
Proven experience in the AI and data industry with a focus on natural language processing, machine learning, and data analysis.";['communication', 'teamwork', 'creativity', 'analytical skills', 'project management']
72;es;"👉 Como Ingeniero de datos especializado en Microsoft Purview, podrás liderar diversas soluciones dentro de la práctica de Digital Enablement de KPMG Argentina. Serás un asesor de confianza y experto en la materia.


💎 ¿Cuáles serán tus tareas?



Asesorar a nuestros clientes en todo lo relacionado a la plataforma de Microsoft Purview con experiencia en gobierno de datos y estrategia. Ayudarlos a alcanzar sus prioridades de negocio con foco en la innovación y transformación de sus datos. Evaluar sus aplicaciones y requisitos comerciales para poder recomendarles soluciones exitosas.


💎 Requisitos: 



Graduados de Carreras informáticas, Administración de empresas o afines.
Más de 5 años de experiencia en áreas de preventa, administración de cuentas o ventas relacionadas con servicios tecnológicos.
Experiencia demostrable en diseño e implementación de soluciones de datos.
Conocimiento sólido de tecnologías y herramientas como: SQL, Python, Hadoop y Spark.
Conocimientos y experiencia en servicios de Data Analytics provistos por los principales CSPs (GCP, Azure, AWS)
Certificación en Azure Data Fundamentals (DP-900) o conocimiento equivalente (Deseable)
Capacidad para aprender rápidamente nuevas tecnologías según sea necesario.
Poseer buenas habilidades comunicacionales, analíticas, de gestión y de liderazgo.
Nivel de inglés requerido: avanzado.


✨ ¿Qué tenemos para ofrecerte?



🏋️Afrontar desafíos de forma constante y desarrollar tu carrera en un ambiente dinámico.
✡ Prepaga para vos y tu grupo familiar directo.
💳Tarjetas de beneficios: Club La Nación Premium, Club La Voz y La Capital.
💻Reintegro de Conectividad & Servicios.
📚Certificaciones con descuentos exclusivos.
🏝Días hábiles de vacaciones.
🎂¡Día de cumpleaños libre!
👨‍🎓¡Días extras por estudio!
💰Reintegro por Guardería.
👩‍🏫Clases de Inglés.
🏋️‍♀️Gympass.
✨Licencia extendida por paternidad y adopción.
👶Programa Softlanding luego del nacimiento/adopción de un hijo.
";['creatividad', 'liderazgo', 'proactividad']
73;en;"Job Description

Ability to enter data into GUI (Authoring UI)
Ability to translate information from spreadsheet into SQL to load into the GUI
Abiliy to understand data formats
Ability to understand data structure
SQL knowledge/NoSQL knowledge
Knowledge of data
ALDM knowledge of source to target mapping
Understanding of Microservices (Conversion DEEP.IO)
Understanding of CI/CD
Experience with Amdocs DataOne - will be a huge plus
 
Job Responsibilities

Attribute Dev & Maintenance:
Maintains existing data feed data pipelines (adding/removing fields and corresponding model alignment). Primarily performed via Authoring UI (AMDOCS Product)
Data Quality:
E2E data mapping and reconciliation.
Data Ingestion:
Work from last month largely centered around Recon, Full Recon & Transient Data (no Scylla, just straight loads from source).
Automation:
Dev utilities that automate manual tasks and perform quality assurance








What We Offer

Exciting Projects: Come take your place at the forefront of digital transformation! With clients across all industries and sectors, we offer an opportunity to work on market-defining products using the latest technologies.
Collaborative Environment:Expand your skills by collaborating with a diverse team of highly talented people in an open, laidback environment — or even abroad in one of our global centers or client facilities!
Work-Life Balance:GlobalLogic prioritizes work-life balance, which is why we offer flexible work schedules.We offer you the best quality of work life so that you exceed the expectations of our clients, while achieving your professional and personal ambitions.
Professional Development:Our dedicated Learning & Development team regularly organizes English classes, professional certifications, and technical and soft skill trainings. We also offer the chance to travel internationally
Excellent Benefits:We provide our employees with competitive salaries, family medical insurance, extended paternity leave, annual performance bonuses, and referral bonuses.
About GlobalLogic GlobalLogic is a leader in digital engineering. We help brands across the globe design and build innovative products, platforms, and digital experiences for the modern world. By integrating experience design, complex engineering, and data expertise—we help our clients imagine what’s possible, and accelerate their transition into tomorrow’s digital businesses. Headquartered in Silicon Valley, GlobalLogic operates design studios and engineering centers around the world, extending our deep expertise to customers in the automotive, communications, financial services, healthcare and life sciences, manufacturing, media and entertainment, semiconductor, and technology industries. GlobalLogic is a Hitachi Group Company operating under Hitachi, Ltd. (TSE: 6501) which contributes to a sustainable society with a higher quality of life by driving innovation through data and technology as the Social Innovation Business.
";['creativity']
74;en;"Rise Interactive (http://www.riseinteractive.com), a rapidly growing full service interactive advertising agency, is looking to hire a Software Engineer, focused on Data Management, into the Innovation team. We are seeking a detail-oriented, highly motivated individual contributor that is excited about joining a new Innovation department and contributing professionally to an entrepreneurial company with an expanding Fortune 500 client base.

Job Summary

We’re looking for a Data Engineer to help us build out our marketing and analytics platforms. Our platform processes billions of records today – and we’re just getting started. This role is not just a research or analytical role, it is an individual contributor role that is expected to contribute to production solutions for the entire data pipeline. Our goal is to add a data engineer who is strong at building systems from scratch by communicating closely with business stakeholders and passionate about delivering the best possible product and customer experience.

Functions And Responsibilities

We operate a cross-functional team that specializes when needed but aims to have everyone able to contribute. Duties of the Data Engineer include:

Implement and optimize data processing pipelines for megabytes to terabytes of data
Onboard and integrate client data into our analytics platform
Design and build our data warehouse as well as real-time data reporting systems
Promote and nurture good team practices such as unit testing, code reviews, build/test automation, etc.
Proactively mentor and guide developers to improve their quality and simplicity in design and code
Design, build and use tools to understand our product platform behavior and performance
Design and conduct experiments to test concepts, technologies, and algorithms
Implement analytics tools to maximize the value of collected data
Implement data tests in data quality frameworks to ensure data is clean and accurate
Adhere to security policies and guidelines to ensure our data is protected and safe
Embrace and assist in evolving our Agile (Scrum) team processes and developer role responsibilities

Education, Training, And Experience

Education

Bachelor's degree in computer science or equivalent field

Training

N/A

Experience

1-3 years of on-the-job experience

Qualifications

PREFERRED SKILLS

Smart, high aptitude to learn new things and sense of urgency to get things done
Extremely strong ETL programming skills using tools like Python, Spark, PySpark, Hadoop, MapReduce, Kafka
Experience building data access layers via cubes, data marts, APIs, or visualization tools like Tableau or D3 
Practical experience with Big data and NoSQL technologies desired
Comfortable working with several large, complex SQL databases and SQL queries
Experience working in cloud-only infrastructure, especially Amazon Web Services
1+ years of experience working with large amounts of real data
A strong passion for empirical research and answering hard questions
Team player – demonstrated experience on a few teams that have shipped a product
Professional developer – experienced with source control (Git) and bug tracking
Practical-minded – chooses stability/reliability/maintainability over shiny new objects
Passionate about technology – ideally you build things outside of work for fun 
Scripting skills – must be totally comfortable at the Linux command line
Nice to have: Expertise in applied statistics or machine learning
Experience delivering data products in the marketing, ad tech space is also a plus
Excellent English verbal and written communication skills

If you were here this month, you would have

Modeled web impression data into usable information
Created scripts to manage our cloud environment
Sped up an ETL process to make our users happy
Tried to get the top pinball score
";['communication', 'problem solving', 'creativity', 'attention to detail', 'project management', 'proactivity', 'mentoring/teaching']
75;es;"En VMLY&R estamos buscando un Data Analyst Sr, para cliente del rubro automotriz en la Región Sudamérica.


Responsabilidades: 

Elaboración de Dashboards en base a las necesidades de los usuarios decisores.
Análisis estratégico de información para detectar Insights.
Identificación e interpretación de KPIs.
Generación y automatización de Queries para informes y reportes ejecutivos.
Armado de ETLs.
Pruebas de consistencia de la información visualizada en Dashboards y comunicada en reportes.


 Requisitos:

Contar con 2 años de experiencia en posiciones similares.
Conocimientos de visualizadores como: Power BI, Looker Studio, Tableau, Qlik Sense, etc.
Lenguajes: SQL (excluyente), Python (deseable), HTML (deseable).
Conocimientos en Google Tag Manager, Google Analytics, Adobe Analytics (Deseable).
Conocimiento de plataforma Sales Force.
Inglés y portugués (deseable).
";[]
76;en;"Dive into a world where code meets creativity and each line you write has the potential to spark digital life into the most advanced AIs. We're not just a company, we're a global tech phenomenon, piecing together the future of engrossing chatbots straight out of science fiction. We're on the hunt for a Python Developer — a sharp coder with a taste for agility, scalability, and all things AI. If you’re a modern-day tech artisan eager to embark on projects peppered with AI, ML, and collaborative innovation, you've found your arena.


Your Adventure Awaits:


Craft high-caliber, resilient code that adapts like AI and scales like cloud infrastructure.
Engage in rigorous code reviews keeping an eye out for the pristine standard of clean and efficient codebases.
Deploy cutting-edge Python libraries to deconstruct and streamline complex challenges with grace.
Be the guardian of your code, ensuring it's not just functional but is a beacon of industry best practices for data-driven AI development.


Your Toolkit and Talents:


Proudly holding a tech decree, supplemented by continuous skill upgrades in the tech sphere.
With 3+ years as a software sage, Python is your staff of power with which you weave backend magic.
You've got fine-tuned expertise in Python, firing up data models, machine learning wizardry, and seamless API concoctions.
Adept in SQL with the QA acumen that places you at the heart of the DevSecOps revolution.
Familiarity with CI/CD, unit testing, and a history of conquered bugs will set you apart as a candidate of legend.
You thrive on solving algorithmic puzzles, transforming towering data sets into digestible insights.
If cloud platforms and container orchestration sing your song, consider us already charmed.
Your software development achievements aren't just noted; they echo in the valleys of tech lore.
You're so well-versed in English, you're unofficially the Rosetta Stone between geeks and mortals.


Unique Perks and Opportunities:


Collaborate with illustrious researchers and innovators from every corner of the globe, building a network that’s as expansive as your ambitions.
This is more than a job; it’s a digital nomad's dream with full remote flexibility. Work where you thrive.
Enjoy a competitive salary paid in USD, ensuring you benefit from a global standard.
Work on breakthrough projects that bend the boundaries of tech, consistently pushing you to the vanguard of industry innovation.


Rise with Us: Answer the call to invent the intelligence that will define tomorrow’s conversational AI. Let's turn what if into what is together! 🚀";['communication', 'teamwork', 'creativity', 'adaptability']
77;en;"Please submit your resume in English - we can only consider applications submitted in this language.

Minimum qualifications:

Bachelor's degree in Computer Science, Mathematics, a related technical field, or equivalent practical experience.
3 years of experience building Machine Learning (ML) solutions.
Experience coding in one or more languages (e.g., Python, Scala, Java, Go, or similar), data structures, algorithms, and software design.
Experience working with technical customers.

Preferred qualifications:

2 years of experience working with recommendation engines, data pipelines, or distributed machine learning.
Experience with deep learning frameworks (e.g., Tensorflow), Vertex AI, or Generative AI.
Experience in technical consulting.
Knowledge of Machine Learning Operations and BigQuery Machine Learning.
Familiarity with foundational concepts of application development, infrastructure management, data engineering, and data governance.

About The Job

The Google Cloud Platform team helps customers transform and build what's next for their business — all with technology built in the cloud. Our products are engineered for security, reliability and scalability, running the full stack from infrastructure to applications to devices and hardware. Our teams are dedicated to helping our customers — developers, small and large businesses, educational institutions and government agencies — see the benefits of our technology come to life. As part of an entrepreneurial team in this rapidly growing business, you will play a key role in understanding the needs of our customers and help shape the future of businesses of all sizes use technology to connect with customers, employees and partners.

As an AI Engineer, you will design and implement machine learning solutions for customer use cases, leveraging core Google products. You will work with customers to identify opportunities to apply machine learning in their business, travel to customer sites to deploy solutions, and deliver workshops to educate and empower customers. Additionally, you will partner with Product Management and Product Engineering to build and drive excellence in our products.

In this role, you will work with Google Cloud customers. You will support customer implementation of Google Cloud products through architecture guidance, best practices, data migration, capacity planning, implementation, troubleshooting, monitoring, and more.

Google Cloud accelerates organizations’ ability to digitally transform their business with the best infrastructure, platform, industry solutions and expertise. We deliver enterprise-grade solutions that leverage Google’s cutting-edge technology – all on the cleanest cloud in the industry. Customers in more than 200 countries and territories turn to Google Cloud as their trusted partner to enable growth and solve their most critical business problems.

Responsibilities

Act as a trusted technical advisor to customers and solve machine learning issues.
Develop and optimize machine learning models, design processing systems and orchestrate Machine Learning (ML) pipelines.
Work with customers, partners, and Google Product teams to deliver tailored solutions into production.
Create and deliver recommendations, tutorials, blog articles, sample code, and technical presentations adapting to different levels of key business and technical stakeholders.
Mentor customers on the practical issues in Machine Learning systems, including feature extraction/feature definition, data validation, monitoring, and management of features/models.


Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .";['communication', 'teamwork', 'adaptability', 'customer service', 'mentoring/teaching']
78;es;"About The Job

Al asumir la posición de Data Science Analyst dentro de la unidad de negocios de SN en las oficinas de HIT tendrás el desafío de

Trabajar de manera de directa con las diferentes áreas para transformar los diferentes datos en información y encontrar oportunidades concretas de negocio.

About You

Suena un gran desafío, ¿no? Para poder alcanzar este logro y ser exitoso en el rol, consideramos que necesitás contar con la siguiente formación, conocimientos y competencias

Formación académica Estudiante avanzado o recibido de Ing. Industrial, Administración de Empresas, Marketing, o carreras afines
1 año de experiencia en roles similares
Conocimientos en Excel (excluyente). Power BI (deseable). Modelado (Deseable)
Competencias Capacidad de análisis. Resiliencia. Trabajo en Equipo. Autonomía. Proactividad. 

About us

Danone es una empresa con una cultura y ADN que nos distingue fuertes raíces, grandes valores y una misión desafiante. En la unidad de negocios de Nutrición Especializada, nos guía un fuerte propósito “brindar salud a través de soluciones nutricionales especializadas para ayudar en los momentos claves de tu vida”.

Contamos con un porfolio amplio de productos, tanto con marcas globales como locales. El mismo se compone de

 Fórmulas infantiles y alimentos para bebés para un crecimiento y desarrollo saludables en los primeros años de vida donde nuestras marcas principales son Nutrilón, Vital, Crecer y La Serenísima Baby. 
 Nutrición pediátrica especializada para temas de salud temprana, como por ejemplo alimentos para prematuros o bebes alérgicos a la proteína de la leche de vaca. 
 Alimentos de nutrición con propositos médicos para adultos con enfermedades agudas y crónicas o en edad avanzada. 
 Un servicio de internación domiciliaria especializada en nutrición. 

A través del negocio buscamos crear un cambio positivo en el ámbito social y ambiental, y por eso nos comprometemos con la comunidad, los trabajadores, los clientes, la gobernanza y el planeta. En 2019 certificamos como Empresa B ¡y esto nos llena de orgullo!";['habilidades interpersonales', 'trabajo en equipo', 'proactividad']
79;en;"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, Trilogy. Have you got what it takes?

Calling AI enthusiasts! Do you dream of a world where AI not only supports but fully runs education services? Does the thought of using AI to replace human decision-making thrill you? Then listen up because we have an exciting opportunity just for you!

At Trilogy, we're on a mission to harness the power of AI to transform education. But we need someone at the helm who's not just an expert in AI integration and prompt engineering but who's also laser-focused on understanding and incorporating the latest in learning science.

Your primary task? Take the reins to transition our human-run education services to be fully automated through the power of generative AI. Sounds like the kind of challenge you're up for? Perfect!

Ready to step into the forefront of education technology? Apply today and start a journey that promises to be exciting, challenging, and super rewarding! We can't wait to hear from you!

What You Will Be Doing

Using your technical acumen and tools like OpenAI Code Interpreter, LangChain, and AWS Glue to revolutionize our educational services.
Unleashing the power of AI to make our services smarter with your knack for breaking down complex cases into component steps and designing AI prompts accordingly.
Keeping us on track, thoroughly checking and validating our IDSs to ensure our AI solutions are on point and delivering top-notch services.
Rolling up your sleeves, evaluating outputs, building prototypes, and doing whatever it takes to push the quality bar higher.

What You Won’t Be Doing

Spending your day delegating tasks. You will get hands-on in the research and data, building prompts and prototypes to find the best solutions.
Wasting time in pointless meetings. Our asynchronous culture prioritizes written communication and moves decision-making and feedback out of meetings and into the comment section.
Managing in the traditional sense. We believe the best managers lead by example, actually doing the work and setting a high-quality standard for their team.
Training LLMs. We're interested in your ability to utilize LLMs, not train them.

Basic Requirements

Senior Machine Learning Engineer key responsibilities

A grasp of AI, Large Language Models (LLMs), and prompt engineering, including Chain-of-Thought (CoT) prompting and Self-Consistency in CoT
Enough coding experience to assemble a set of prompts into a working prototype service in a single day
A mastery of self-learning. If you're the type of person who applies learning science to your own learning journey – you're our kind of people!
A process-focused mindset. It’s all about designing simple, repeatable processes that allow a system to scale.

Nice-to-have Requirements

Experience working with CodeInterpreter, LangChain, AWS Glue, and AI Orchestration tools to create 100% AI-based workflows
Prior successful experience automating manual processes

About Trilogy

Hundreds of software businesses run on the Trilogy Business Platform. For three decades, Trilogy has been known for 3 things: Relentlessly seeking top talent, Innovating new technology, and incubating new businesses. Our technological innovation is spearheaded by a passion for simple customer-facing designs. Our incubation of new businesses ranges from entirely new moon-shot ideas to rearchitecting existing projects for today's modern cloud-based stack. Trilogy is a place where you can be surrounded with great people, be proud of doing great work, and grow your career by leaps and bounds.

There is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!

Working with Crossover

This is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $200 USD/hour, which equates to $400,000 USD/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com/help-and-faqs for more details on this topic.

What to expect next:

You will receive an email with a link to start your self-paced, online job application.
Our hiring platform will guide you through a series of online “screening” assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.

Important! If you do not receive an email from us:

First, emails may take up to 15 minutes to send, refresh and check again.
Second, check your spam and junk folders for an email from Crossover.com, mark as “Not Spam” since you will receive other emails as well.
Third, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.
If all else fails, just reset your password by visiting https://www.crossover.com/auth/password-recovery if you already applied using LinkedIn EasyApply.";['communication', 'creativity', 'proactivity']
80;en;"About Us

Braintrust is a user-owned talent network that connects top-tier professionals with the world's leading enterprises. We prioritize transparency, eliminating middlemen and high markups, ensuring job-seekers are matched swiftly to innovative roles while clients benefit from unparalleled efficiency and quality.
About The Hiring Process

The hiring process for this role involves completing your Braintrust profile, applying directly to the role on Braintrust, and undergoing a one-time screening to ensure you meet our vetted talent specifications. After this, the hiring team will contact you directly if they believe you are a suitable match.
Our process isn't for everyone, that's intentional. If you believe that you are a top candidate for this job, please join our network to give yourself the opportunity to work with top companies.
JOB TYPE: Freelance, Contract Position (no agencies/C2C - see notes below)
LOCATION: Work from anywhere - Anytime | No timezone overlap required
HOURLY RANGE Our client is looking to pay $16.00 – $55.00/hr
ESTIMATED DURATION: 20/week - short term
EXPERIENCE: 3-4 years
BRAINTRUST JOB ID: 11450
The Opportunity
This is a great opportunity to supplement your income while looking for longer or more full-time work, all while contributing to the development of new AI models using your domain expertise!
Our client has hired over 100 BT Talent and intends to hire hundreds more!

You’ll have the flexibility to work as much or as little as you choose - 20hrs/week is suggested, but not a limit. Start working in as little as 48 hours.
What to expect: If qualified, you’ll complete an ID verification & be invited to complete a 30-minute technical interview, typically scheduled within 48 hours of being invited. The interview will consist of technicals, choosing from: JS, Java, C++, and Python. If you successfully pass the interview, you’ll be approved and able to begin work ASAP. Otherwise, the next step will be to complete an async rating & writing assessment.
In both scenarios, you will be compensated for successfully completing the assessment, up to $175.
Required Qualifications

Complete fluency in the English language is required. You should be able to describe code and abstract information in a clear way.
Proficiency working with any of the the following:
Python, Java, JavaScript / TypeScript, SQL, C/C++/C# and/or HTML
Preferred Qualifications

Bachelor's and/or Master's degree in Computer Science or equivalent. Students are welcome.
Proficiency working with any of the the following (in addition to the languages above):
Swift, Ruby, Rust, Go, NET, Matlab, PHP, HTML, DART, R, Apex, and Shell
Data Science experience
Note: Scale AI is partnering with Remotasks for this opportunity
What You'll Be Working On
Our client has partnered with organizations to train AI large language models, helping cutting-edge generative AI models write better code. 

Example projects might include:
Evaluating the quality of AI-generated code, including human-readable summaries of your rationale
Solve coding problems, writing functional and efficient code
Optimize code to run at maximum efficiency
Writing robust test cases to confirm code works efficiently and effectively
Writing human-readable summaries of coding problems
Writing explanations of how code can solve problems and evaluate various solution approaches
No previous experience with AI necessary! You will receive detailed instructions on what is expected of you after you complete the application and verification process.
Apply Now!

Notes

Our employers all have varying legal and geographic requirements for their roles, they trust Braintrust to find them the talent that meet their unique specifications. For that reason, this role is not available to C2C candidates working with an agency. If you are a professional contractor who has created an LLC/corp around their consulting practice, this is well aligned with Braintrust and we’d welcome your application.
Braintrust values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status.";['creativity', 'adaptability']
81;en;"Full-Stack Software Engineer
Are you ready to level up your career? Parrade is looking for an ambitious full-stack software engineer to help shape the future of retail. If you are eager to design a groundbreaking platform from the ground up, we want to hear from you!


At Parrade, we're not just changing the game in retail; we're creating a new one. Our platform is at the forefront of co-retailing and online-to-offline commerce, transforming unused spaces into vibrant, revenue-generating opportunities. Our company was founded by an e-commerce veteran with two decades of experience building successful businesses.


Learn more about our company: www.parrade.com/blog

About the role
As a full-stack software engineer at Parrade, you won't just be joining a team; you'll be at the forefront of pioneering a new era in retail technology. Working directly with our leadership team in Texas and California and reporting to our CTO, you will bring your expertise to a diverse and forward-thinking environment.


As the first full-time member of our startup, your work will lay the foundation for our technological vision, driving forward our mission to revolutionize the retail experience. This is more than a job; it's a chance to be part of a movement that's redefining retail with every line of code.


This role is a full-time, 100% remote position. You'll initially focus on front-end development (70%) with a gradual shift to include more back-end responsibilities (30%).

Role outcomes
In this pivotal role, your contributions will directly impact our platform's success and growth, as outlined in the following key outcomes:

Successful platform launch: You will play a crucial role in launching our two web applications by April 2024. This involves active participation in the development, testing, and refinement phases, ensuring that the launch is smooth, meets our high standards, and is ready for user engagement.
Facilitate revenue generation: Your contributions will be key in enabling Parrade to start generating revenue by the summer of 2024. This includes developing features that enhance user experience and ensuring scalability to handle increasing traffic and transactions.
Set a high bar: As the first full-time member of our startup, you will establish the performance standards for future hires. This means demonstrating exceptional skill, dedication, and creativity in your work, thereby setting a precedent and a benchmark for excellence in our growing team.

The work is challenging, but the growth potential is limitless! We promise you won’t be bored.

What you will be doing
Build high-performance ReactJS web applications with MUI (70% of the work)
Build robust GraphQL microservices with Python and Django (30% of the work)
Build and maintain components with Storybook
Work with our product designer to deliver delightful UIs
Triage production bugs and issues
Help our CTO plan new features
Use TDD to minimize bugs
Review code and improve code quality
Participate in scrum ceremonies such as daily stand-up, OKR + backlog refinement, and sprint showcase
Redesign and maintain our home page (parrade.com)
Maintain deployment pipelines and automate DevOps tasks
Design and implement data models; deploy and migrate backends
What you should have
A degree in computer science or a certificate from a boot camp
Strong English skills (B2 - C1)
Experience with Git
A strong eye for good design
1+ years of experience building ReactJS applications with HTML5 + CSS
1+ years of software experience (Typescript/Python)
6+ months of database management experience (Postgres)
A desire to own your work and consistently exceed expectations
Strong communication, collaboration, and management skills
An understanding of software design patterns
A willingness to learn how to manage complex software development projects
Commitment to continuous learning and professional growth.

The first 30 days of working with us will be an introductory period. After your first 30 days, we evaluate if you are a strong fit per the criteria in this post. If we are a solid fit for each other, you will become a permanent team member.


Please note that this role requires a stable high-speed internet connection. You must be available to work 8+ hours, Monday - Friday. We work between 8 am and 5 pm Central Time.

Nice-to-haves
Prior experience building NextJS apps with server-side rendering
Expertise in designing and consuming GraphQL Relay APIs
Familiarity with Django or FastAPI
Project management experience
Experience working with GCP
Knowledge of Domain Driven Design (DDD) principles
Experience with Docker
Experience using Terraform
What we offer
A competitive compensation with the potential for growth
Paid time off (PTO)
A 100% remote work culture with a focus on autonomy and trust
Ample opportunities for personal and professional development
Freedom to make impactful decisions
A supportive team of “A” players";['communication', 'teamwork', 'creativity', 'leadership', 'project management']
82;en;"Scope of Position:

This group develops and integrates the Measurement and Inspection systems that enable Global Manufacturing to characterize and verify compliance of products manufactured and sold to our customers.

The Software Engineer uses computer science principles to support Global initiatives in the development and sustainment of measurement platforms. Needs strong technical curiosity across many technologies, and the ability to learn and desire to work with others for the progress of the business. As part of a global team, this position provides integrated measurement solutions to Corning’s Optical Connectivity business to deliver best in class products to our customers.

Day to Day Responsibilities:

· Work closely with Technology Development, Manufacturing, Division Engineering, and IT to define, develop and implement product measurement and instrumentation, industrialize and standardize measurement applications and architectures for consistent data flow and reporting among processes and regions.
· Provide technical leadership and expertise to design, develop, and deploy integrated measurement systems to global manufacturing facilities.
· Participate in all phases of projects including design, off-line integration and testing, installation, production start-up support, training of plant personnel, and technology transfer.
· Setup and execute measurements, perform post-processing of data, and deliver reports and analysis to customers.
· Provide troubleshooting support for equipment and process issues during equipment installation and start-up phases, identify root cause and implement corrective actions.
· Support the transfer of measurement technology from other location/region or in early stage development to a system ready for use in a manufacturing environment.
· Develop and manage documentation in support of measurement system deployments including machine specifications, operating procedures, and drawing packages.
· Train engineering, maintenance and operations people how to use and maintain the measurement systems.
· Leverage external suppliers with key technologies or systems integration expertise to develop, procure, build, and install test applications in measurement platforms.
· Upgrade and sustain Legacy Measurement Webpages to improve customer interaction and develop metric reporting site to keep track equipment and server performance.
· Management of execution of short term and long-term solutions.
· Assure quality and repeatability of processes and measurement systems software.
· Visibly support the establishment and maintenance of a safe work environment.
Required Education, Years and Area of Experience:

- BS or MS in Electrical Engineering, Computer Systems or Computer Science
- 3+ years of work experience in systems development, test equipment integration and/or software development.
Required Skills:

- Strong English and Spanish written and verbal communication skills.
- Ability to work independently without close supervision.
- Strong time management skills to be able to manage multiple projects and tasks in parallel.
- Strong initiative and self-motivated. Ambition and ability to independently fill gaps in knowledge and expertise through self-guided learning.
- Excellent problem-solving skills.
- Experience with manufacturing test systems and/or instrumentation
- Experience with computer-based measurement equipment setup and support.
- Working knowledge and experience in Visual C# or VB.Net software development.
- Experience in client/server system development in an Oracle or SQL Server environment.
- Basic understanding of Oracle or SQL Server relational databases.
- Ability to interface with Oracle or SQL Server through either Stored Procedure calls or dynamic SQL.
- Understanding of basic SQL (Select/Insert/Update statements).
- Experience in data acquisition system interfacing either through direct API calls, SCPI protocols, or other communication protocols.
- Ability to work in technical project teams in leadership and team member roles.
- Able to make sound decisions by blending analytical thinking with practical judgment.
- Accountable for actions/behaviors.
- Ability to work closely with internal customers around the world to meet customer requirements.
- Ability to work individually and on teams to execute projects on time, on budget, and with expected results.
- Ability to work in a multi-cultural team.
Desired Skills:

- Working knowledge of test equipment used to characterize various fiber optic assemblies. This can include, but is not limited to – equipment capable of measuring optical power loss, attenuation (OTDR), interferometers, and microscopy (end-face inspection) equipment.
- Working knowledge and experience in LabVIEW.
- Experience in the use of Source Code Control systems.
- Experience working within a team of developers on a single source code project.
- Experience in RS232/USB/GPIB/Ethernet interfacing to data acquisition hardware.
- Experience in Optical Communication product test methods, characteristics, and data acquisition hardware.
- Experience with image capture systems or machine vision systems (Like Keyence, Cognex, Omron).
- Experience in relational database design.
- Experience in Manufacturing Execution Systems.
- Demonstrated project management experience.";['communication', 'problem solving', 'leadership', 'analytical skills', 'project management', 'proactivity']
83;es;"En Telefónica - Movistar, tenemos como Misión hacer nuestro mundo más humano, conectando la vida de las personas porque ellas son las que dan sentido a la tecnología y no al revés. 
Creemos que las conexiones más importantes son las conexiones humanas, por eso unimos a las personas en lugar de aislarlas y las invitamos a ser ellas mismas, a expresarse, a compartir. 
 Aspiramos a ser inclusivos digitalizando a toda la sociedad, sin dejar a nadie atrás. 
 
 Telefónica Hispanoamérica es la unidad del Grupo Telefónica que aglutina los activos y operaciones en Argentina, Chile, Colombia, Ecuador, Perú, México, Uruguay, Venezuela y Centroamérica. Ha puesto en marcha un nuevo modelo operativo multi país para maximizar el valor de sus activos en Hispanoamérica a través de la simplificación y la excelencia. La compañía es uno de los mayores proveedores de servicios de telecomunicaciones en la región, opera bajo la marca comercial Movistar, ofrece servicios de conectividad de banda ancha fija -con soluciones de FFTH- y móvil con redes de 4G, así como una amplia gama de servicios digitales para más de 108 millones de clientes residenciales y empresariales. 

 
Dirección: BIG DATA ADVANCED DELIVERY
Área: Machine Learning
Modalidad de trabajo: Híbrido / Remoto
 

Misión del Rol  
 
 El puesto tiene como principal objetivo resolver problemáticas complejas mediante el desarrollo de modelos de machine learning y análisis estadísticos avanzados con una fuerte visión de negocio. 

 
Funciones Asociadas al Rol 
 
Modelar problemáticas de negocio utilizando técnicas de data science y herramientas para explotar grandes volúmenes de datos.
Diseñar, desarrollar, entrenar, evaluar y recalibrar modelos de machine learning, adaptándolos a entornos productivos de manera eficiente y automatizada.
Realizar análisis estadísticos detectando insights y oportunidades de mejora del negocio.
Extraer conocimiento y producir otros nuevos a partir de las metodologías empleadas.
 
Requisitos Indispensables (Excluyente)
Ser estudiante avanzado o graduado de las carreras de Lic. en Ciencias de Datos, Ciencias de la Computación, Economía, Estadística, Física, Ingeniería, Matemática o afines.
Tener experiencia de no menos de 2 años en desarrollo e interpretación de modelos de machine learning.
Contar con conocimientos de entorno Hadoop y herramientas de Big Data, programación avanzada en Python, Spark, SQL.
Poseer amplia capacidad analítica para dar respuesta a las distintas necesidades o promover una oportunidad de mejora.
  
Requisitos Deseables 
 
Contar con conocimientos de programación: Scala, R, Tensorflow, Keras, Pytorch.
Poseer conocimientos de Cloud ML Ops (Azure/AWS/GCP). 
 
 
Competencias  
 
Ser una persona emprendedora con un alto grado de auto-motivación y proactiva.
Tener un perfil autodidacta orientado al trabajo por objetivos y que pueda resolver tareas de forma autónoma.
Ser constructor de relaciones a todos los niveles.
Ser un apasionado por la innovación y contar con entusiasmo y habilidades de comunicación para transmitir de forma clara los conceptos a equipos de otras áreas.";['comunicación', 'creatividad', 'proactividad']
84;en;"Luflox is a dynamic and innovative IT solutions provider, and we are on the lookout for a talented Junior Angular Developer to join our growing team. If you are passionate about web development, have a solid foundation in Angular, and are eager to learn and grow in a collaborative environment, we want to hear from you!


Responsibilities:

Collaborate with the development team to design and implement responsive user interfaces using Angular.
Collaborate with the design team to implement user-facing features.
Ensure the technical feasibility of UI/UX designs.
Optimize application performance for maximum speed and scalability.
Write clean, maintainable, and efficient code.
Troubleshoot and debug applications to enhance performance and user experience.
Conduct thorough testing of applications to identify and resolve issues.
Actively contribute ideas and solutions to enhance team productivity and project efficiency.
Requirements:

Bachelor's degree in Computer Science, Software Engineering, or a related field.
1+ years of experience with Angular.
Proficiency in Angular and its core principles.
Understanding of web development concepts, HTML, CSS, and JavaScript.
Strong problem-solving and analytical skills.
Eagerness to learn from senior team members and adapt to new technologies.
LATAM resident.
Preferred:

Experience working with Angular Material.
Experience working with Firebase.
Experience developing backend with Node Js.
Advanced English level.
Hiring Process:

30-minute screening meeting + 15-minute English assessment.
45-minute account manager interview.";['communication', 'teamwork', 'problem solving', 'creativity', 'adaptability', 'proactivity']
85;en;"Who we are:

Kajae is a premium staff augmentation company, connecting top global talents to thriving US companies and clients offering fully remote opportunities. Our team hails from over 15 different countries, with the majority coming from the Philippines and Latin America. We pride ourselves on our tight-knit culture and strong bonds, despite working remotely across diverse time zones.


Benefits

• Competitive salary. Receive your pay in USD! 100% fully remote work setup. Work from home or work from anywhere in the world— forever! Eliminate the hassles of commuting and be around family more without missing out on life’s biggest moments.
• Healthy work-life balance. There’s nothing we prioritize more. We do regular check-ins with the team for the first few months to provide support and work advice. We also make sure you are working with only the best clients and a healthy work environment.
• Health Insurance. Covered after the third month of contract.
• Mental Health Support Program. We have an in-house mental health professional to make sure our team members have all the support they need.
• Referral Bonuses. Earn up to $100 USD for every successful candidate you refer (because you'll want to tell your friends!)
• Fun virtual events. We have monthly virtual events where everyone gets together, play fun games, celebrate special holidays, with many opportunities to win cash and exciting prizes.
• Kajae Spotlight Bonus. With stellar performance comes the Kajae Spotlight cash bonus!
• We have a tribe! Get the chance to engage with the whole team on our team’s social platform and earn coins along the way. Bid on some of our crazy auctions and get the chance to win prizes like Airpods, Apple Watch, Starbucks gift cards, shopping or experience vouchers, and more!
• Continuing Education. 100% free courses offered through our university partners in the US in order to earn academic credits for Master’s or Graduate Degree programs.
• All-Expense Paid Summits. Earn your way to our annual Kajae Summit as a reward for your outstanding performance and tenure. The last two summits were held at Palawan, Philippines and Cusco, Peru (we saw Machu Picchu together!)


Who We Are looking For:

As a Data Analyst / Google Sheets Analyzer, you will play a crucial role in the analysis and reporting of before and after traffic data, placement information, keyword indexing, and overall performance metrics for both internal tools and client reporting. This part-time position involves working on diverse projects, including enhancing AI content rewriter processes, developing client indexing reporting dashboards, and generating insightful ASIN/Keyword reports based on content inclusion.


What You´ll Do:

Transition from the Mixed Analytics API connector to a custom library for data retrieval.
Update code, formulas, and reporting to align with a new process for selecting keywords for AI content integration.
Retrieve information from S3 files reporting on ASIN/Keyword indexing status.
Develop a dashboard to present indexing information in a client-friendly report.
Coordinate with a virtual assistant to pull ASIN/Keyword/Week level data from Seller Central reports.
Organize and maintain data in a designated data source (e.g., Google Sheets).
Generate weekly reports showcasing keyword traffic changes categorized into keywords not in content, keywords in content before optimization, and keywords added post-optimization.


Requirements

Bachelor's degree in a related field (Data Science, Analytics, etc.) or equivalent work experience.
Previous experience in a similar role, preferably in e-commerce or digital marketing analytics.
Familiarity with AI content rewriters and tools used in content optimization.
Proficient in Google Sheets with advanced knowledge of formulas, scripts, and data manipulation.
Experience working with APIs for data retrieval and integration.
Strong analytical and problem-solving skills with the ability to interpret data trends.
Familiarity with traffic analysis, placement data, and keyword indexing.
Ability to effectively communicate insights and findings to both technical and non-technical stakeholders.
Collaborative mindset to work with virtual assistants and other team members.
Proven ability to manage multiple projects simultaneously and prioritize tasks effectively.
Detail-oriented and committed to maintaining data accuracy.
";['communication', 'problem solving', 'attention to detail']
86;en;"Job Description

We have an exciting and rewarding opportunity for you to take your software engineering career to the next level.

As a Software Engineer III at JPMorgan Chase within the Infrastructure Platforms Team, you serve as a seasoned member of an agile team to design and deliver trusted market-leading technology products in a secure, stable, and scalable way. You are responsible for carrying out critical technology solutions across multiple technical areas within various business functions in support of the firm’s business objectives.

Job Responsibilities

Builds relationships with internal teams and clients and is passionate about unlocking value using AI and Machine learning
Demonstrates intellectual curiosity for solving difficult problems
Is a self-starter with technical knowledge and a hands on approach to using our data assets both efficiently and effectively
Develop approaches for understanding each individual client and their behavior to deliver highly impactful ML models
Develop, plan and execute analytical projects as an individual contributor and in teams.
Executes software solutions, design, development, and technical troubleshooting with ability to think beyond routine or conventional approaches to build solutions or break down technical problems
Creates secure and high-quality production code and maintains algorithms that run synchronously with appropriate systems

Required Qualifications, Capabilities, And Skills

Formal training or certification on data mining concepts and 3+ years applied experience
Experience in: SQL; Python; AWS, GCP or Azure
Working with relational and non-relational databases; ML techniques including: regression, classification, time series, clustering, deep learning, hypothesis testing, cross validation, feature selection and feature extraction; NLP techniques including: topic modeling, entity extraction, summarization, and sentiment analysis;
Working with machine learning and natural language processing libraries such as: scikit-learn, tensor flow, pandas, nltk,; and Building data pipelines and deploying ML models and data visualization techniques.
Analytical thought leader - You can define the analytical agenda for projects, frame ambiguous business questions into analytical plans (e.g., assess data needs, source files, prepare data, create new features, evaluate quality, etc.), and execute.
Leadership - Primary focus of building something of significance. Willingness to roll up sleeves and do whatever it takes to achieve the goals.
Experience in developing, debugging, and maintaining code in a large corporate environment with one or more modern programming languages and database querying languages.

Preferred Qualifications, Capabilities, And Skills

Fluent in English";['problem solving', 'leadership', 'project management', 'proactivity']
87;en;"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, Trilogy. Have you got what it takes?

Calling AI enthusiasts! Do you dream of a world where AI not only supports but fully runs education services? Does the thought of using AI to replace human decision-making thrill you? Then listen up because we have an exciting opportunity just for you!

At Trilogy, we're on a mission to harness the power of AI to transform education. But we need someone at the helm who's not just an expert in AI integration and prompt engineering but who's also laser-focused on understanding and incorporating the latest in learning science.

Your primary task? Take the reins to transition our human-run education services to be fully automated through the power of generative AI. Sounds like the kind of challenge you're up for? Perfect!

Ready to step into the forefront of education technology? Apply today and start a journey that promises to be exciting, challenging, and super rewarding! We can't wait to hear from you!

What You Will Be Doing

Using your technical acumen and tools like OpenAI Code Interpreter, LangChain, and AWS Glue to revolutionize our educational services.
Unleashing the power of AI to make our services smarter with your knack for breaking down complex cases into component steps and designing AI prompts accordingly.
Keeping us on track, thoroughly checking and validating our IDSs to ensure our AI solutions are on point and delivering top-notch services.
Rolling up your sleeves, evaluating outputs, building prototypes, and doing whatever it takes to push the quality bar higher.

What You Won’t Be Doing

Spending your day delegating tasks. You will get hands-on in the research and data, building prompts and prototypes to find the best solutions.
Wasting time in pointless meetings. Our asynchronous culture prioritizes written communication and moves decision-making and feedback out of meetings and into the comment section.
Managing in the traditional sense. We believe the best managers lead by example, actually doing the work and setting a high-quality standard for their team.
Training LLMs. We're interested in your ability to utilize LLMs, not train them.

Basic Requirements

Senior Machine Learning Engineer key responsibilities

A grasp of AI, Large Language Models (LLMs), and prompt engineering, including Chain-of-Thought (CoT) prompting and Self-Consistency in CoT
Enough coding experience to assemble a set of prompts into a working prototype service in a single day
A mastery of self-learning. If you're the type of person who applies learning science to your own learning journey – you're our kind of people!
A process-focused mindset. It’s all about designing simple, repeatable processes that allow a system to scale.

Nice-to-have Requirements

Experience working with CodeInterpreter, LangChain, AWS Glue, and AI Orchestration tools to create 100% AI-based workflows
Prior successful experience automating manual processes";['communication', 'proactivity']
88;en;"🚀 What does Finalis do?

Finalis is the leading platform enabling the securities brokerage landscape to operate legally and compliantly. The firm delivers a white-labeled regulatory affiliation and compliance back-office solution that supports a wide range of private market dealmaking including M&A, capital raising, private placements, direct participation programs, fintech marketplaces, and alternative investment sponsors.

Finalis provides additional leverage to securities brokers with the Finalis Platform, which delivers a hassle-free deal management solution and a Marketplace that connects brokers with one another to gain insights and explore collaborations.

Launched in 2020 and growing rapidly, the SF- and NYC-based firm is on a mission to power dealmakers by building the world’s largest dealmaking platform.

Join us in disrupting the securities industry, for good. 

🌍 How does Finalis work?

We are a fully-remote company with Finalists distributed between the time zones of Eastern Standard Time and Eastern European Time .
If you’re located outside this time zone range, depending on the needs of your team, you may be requested to be available during specific hours.
Although we don’t have an official physical place to work, we promote gathering with your team or other colleagues whenever possible. 

🤝 What about your team?

We are looking for a Data Scientist to join our Connect team within the Delivery department and help us scale up our broker-dealer platform, which connects bankers across the globe to work on collaborative deals. You will be responsible for developing and implementing data-driven solutions to optimize deal origination, qualification, and assignment processes. You will also collaborate with other data professionals and business stakeholders to provide insights and recommendations based on data analysis.

✨ What will you be doing?

Collect, clean, and analyze data from various sources, such as internal databases, external APIs, web scraping, etc.
Build and deploy machine learning models to automate and improve deal origination, qualification, and assignment tasks, such as matching bankers with potential clients, scoring deals based on various criteria, and assigning deals to the most suitable bankers
Evaluate and monitor the performance and accuracy of the machine learning models and data pipelines
Analyze customer behavior data to enhance customer segmentation, targeting, and personalization strategies.
Provide recommendations for improving customer satisfaction and retention
Communicate and present the results and findings of the data analysis and machine learning models to both technical and non-technical audiences
Keep up-to-date with the latest trends and developments in data science, machine learning, and the broker-dealer industry

The Connect Data Scientist will report to the Connect Manager

💬 Who are we looking for 

Bachelor's degree or higher in computer science, statistics, mathematics, or a related field
Experience in data analysis and machine learning, preferably in the financial sector or a similar domain
Experience in working with relational and non-relational databases, such as SQL, MongoDB, etc.
Proficiency in Python, R and its data science libraries, such as pandas, numpy, scikit-learn, tensorflow, etc.
Experience in using data visualization tools and frameworks
Strong communication and presentation skills, both written and verbal
Ability to work independently and collaboratively in a fast-paced and dynamic environment
Experience in using cloud platforms and services, such as AWS, Azure, Google Cloud, etc.
You have exceptional written and spoken English
You have a minimum of 4+ years of relevant work experience
You have Google Workspace experience
You have excellent communication skills 
You have strong organizational skills 
You can handle confidential information
You have the ability to work swiftly with a high sense of urgency and be comfortable with shifting priorities and deadlines
You are a self-starter, quick learner and highly organized with attention to detail
You have the ability to follow up; know what's going on at all times and respond quickly
You are flexible, patient, persistent and have a team spirit attitude
";['communication', 'teamwork', 'attention to detail', 'analytical skills', 'proactivity']
89;en;"An NYSE-listed multinational pharmaceutical giant that has been consistently transforming the industry for over a century with their innovative solutions, is looking for a MLOps Engineer. The engineer will create and implement scalable services and tools to manage inference and training for machine learning. The company’s advanced research capabilities and wide range of healthcare products have efficiently catered to the changing needs of a global customer base. This is an amazing opportunity for candidates who are eager to work with an established organization and build a lucrative career for themselves.

Job Responsibilities:

Collaborate with cross-functional teams to develop new product features from conception to completion, including research, development, implementation, and maintenance
Develop the engineering architecture and data pipelines needed to enable large-scale machine learning systems
Build products, tools, and services from the ground up in close collaboration with internal and external stakeholders to produce high-caliber solutions
Automate the production deployment and scalability of machine learning models

Job Requirements:

Bachelor’s/Master’s degree in Engineering, Computer Science (or equivalent experience)
At least 3+ years of relevant experience as an MLOps Engineer
Extensive experience working with DevOps and Machine Learning
Ability to work well under pressure in an ambiguous environment
Excellent conversational and written English communication skills";['communication', 'teamwork', 'creativity', 'proactivity']
90;en;"About Fusemachines

Fusemachines is a leading AI strategy, talent, and education services provider. Founded by Sameer Maskey Ph.D., Adjunct Associate Professor at Columbia University, Fusemachines has a core mission of democratizing AI. With a presence in 4 countries (Nepal, the United States, Canada, and the Dominican Republic and more than 400 full-time employees) Fusemachines seeks to bring its global expertise in AI to transform companies around the world.

About the Role:

We are seeking a Data Scientist with hands-on Python experience and proven abilities to

support software activities in an Agile software development lifecycle. We are seeking a well- rounded developer to lead a cloud based big data application using a variety of technologies.

The ideal candidate will possess strong technical, analytical, and interpersonal skills. In

addition, the candidate will lead developers on the team to achieve architecture and design objectives as agreed with stakeholders.

This is a remote, contract-based role.

Responsibilities:

Work with developers on the team to meet product deliverables.
Coach developers on the team to develop scalable implementation.
Must have the ability to convert legacy SAS and SPSS code to Python or R-code.
Work independently and collaboratively on a multi-disciplined project team in an Agile development environment.
Contribute detailed design and architectural discussions as well as customer requirements sessions to support the implementation of code and procedures for our big data product.
Design and develop clear and maintainable code with automated open-source test functions such as Pytest, unittest, etc.
Lead developers on the team to meet product deliverables.
Ability to identify and solve for code/design optimization.
Learn and integrate with a variety of systems, APIs, and platforms.
Interact with a multi-disciplined team to clarify, analyze, and assess requirements.
Be actively involved in the design, development, and testing activities in big data applications.

Requirements:

Minimum of 3+ yrs of hands-on experience Python and Pyspark, Jupyter Notebooks,
Python environment controllers such as Poetry or PipEnv.
The ability to convert SAS and SPSS to Python.
Ability and desire to learn Julia and R-Code to convert legacy programs to Python and Spark for maintainability.
Familiarity with Databricks. Azure Databricks is a plus.
Familiarity with data cleansing, transformation, and validation.
Proven technical leadership on prior development projects.
Hands-on experience with a code versioning tool such as GitHub, Azure Devops, Bitbucket, etc.
Hands-on experience building pipelines in GitHub (or Azure Devops, Jenkins, etc.)
Hands-on experience with Spark.
Hands-on experience using Relational Databases, such as Oracle, SQL Server, MySQL, Postgres or similar.
Experience using Markdown to document code in repositories or automated documentation tools like PyDoc.
Strong written and verbal communication skills.
Self-motivated and ability to work well in a team.

Nice to Have:

Experience with data visualization tools such as Power BI or Tableau.
Experience with DEVOPS CI/CD tools and automation processes (e.g., Azure DevOPS, GitHub, BitBucket).
Containers and their environments (Docker, Podman, Docker-Compose, Kubernetes, Minikube, Kind, etc.)
Experience with Azure Cloud Services and Azure Data Factory.

Education:

Bachelor of Science degree from an accredited university";['communication', 'interpersonal skills', 'problem solving', 'leadership', 'project management', 'proactivity']
91;en;"Job Description & Summary
A career in our STEM line of Service, within Technology Strategy services, will provide you with the opportunity to help organisations
develop strategies that transform their technology capabilities and solve their most critical challenges. We focus on building technology enabled and agile operating models, planning their new enterprise architecture into a differentiating capability system that helps them win in the market, leveraging digital analytics to enhance the customer experience and optimising business operations, and using modern management techniques such as robotic
process automation and next generation sourcing strategies to help our clients get fit for growth.


To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.

As an Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:


Invite and give in the moment feedback in a constructive manner.
Share and collaborate effectively with others.
Identify and make suggestions for improvements when problems and/or opportunities arise.
Handle, manipulate and analyse data and information responsibly.
Follow risk management and compliance procedures.
Keep up-to-date with developments in area of specialism.
Communicate confidently in a clear, concise and articulate manner - verbally and in the materials I produce.
Build and maintain an internal and external network.
Seek opportunities to learn about how PwC works as a global network of firms.
Uphold the firm's code of ethics and business conduct.


As a Junior Consultant in DATS, you are an important member of the team supporting transaction-focused projects. In this role, you will work on data analytics assignments that span across the entire lifecycle of an M&A deal. You will support sell- and buy-side due diligence activities by preparing common data models, visualizations, automation and machine learning models. You will take ownership of tasks and work streams of international client-related projects.

Essential
Bachelor’s degree (or advanced) in Engineering, Computer Science, Statistics, Economics or related fields.
Solid knowledge of data models and/or process modelling.
High degree of analytical thinking and ability to solve complex problems.
Willingness to take ownership for tasks.
Strong communication skills in Spanish and English, verbal and written.
You can share your concepts with clarity, get to the core of issues and contribute to our success as a true team player.
Ability to work independently on qualitative and quantitative analyses.
Show self-learning abilities.
Team player who can engage in international teams.
Advanced English level, both verbal and written.
High intermediate skills in MS-Office tools (Excel, Word, PowerPoint).

Desirable
Experience in workflow tools such as Alteryx
Experience in visualization tools such as: Tableau, PowerBI or similar.
Experience in programming languages such as: SQL, Python or similar.
 Required Skills
Data Analysis, Microsoft Excel, Microsoft Power BI, Microsoft SQL Server

Optional Skills

Desired Languages (If blank, desired languages not specified)
English";['communication', 'teamwork', 'problem solving', 'leadership', 'analytical skills', 'project management']
92;en;"Want to build a stronger, more sustainable future and cultivate your career? Join Cargill's global team of 160,000 employees who use new technologies, dynamic insights and over 157 years of experience to connect farmers with markets, customers with ingredients, and people and animals with the food they need to thrive.

JOB PURPOSE AND IMPACT

The Analytics Engineer will enable analytics and reporting through the use of the data foundation and digital core competency. In this role, you will leverage the core capabilities of data management, data engineering and information products to enable timely, accurate and actionable insights to the teams. You will be a key partner to deliver the final information products that enable business value.

Key Accountabilities

Partner collaboratively with data analysts and subject matter experts to understand data needs. 
Prepare data to meet specific reporting and analytics needs. 
Build data sets to enable functional requirements for reporting and analytics use cases. 
Model, design, develop, test and implement moderately complex back end and front end structures to meet business visualization, reporting and analytics requirements. 
Assess and monitor the performance of processes, services and outcomes and support access to data assets. 
Partner with the team to develop detailed understanding of the business and offer guidance on technical solutions to solve business problems. 
Independently solve moderately complex issues with minimal supervision, while escalating more complex issues to appropriate staff. 

Qualifications

MINIMUM QUALIFICATIONS

Bachelor’s degree in a related field or equivalent experience. 
Confirmed skills to blend and organize data. 
Confirmed experience to enable data content for reporting or analytics solutions. 
Minimum of two years of related work experience. 
Experience working with SQL. 
Experience working with Power BI. 
Understanding of data concepts.";['problem solving']
93;en;"We are Kubikware™, a digital agency with 20 years of experience designing and developing web and mobile platforms, as well as video games, AR/VR apps, and AI/ML. We are headquartered in Miami, FL with a strong South American team, and have clients and partners in the US market of all sizes and verticals. Among other accolades, we are a 4-time Inc. 5000 Fastest Growing Companies in America honoree.

We are looking to expand our amazing roster with a Data Engineer that is well-versed in Python and AWS and is located in Latin America, preferably in Argentina. As we are currently working with multiple companies on many different products, we have quite a few projects where someone like you could make a difference.

We are looking for:

4+ years of experience with building out data pipelines, warehouses, and data lakes
3+ years of experience with Python
3+ years of experience with AWS and Google Cloud
Strong agile/scrum development experience
Excellent written and verbal communication skills


We offer:

Fully remote 
Long-term
20 to 30 hours a week contract
No timezone shifting
Compensation in US Dollars


If you are as excited to learn more as we are in working with you, please submit your resume and let’s be in touch!";['communication', 'project management']
94;en;"Overview

We're looking for a Data Engineer. Headquartered in Los Angeles, California, Right Balance applies the latest technology and best engineering practices to help businesses grow. We’re in the top 50 companies to watch in LA.

Engagement Details

We're a digital platform for total well-being. We help our community feel their best in body and mind through on-demand yoga, meditation, Pilates, and fitness classes with world-class teachers. Data Engineer plays an important role in our mission and vision to connect people through self-care so that, together, we can heal ourselves and our planet. Support the company's data strategy and work with the Data Team implementing data pipelines, dashboards, models, and AI/ML projects as needed. This role will be responsible for enabling data-driven decisions across the company by sourcing accurate data, building scalable infrastructure, and delivering analytics with predictive modeling. Use various methods to transform raw data into useful data systems, ultimately supporting the team to implement methods to improve data reliability, quality, and relevance.

What’s in it for you

Learn and evolve your skills using the latest and greatest technology tools in a rapidly growing company.
Learn from the best engineers. We constantly challenge the status quo and invent new ways of building a great product.
Flexible hours. Just join daily standups, sprint planning, and retrospective meetings. Other than that, you’re in control of your own schedule.
100% remote. Work anywhere, whether it is remotely in the comfort of your home, in a shared co-working space, in an RV on the beach, or while being a nomad in another country.
Work on challenging problems, innovate, impacting lots of people's lives for the better while having fun doing it.


Required Qualifications

Upper-intermediate to fluent speaking and writing English. Able to have a real-time conversation.
6+ years of full-time hands-on Data Engineering experience.
4+ years of full-time hands-on SQL experience.
4+ years of full-time hands-on Python experience.
Experience designing, developing, and maintaining Extract, Transform, Load (ETL) pipelines, ensuring data quality and integrity throughout the ETL process.
Experience managing and maintaining data warehouse performance to meet organizational requirements.
Deep understanding of conversion, retention, and engagement metrics.
Experience with data visualization tools such as Tableau, MixPanel, Google Looker.
Knowledge of data engineering and data warehousing concepts, including RedShift, Redshift Spectrum, AWS Glue, AWS Lambda.
Excellent communication and presentation skills to convey technical concepts to non-technical stakeholders.
Ability to work collaboratively in cross-functional teams and lead projects from ideation to implementation.
Experience mentoring junior data engineers and guiding best practices in modeling and analysis.
Ability to communicate clearly, and proactively with the team.
Able to respect and support cultural policies, values and processes.
Always strives to support colleagues through positive collaboration.
Ability to treat each team member with respect.
Receptive to change and open to feedback.


Nice to haves

PySpark experience.
Experience in user subscription data.
Bachelor's or Master's degree in Computer Science, Statistics, Mathematics, or a related field.
Experience in Data Science, Machine Learning, and Statistical Modeling
SAS experience.
Knowledge and experience in utilizing advanced table formatting such as Delta, Hudi, or Iceberg.
Experience building ML Models for new Product Features & Fraud.
Experience with Open Source Data Visualization tools.
Experience with Databricks, Reverse ETL.
Bachelor’s degree in Computer Science or equivalent demonstrated ability.


Frequently Asked Questions

What are your typical clients?

The majority of our clients are venture-backed startups in the growth stage. Usually, at this stage, the company already achieved a product-market fit and is looking to expand rapidly. That’s where we bring the best engineering practices, strong architecture, and the latest technologies to help companies scale.

What’s your company size?

The Right Balance team is 60+ engineers going to 100 by the end of the year. The current client size team is 340+ people. The timing is great to be a part of a rapidly growing team making meaningful contributions.

What happens if the engagement is completed?

Most of our engagements are long-term in nature. That said, if the current engagement is ramping down, we’ll present you with more long-term opportunities to transition into.

What are your core values?

Client First: we only win when our clients win. We treat client challenges as our own.

Ownership: we embrace responsibility, taking on challenges, getting them to completion, and enjoying getting things done.

Quality: we’re passionate about achieving quality outcomes by applying meticulous attention to detail.";['communication', 'teamwork', 'problem solving', 'creativity', 'attention to detail', 'leadership', 'proactivity', 'mentoring/teaching']
95;en;"Hi! This is Yalo! We are on a mission to bring conversational commerce to the world...

Remember how it used to be to interact with businesses that knew and understood you, that could recommend exactly what you needed, and that with a simple message could get you what you wanted??? Yep... neither do we. That is why at Yalo we are marrying the scale of digital commerce with the personalization and simplicity of conversations to help companies delight their users.

We know that traditional SAAS companies focus on first world problems... we don't! Having started in Latin America, our roots are in Emerging Markets and therefore we care about bringing amazing experiences to a population that traditionally has been underserved, such as the small shop owner in Brazil that is ordering online for the first time.

What we are looking for? 

We are seeking a skilled Senior Data Engineer with a deep understanding of data structures, formats, construction of ETL’s and good understanding of the implementation of data pipelines such as Kafka or Snowplow. We are looking for a person who also will be responsible for ensuring built data models, their integrity and security as well to be able to help in the maintenance of a semantic layer.

What are the responsibilities for this role?


Design, build and maintain batch or real-time data pipelines in production. 
Maintain and optimize the data infrastructure required for accurate extraction, transformation, and loading of data from a wide variety of data sources.
Build and maintain Kafka and Snowplow pipelines.
Develop ETL (extract, transform, load) processes to help extract and manipulate data from multiple sources. 
Help to design and maintain a semantic layer. 
Automate data workflows such as data ingestion, aggregation, and ETL processing. 
Prepare raw data in Data Warehouses into a consumable dataset for both technical and non-technical stakeholders. 
Partner with data scientists and data analysts to deploy machine learning and data models in production. 
Build, maintain, and deploy data products for analytics and data science teams on GCP platform.
Ensure data accuracy, integrity, privacy, security, and compliance through quality control procedures.
Monitor data systems performance and implement optimization strategies.
Leverage data controls to maintain data privacy, security, compliance, and quality for allocated areas of ownership. 
Collaboration: Work closely with cross-functional teams, product managers, and stakeholders to ensure the delivery of high-quality software.
Continuous Learning: Stay updated with the latest trends and technologies in data systems, ensuring that our systems remain state-of-the-art.


Job Requirements (Must Have)


Bachelor’s/Master’s degree in Computer Science, Information Systems, or a related field.
Minimum 5 years of Data Engineering experience ideally in cloud environments and good understanding of microservices and APIs.
Working knowledge of Kafka pipelines.
Strong experience in designing and building ETL models and data workflows.
Working knowledge on designing and implementing a BI semantic layer.
Strong foundation in data structures, algorithms, and software design.
Advanced SQL skills and experience with relational databases and database design.
Experience working with BigQuery cloud Data Warehouse and other solutions like Snowflake, Databricks. 
Working knowledge in object-oriented languages (e.g. Python, Java).
Strong proficiency in data pipeline and workflow management tools (e.g., Airflow). 
Strong project management and organizational skills. 
Excellent problem-solving, communication, and organizational skills. 
Proven ability to work independently and with a team.


Nice To Have


Expertise in open table formats like Hudi, Iceberg, Delta.
Expertise with Snowplow pipelines.
Expertise in databases like Druid, Pinot, and Elasticsearch.
Collaborative project experience in Data Governance.


What do we offer? 


Unlimited PTO policy
Competitive rewards on the market range
Remote working is available (-+3 hours CT)
Flexible time (driven by results)
Start-up environment
International teamwork
You and nothing else limit your career here";['communication', 'teamwork', 'problem solving', 'project management']
96;en;"Launchpad, a people-first technology company, is a leader in North America´s rapidly growing tech sector. Through two solutions, Launchpad supports its clients with digital transformation:

PaasportTM, our iPaaS solution, streamlines software integration and automates workflows. 
Nearshore Staff Augmentation, our managed IT staffing service, connects top IT talent across various geographical regions, bringing industry expertise to leading clients. 

Based in Vancouver, Canada, our operational footprint spans across North and South America, with a second headquarters in Santiago, Chile.

In 2023, our unwavering dedication to innovation garnered recognition as a Deloitte Technology Fast 50™ Program Company. Our clientele boasts industry leaders such as Walmart, GM, TIME Magazine, Salesforce, Tableau, Splunk, Bolt.com, Freedom House, and more.

At Launchpad, we genuinely care about our people as individuals. If you are looking for a team that values growth, drive, and passion for your craft, if you’re seeking a place to achieve your goals and dreams with fairness and integrity, then we’d love to hear from you.

Are you a skilled Augmented Reality Architect eager to explore new opportunities? We want to introduce you to our Augmented Reality Architect talent pool. While we may not have an immediate opening, we are building a selected pool of developers for upcoming projects. At Launchpad, we value innovation and expertise. By being part of our Talent Pool, you're positioning yourself for exciting opportunities in the future.

Why join our Talent Pool?

Stay ahead: By becoming a part of our Talent Pool, you'll be first in line for consideration when a suitable role opens up. 
Showcase your expertise: Share your skills, projects, and experience with us, so we can match you with the right role. 

Responsibilities:

Lead the design and architecture of augmented reality applications and experiences. 
Collaborate with cross-functional teams to define AR project requirements. 
Evaluate and recommend AR technologies, frameworks, and hardware. 
Design and implement AR solutions that align with project goals and user experience. 
Develop strategies for AR content creation, interaction, and integration. 
Optimize AR applications for performance and user engagement. 
Stay updated on emerging AR technologies, hardware, and software. 
Collaborate with developers and artists to integrate AR elements seamlessly. 
Provide technical leadership and mentorship to AR development teams. 
Participate in the planning and execution of AR projects. 

Qualifications:

Bachelor's or Master's degree in Computer Science, Information Technology, or a related field. 
Proven experience as an AR Architect or in a similar senior AR role. 
Extensive expertise in AR design, development, and implementation. 
In-depth knowledge of AR hardware, sensors, and tracking technologies. 
Proficiency in AR development tools and frameworks (e.g., Unity, ARKit, ARCore). 
Strong programming skills in languages such as C# or C++. 
Experience with 3D modeling, animation, and rendering. 
Excellent problem-solving and analytical skills. 
Ability to work independently and collaboratively in a team. 

Preferred Skills:

Certification in AR development or related field. 
Experience with virtual reality (VR) development. 
Familiarity with AR cloud technologies and services. 
Knowledge of computer vision and image recognition. 
Previous experience with AR in gaming, retail, or industrial applications. 

Why work for Launchpad?

100% remote
People first culture
Excellent compensation in US Dollars
Hardware setup for working from home
Work with global teams and prominent brands based in North America, Europe, and Asia
Training allowances
Personal time off (PTO) for vacations, study leave, personal time, etc. 
...and more!

At Launchpad, we genuinely care about our people as individuals. If you are looking for a team that values growth, drive, and passion for your craft, if you’re seeking a place to achieve your goals and dreams with fairness and integrity, then you are the future of Launchpad. Launchpad is committed to fostering a diverse and representative workforce and an inclusive work environment where all employees are respected and treated equally.

Are you ready to elevate your career at Launchpad? We want to hear your story! Contact us today.";['communication', 'teamwork', 'problem solving', 'creativity', 'leadership', 'proactivity', 'mentoring/teaching']
97;en;"Liberty Latin America´s Advanced Analytics area is responsible for delivering measurable and actionable value to all the group´s business functions (commercial, finance, operations, networks, etc..) through data and analytics-based enhancements. Those enhancements will be a mix of AI/ML models and operationalized strategies which allow the different areas to improve their decisions and actions.


Key Accountabilities



The ideal candidate will have a very strong technical background in Big Data and pipeline automation, practical experience in AWS, and will fulfil the following main functions:


Develop ETL processes to add new data sources to the data lake or any other data management environment used by the advanced analytics area
Provide data to business analytics and data science teams to ensure the optimal way to consume for the business needs.
Investigate and test new technologies that could improve our processes.
Permanently enable the Data Science team´s and Business Analytics teamwork through timely and high-quality input data delivery
Work with stakeholders including data, design, product and executive teams and assist them with data related technical issues.
Integrate and work with various data sources to provide a single, comprehensive view of the customer.
Support in orchestrating seamless experiences across marketing, sales and customer service channels.
Design and develop integrations that facilitate the transfer of data between systems.
Execution and monitoring of daily CDP routines to ensure data integrity and continuous availability.
Implementation and configuration of monitoring tools to supervise CDP performance.
Identification and rapid response to real-time alerts and anomalies to ensure system stability.
Support data integrations and data quality framework.


Preferred education/ qualifications:



Bachelor’s degree in information technology or related technical field.
Proven education or certifications in data management and cloud.
Proficient English skills.


Experience:

3+ years of proven experience in Data ETL / data engineering.
Advanced knowledge in one or more programming languages (Python, R, Scala, Java, C/C++ or similar).
Proficiency in command-line usage and scripting in Linux.
AWS Toolset (S3, Lambda, Step Functions, Glue, Athena, Redshift).
Data Catalog, Data Governance, Data Lineage is a plus.
Hands-on experience with Docker for efficient deployment of containerized applications.
Experience in BI-Reporting is a plus.
Experience with or knowledge of Agile Software Development methodologies.
Knowledge of data security best practices and the ability to implement measures to protect data integrity and privacy.
Familiarity with networking concepts, communication protocols and security in data transfer over networks.
Understand the fundamental principles of a Customer Data Platform and have experience in its implementation is a plus.


We will be happy to count with you for the new challenges of 2024. If you are interested apply and we will gladly contact you. Salary up to 4000 USD a month. The candidate can based anywhere in Latin America";['communication', 'teamwork', 'problem solving', 'project management', 'customer service']
98;en;"HundredX stands at the intersection of data intelligence and social responsibility. As a pioneer in customer dynamics and growth drivers analysis, we empower financial investors and business leaders with critical insights for strategic decisions. Our commitment extends beyond business, aiming to create meaningful impacts in society. Our innovative data-sourcing ecosystem ethically gathers consumer feedback, benefiting non-profit causes, especially in diverse and underserved communities.


Job Description: As a Data Engineer at HundredX, you will be instrumental in architecting, building, and maintaining our data infrastructure. This role involves working closely with a team of data scientists and analysts to ensure efficient data flow and management, supporting our mission of delivering high-quality insights.


Key Responsibilities:

Develop, construct, test, and maintain architectures, including databases and large-scale processing systems.
Ensure data architecture aligns with business requirements.
Implement data collection and data analytics systems for new data and data sources.
Optimize data retrieval and develop dashboards, reports, and other visualization tools.
Work closely with data scientists and analysts to improve data models and algorithms.
Ensure compliance with data governance and data quality standards.
Contribute to our ethical data-sourcing initiatives by ensuring data security and privacy.


Qualifications:

Proven experience as a Data Engineer or in a similar role.
Strong knowledge of programming languages like Python.
Expertise in SQL, data warehousing solutions, and ETL tools.
Experience with cloud services (AWS, Azure, GCP), big data technologies, and machine learning frameworks.
Strong analytical skills and problem-solving ability.
Excellent communication and teamwork skills.";['communication', 'teamwork', 'problem solving', 'creativity']
99;es;"Somos el #BancoDelHogar🏡 y nos encantaría que puedas integrar nuestro equipo de Ingeniería de Datos.

Buscamos personas apasionadas por traducir las necesidades del negocio a soluciones informáticas.

🎯 Algunos datos de tu misión en BH

Gestión de la información generada por los distintos sistemas del banco.
Creación de procesos de extracción, transformación y carga de la información a nuestro repositorio de datos onprem y entorno de datos en cloud.
Generación de métricas, hechos y dimensiones para el consumo de los usuarios del banco.
Gestión del repositorio de información del banco y.la correcta distribución de la información.
Responsables de los procesos de carga de información a los distintos repositorios de información del banco en cloud.


Requisitos


🔎 ¿Qué buscamos?

Estudiantes o profesionales recientes de carreras universitarias de sistemas, programación, científicos de datos o de otras carreras con cursos de formación afin.
Es un plus que tengas conocimiento en Data Lake, Lake house (Google, amazon o azure) y lenguaje Python.
Seran especialmente valorados conocimientos de Ingeniería de datos, herramientas o lenguaje ETL
Actitud proactiva, capacidad analitica y muchas ganas de aprender y desarrollarte. ";['proactividad']
100;es;"Analista de Datos
Funciones:
- Realizar el seguimiento de interesados en las carreras de UMAI.
- Contactar a candidatos que han solicitado información y no avanzaron la inscripción.
- Mantener actualizada la base de datos, mediante el registro correspondiente en el CRM.
- Promover mejoras en procesos, acciones de ventas y planificación.


Requisitos:
- Preferentemente, estudiantes o graduados de las carreras de Comunicación, Marketing, Relaciones Públicas o afines.
- Experiencia previa en puestos similares: atención al cliente o en call center.
- Marcado perfil comercial.
- Buena comunicación y redacción.
- Habilidad para las relaciones interpersonales.
- Se valorarán conocimientos de CRM.


Días y horarios: De lunes a viernes, presencial, de 9 a 18. 

Lugar de trabajo: Caballito - CABA
";['comunicación', 'atención al cliente']
101;en;"GlobalSource IT is currently working with a Direct Client in the US looking to add a couple of Sr. Data Engineers for nearshore support of their data platforms. They are looking for Senior resources who can help maintain and optimize current solutions and help business users/groups create designs that match their needs. This would be strong Data Modeling, Databricks, ETL, Integrations, Analysis, and Designs. Skills would primarily focus on using Azure, Spark, On-Prem, API, SQL, and Python. This would be a 100% remote opportunity for an initial 6 months to start supporting their US-based business units. 



Must have 5+ years of Data related experience and a focus on current Data Engineering responsibilities
Must have experience with Azure, SQL, ETL, Integrations, Python, and Spark
Past experience creating Databricks, new Data Models, Data Analysis and documents
Strong communication to help create designs and models will be critical for this role on top of technical efforts";['communication', 'analytical skills']
102;en;"and Future 50 companies. Listed on Inc. 5000 among the fastest-growing US companies, we are always open to talented software, UX, and data experts in the Americas, Europe, and Asia.

If you like a challenging environment where you’re working with the best and are encouraged to learn and experiment daily, there’s no better place — guaranteed! :)

What you will do

Perform analysis on existing relational and non-relational structures from various sources and business groups; 
Consolidate and Normalize the data and map to the destination data model; 
Identify new attributes, build technical requirements while mapping to the business context and usage of the attribute; 
Recommend incremental updates to data model accommodating additional data attributes and entities; 
Work with technical team implementing changes to data model; 
Evaluate the data for integrity and accuracy; feedback and work with business and technical teams to backfill gaps, if any; 
Leverage in-depth master data management and PIM knowledge combined with technical data analysis to gain significant insights to maintain and improve the master data; 
Support content syndication to all retail partners & channels (Brand.com, Retailer.com, TR, 3rd party product feeds)including basic product content, retailer attributes, images, 360 spins, videos and enhanced/A+ content, etc; 
Identify, track and report new data attributes across brands; 
Summarize and report the work progress on daily basis; 

Must haves

Bachelor’s degree in technology / engineering with computer science or related field; 
5+ years’ experience in implementing database driven projects; 
2-3 years of experience in architecting database, data warehousing or data migration; 
Must be extremely detail-oriented, deadline driven and have the ability to manage multiple projects at once; 
Tech savviness with an initiative to learn new software systems quickly; 
Strong problem-solving skills, analytical and critical-thinking skills to be able to proactively resolve issues and continuously improve results; 
Outstanding written and verbal communication skills required; 
Strong knowledge relational databases like Oracle, MySQL or Microsoft SQL Server; 
Good written and verbal communication skills required. 

Nice to haves

Experience in working with data interchange formats like JSON and bulk data formats like CSV and Excel; 
Experience in business analytics tools like PowerBI is preferred; 
Knowledge of InRiver and/or Adobe Creative Suite is a plus; 
Knowledge in eCommerce testing is added advantage. 

The benefits of joining us

Professional growth 

Accelerate your professional journey with mentorship, TechTalks, and personalized growth roadmaps.

Competitive compensation 

We match your ever-growing skills, talent, and contributions with competitive USD-based compensation and budgets for education, fitness, and team activities.

A selection of exciting projects 

Join projects with modern solutions development and top-tier clients that include Fortune 500 enterprises and leading product brands.

Flextime 

Tailor your schedule for an optimal work-life balance, by having the options of working from home and going to the office – whatever makes you the happiest and most productive.
";['communication', 'problem solving', 'creativity', 'attention to detail', 'leadership', 'analytical skills', 'mentoring/teaching']
103;en;"#poweringyouringenuity 🚀

Our mission is to bridge top-level technology companies with engineering talent from across the globe. With presence in LATAM, USA and Europe, we empower companies by providing remote engineering teams of all levels tailored to the needs of each project.

Our teams are passionate about technology and thrive on challenges. We value technical expertise and a willingness to learn new things. Each development is tailored to the needs of each project, so being passionate about learning and using new languages, tools, and frameworks is part of our DNA. Our software engineering teams focus on best coding practices to ensure readability, reusability, and scalability of our systems' designs and developments.

We are looking for passionate senior robotics / embedded systems engineers to work along with teams as a solutions architect and participate in the development of a first-of-its-kind service robotics product.

If You

Have strong experience with C++
Have solid experience with embedded systems and linux environments
Have experience working in firmware. 
Can tackle high complexity tasks independently.
Are able to engage in software design conversations.
Are able to obtain information indirectly to identify risks to the team or projects.
Provide technical specialty or architectural guidance for current and potential new projects.
Speak English & German fluently enough to work comfortably in an English/German speaking environment.

It'd Be Nice If You

Have experience working with Rust language. 
Have knowledge about machine learning and computer vision. 
Can speak in Spanish to feel comfortable working with Spanish speaking teams.

Applicants must be authorized to work in Europe without sponsorship.

Join us to be part of a dynamic community where your skills and contributions truly matter!";['proactivity']
104;en;"Mission:

Create high quality mobile experiences, working in a great place to collaborate and grow.


Top Responsibilities:

•Design, develop, support, and maintain excellent Python applications with clean code.
•Build backend data services and APIs using various design patterns
•Write unit and integration tests.


Soft skills requirements:

•We are looking for people with excellent communication skills, proactive, flexible and easy to work in a team.
•With customer orientation and high quality standards


Technical skills requirements

•+4 years solid experience as Python Developer 

•Experience with Python frameworks (e.g. Django, Flask, Bottle)
•Understanding of relational/non-relational databases and SQL
•English Level: Advanced


Optional requirements

•Familiarity with Amazon Web Services (AWS), Azure (optional) and REST API
•Knowledge of JavaScript and the modern frameworks (Angular/React) is a plus
•Knowledge and experience using DOCKER and DOCKER COMPOSE


Working conditions

Availability: Monday – Friday. 8am - 5pm (EST Time)
Remote Position 

Full Time";['communication', 'teamwork', 'proactivity']
105;es;"Descripción



En Junco Films, estamos trabajando en soluciones tecnológicas avanzadas, centradas no solo en la automatización y optimización de procesos, sino también en la integración de capacidades basadas en Machine Learning. Para fortalecer nuestro equipo, buscamos un especialista en DevOps con experiencia en entornos de alta disponibilidad, escalabilidad y con conocimientos en Linux, Servers, Kubernetes, Cloud infrastructure, Data Lakes, Databases, Performance y Latency improvement, Redis, django, authentication and authorization web y otros. Este rol demanda un dominio excepcional de herramientas de infraestructura open source y pagos.


Requisitos académicos:



Solo consideraremos a aquellos candidatos que posean como mínimo 5 años de experiencia, y/o con título universitario en disciplinas como Ciencias de la Computación, Sistemas, Ingeniería Informática o áreas relacionadas. Se valorará especialmente a aquellos que cuenten con formación o certificaciones específicas en DevOps, infraestructura o áreas afines.


En esta posición de DevOps, tendrás la oportunidad de:



- Integrar, automatizar y optimizar infraestructuras continuas.
- Administrar y optimizar VM, bases y flujos de datos.
- Gestionar el ciclo de vida de aplicaciones y servicios, especialmente los relacionados con Machine Learning y Python.
- Monitorizar la salud, rendimiento y seguridad de infraestructuras y aplicaciones. Authentication y authorization de web,
- Colaborar estrechamente con equipos de desarrollo y operaciones para mejorar la entrega de software.


Obligaciones del Cargo:



Automatización y Optimización:



- Desarrollar y mantener pipelines de CI/CD.
- Optimizar la infraestructura, garantizando alta disponibilidad y rendimiento.
- Implementar automatizaciones, incluyendo flujos basados en Machine Learning y Python.


Infraestructura como Código y Base de Datos:



- Diseñar, implementar y mantener soluciones basadas en infraestructura como código.
- Administrar y optimizar servidores y bases de datos, garantizando la integridad y eficiencia de los datos.
- Manejar flujos de datos en tiempo real.


Monitoreo y Seguridad:



- Implementar soluciones de monitoreo y alerta.
- Asegurar que todas las soluciones cumplan con estándares de seguridad.


Colaboración:



- Trabajar con equipos de desarrollo centrados en Machine Learning y Python para optimizar la integración y entrega de software.
- Asesorar sobre mejores prácticas de DevOps y herramientas relacionadas.


Documentación:



- Mantener documentación actualizada sobre procesos, sistemas y cambios realizados.
- Documentar soluciones, arquitecturas y flujos de datos implementados.


Valoramos:



- Tu habilidad con herramientas como Docker, Kubernetes, Jenkins y plataformas de nube.
- Tu experiencia en automatización, CI/CD y gestión de infraestructura.
- Tu capacidad para trabajar en un entorno ágil y en colaboración con equipos de Machine Learning y desarrollo Python.
- Conocimientos en redes, seguridad y bases de datos.
- Experiencia con microservicios, arquitecturas basadas en contenedores y Machine Learning.


Además, es un plus contar con:



- Certificaciones específicas en herramientas o plataformas DevOps.
- Familiaridad con frameworks y herramientas de Machine Learning en Python.


La selección:



Nuestro proceso de selección consta de tres fases. Primero, una tarea técnica que presentarás en una video llamada. Luego, una entrevista técnica y general por video llamada en el segundo paso. Finalmente, la tercera etapa consiste en una entrevista final que abarcará aspectos culturales, responsabilidades y ética laboral.


Junco Films ofrece un contrato inicial de 30 días, renovable mensual o trimestralmente, con un salario competitivo acorde a tu experiencia y habilidades.


Somos una organización que valora profundamente una cultura laboral sólida, ya que entendemos que esto potencia lo que podemos brindar a nuestro equipo. Actuamos activamente para fomentar la diversidad en todas sus formas en cada rincón de nuestro negocio. Trabajamos con pasión y determinación para crear con orgullo una cultura de inclusión y apertura para todos nuestros empleados.";['comunicación', 'trabajo en equipo', 'gestión de proyectos']
106;es;"Quienes Somos

Somos Telecom Argentina, una empresa de servicios digitales, telecomunicaciones y entretenimiento, líder en la región. Evolucionamos para convertirnos en una tech-co ágil, diversa y sustentable. Confiamos y creemos en las personas, como diferencial en la entrega de valor a nuestros clientes. Nos impulsa el propósito de potenciar la vida digital de nuestros clientes y de la sociedad en su conjunto.

En el equipo Advanced Analytics de la compañía, estamos sumando profesionales ML Data Engineer, con pasión por la innovación, ganas de ser protagonistas y facilidad para el desempeño en un entorno desafiante y dinámico.

Dentro de la gerencia de Advanced Analytics & Big Data, el equipo de Data Management tiene como propósito velar por la calidad y disponibilidad de los datos, promover y colaborar en la integración de todos nuestros desarrollos y nuevas fuentes de datos.

Buscamos protagonistas que se animen a:

 Usar billones de datos para diseñar y desarrollar la mejor solución de ML que se te ocurra. 
 Formar parte del diseño y la evolución de la práctica de ML OPS en la compañía. 
 Responder a distintas problemáticas de la organización en riesgo, marketing, network Analytics, finanzas, customer experience, IoT y MAS! 
 Ver los resultados y el impacto de tu trabajo. Vas a sumarte a un equipo con muchas ganas de seguir creciendo 
 Debido al volumen de datos que la compañía está manejando, estamos en un proceso muy avanzado de evolución de tecnología y es aquí donde tenemos el mayor desafío y por lo que queremos contar con vos para llevarlo a cabo! 
 Es importante que sepas y quieras desenvolverte dentro de un ámbito extenso, con muchos equipos de diferentes perfiles pero con un claro objetivo que es el de hacer una compañía Data Driven. 

#CB-1

#EB-1

Y cuenten con estas experiencias y habilidades:

 Experiencia trabajando con bases de datos SQL y NoSQL (Bigquery, Postgresql, Hive, Dynamodb, redis) - Excluyente 
 Conozcas y hayas trabajado con plataformas distribuidas (Dataproc / Hadoop), su arquitectura y funcionamiento. - Excluyente 
 Experiencia previa en desarrollo (Python, SQL) – Excluyente 
 Experiencia en herramientas de orquestación (Airflow preferentemente) 
 Experiencia en entornos cloud (GCP, AWS, Azure). Preferentemente GCP 
 Conocimientos en herramientas de Integración Continua y repositorios de código: gitlab, github, gitlab CI, github action. - Excluyente 

¿Qué tenemos para ofrecerte?

🌏 Modalidades de trabajo flexible

🏆 Bono por performance

✈️ Una semana extra de vacaciones

📱 Descuentos y bonificaciones exclusivas en nuestras marcas Personal y Flow (internet, conectividad móvil y entretenimiento) para vos y tu familia

🏥 Prepaga para vos y tu grupo familiar a cargo

📕 Acceso libre a la plataforma digital de contenidos de aprendizaje (Universo Telecom)

🎓Bonificaciones especiales en universidades de primer nivel

💪🏼 Bonificaciones en plataforma de entrenamiento y bienestar para membresía en gimnasios cercanos a tu rutina diaria.

👫 Programa de referidos con reconocimiento económico (TECOnecto)

¡Y mucho más!

¡Súmate a la transformación digital más desafiante del país!";['trabajo en equipo', 'creatividad', 'gestión de proyectos']
107;en;"Objective

This role is considered at the center of the Territorium product strategy to develop education products that are centered and powered with Artificial Intelligence. You will be part of a high performing team that works to implement the full spectrum of data analytics and data science, from data querying and data wrangling to data visualization and dashboarding for business intelligence (BI) using Microsoft’s PowerBI, to predictive analytics, machine learning, and artificial intelligence. 

 
Our Data Scientists help to define Territorium’s information strategy, architecture, and governance, get the most value from business intelligence and analytics, and implement enterprise content and data management solutions to enable business insights, reduce cost and complexity, increase trust and integrity, and improve operational effectiveness including accelerated onboarding experiences. 



Responsibilities

 Work closely with the technology team to continually evaluate company, customer, and supplier data.
 Comply with the integrity and understand the scope of the data and new data collection needs/possibilities.
 Collect data that will benefit the company and its products.
 Digest data to be able to transmit it efficiently.
 Filter unwanted information using data cleaning techniques.
 Collaborate effectively with product and development teams to implement data sets and models necessary for the company and its products.
 Combine multiple algorithms to discover patterns and trends in historical data.
 Present data using various data visualization techniques and tools.
 Investigate additional technologies and tools to develop innovative data strategies.
 Meet with growth and product stakeholders to establish realistic goals based on current data and possible future data, all aligned to company objectives.
Support in the construction of data flow (ELT/ETL pipelines).


Qualifications

Studies: M.S./M.A. in Data Science/Analytics, Statistics, Mathematics, Operations Research, Computer Science, Information Systems, Engineering, Economics, Statistics, or similar quantitative/computational discipline.
Language: Minimum B1 (proven)
Experience: Minimun 3 years of Data Science (proven)


Technical Knowledge 

Data mining, machine learning, natural language processing, data visualization.
Required: Python, SQL, ChatGPT
Must understand APIs, Deep Learning, Neural Networks, Semi-structured and unstructured data elements, Microsoft Azure, and algorithms. 
Optional (bonus): OpenAI Assistant API, Co-Pilot, Bard, BERT, PaLM, and LaMDA models.
Preferred: Prior Education Experience";['communication', 'teamwork', 'problem solving', 'creativity', 'proactivity']
108;es;"Somos una empresa nativa digital que brinda productos y servicios a clientes del rubro financiero, seguros, salud y retail.
Dedicada a la provisión de soluciones tecnológicas con fuerte foco en la innovación, diseñamos e implementamos grandes sistemas para ayudar a las organizaciones a alcanzar su máximo potencial.
Estamos buscando un Data Engineer para sumarse a un proyecto con uno de nuestros clientes más grandes.
 
Tendrás la oportunidad de:

Trabajar con profesionales de amplio conocimiento técnico que te ayudarán a superarte día a día.
Ser parte de proyectos altamente desafiantes.
Trabajar con las últimas tecnologías y continuar capacitándote en ellas.
Desarrollar tu carrera tanto técnicamente como a nivel de industria.
Ser parte de una cultura ágil, digital y colaborativa que pregona la cultura de trabajo en equipo.
Tus responsabilidades serán:

Relevar, modelar y disponibilizar información a distintos mercados para poder mejorar la eficiencia del uso de los datos en la organización y fomentar la cultura Data Driven.
Identificar y resolver problemas para garantizar integridad de los datos.
Modelado y estructuración de flujos de datos y arquitecturas de información.
¿Qué buscamos?

Al menos 4 años de experiencia en roles de Ingeniero de Datos.
Experiencia utilizando Python.
Experiencia utilizando Spark sobre entornos Databricks.
Dominio de entornos cloud con GCP y AWS.
Dominio de Azure Data Factory.
Ofrecemos:

Proyección de crecimiento, seguimiento de plan de carrera. 
Días de home office (con posibilidad de esquema 100% remoto). 
Clases de Inglés in-company. 
Capacitaciones a través de plataformas de cursos y certificaciones de Microsoft.";['trabajo en equipo', 'creatividad', 'gestión de proyectos']
109;es;"Somos una empresa de automatización de Procesos de Negocios y estamos buscando un profesional con experiencias en desarrollo en ETL's, Python y SQL (Intermedio) para un proyecto con el rol de Data Extractor


Perfil y calificaciones mínimas:
Al menos 2 años de experiencia con conocimientos sólidos en Python, SQL (Power BI y AWS opcional)
Excelente capacidad de relacionamiento con clientes y miembros del equipo de trabajo.
Disposición colaborativa y mentalidad de construcción, deseo de trabajar en una Startup
Habilidad demostrable en entrega de soluciones extremo a extremo. Desarrollo y revisión de código
Excelentes habilidades de resolución de problemas, comunicación y presentación de soluciones al cliente.
Alta atención al detalle y al trabajo con resultados de impecable precisión.
Deseo y capacidad de trabajar de forma remota con equipos multiculturales colaborando con herramientas de nube.


Detalles de la asignación:
Trabajo 100% remoto
Horario y Calendario Colombia
Contrato por prestación de servicios a 6 meses con opción de extenderse
Debe tener su computador en buen estado para brindar el servicio
Al computador se le instalará software de control y seguridad de datos
Pagamos en US$";['comunicación', 'resolución de problemas', 'atención al detalle']
110;en;"At Encora we are looking for a great talent like you to join our team as the next Principal AI Engineer 

Would you like to join our great team of engineers? Here we will tell you more about us and the role!


About the role:



Our Requirement:

10 years of experience in software engineering related fields.
Bachelor’s degree in computer science, mathematics, or related field
Proficiency in writing technical documentation and requirements in English.
Experience building RESTful microservices and deep understanding of building cloud-based services (or)
Production experience in cloud-based AI or ML systems particularly in developing and deploying machine learning models.
Experience performing pull request and code reviews and providing effective, helpful feedback to team members.
Demonstrated work with NoSQL databases. Experience with columnar, time series databases such as InfluxDB, Timestream or QuestDB (or)
Hands-on experience with Data science, Machine Learning and Statistical systems and Python packages such as pandas, scipy, scikit-learn, pytorch, dask, pyarrow, ray.
Preferred:
Graduate degree in computer science, mathematics, or related field
Experience writing unit tests as part of development cycle and using code coverage tools
Knowledge of containerization technologies, including Docker and Kubernetes
Familiarity with database, performance, profiling and tuning tools
Experience with bug and feature tracking and source control systems; Jira, Confluence, and Git


Why you will love working with us:

Work from Home/ Work from Anywhere and available workplace office space if preferred
Private medical insurance
Birthday day-off
Referral bonuses
Flexible work schedules and work patterns for a better work/life balance
Continuous technical training
Working in a Great Place To Work characterized by a horizontal and dynamic environment
Corporate recognition program
Career path that will allow you to grow with us.
Among others


About Encora:

Encora is a global company that offers Software and Digital Engineering solutions, with more than 9000 Encorians around the world. Our technology practices include Cloud Services, Product Engineering, Data Science and Engineering, Digital Experience, DevOps, Cybersecurity, Quality Engineering, among others.";['communication']
111;es;"Les traemos una oportunidad desafiante para unirse a una compañía de servicios de TIC en crecimiento y con una cartera global, como Data Engineer en nuestro equipo de Continuidad Operacional y Soporte Big Data.

La familia Getronics es un grupo de servicios de ICT que consta de las marcas Getronics y Connectis, y es propiedad de Bottega InvestCo S.à r.l. Nuestra visión es convertirnos en el socio preferido en la transformación de negocios utilizando tecnología y personas excepcionales, con un enfoque único en clientes felices al contar con empleados felices. Con casi 9.000 empleados en 23 países de Europa, Asia Pacífico, América del Norte y América Latina, la cartera de Transformación de Getronics brinda una gran capacidad y experiencia en materia de Workspace, Aplicaciones, Soluciones de Software Específicas de la industria, Gestión de Múltiples Nubes, Comunicaciones Unificadas y Servicios de Seguridad para proveer un portfolio proactivo de punta a punta al usuario digital, ya sea comercial o consumidor, tanto en el sector público como en el privado.
Getronics es el miembro líder de la Global Workspace Alliance, un modelo único que brinda a los clientes servicios de IT abarcando 110 países y con un único punto de contacto. 

La GWA ocupa el puesto número 3 a nivel mundial con un total de 7.4 millones de activos.
Getronics apoya a sus empleados para que se conviertan en expertos en su campo a través del desarrollo de una Universidad interna y un programa de reclutamiento interno.
 
Propósito del Equipo:

El equipo de Continuidad Operacional y Soporte Big Data es el responsable de construir y mantener las estructuras de datos y las arquitecturas tecnológicas necesarias para el procesamiento, ingesta e implementación a gran escala de aplicaciones que usan datos de manera intensiva permitiendo a las áreas usuarias contar rápidamente con información de valor proveniente de sus datos para el análisis de los mismos.
 
 
Propósito del Rol:

Diseñar y construir los repositorios de datos en bruto para su recolección, transformación y análisis. 
Diseñar y construir los procesos que cargarán los modelos de datos para dar soporte a la toma de decisiones.
Resolver problemas funcionales relacionados con la organización y modelado de la data para un consumo óptimo por herramientas de explotación y visualización de información.
Tener autonomía sobre los temas propios.
Interactuar con distintos áreas y equipos de la compañía
Identificar oportunidades para la adquisición de datos.
Colaborar con científicos de datos y arquitectos de datos en varios proyectos
Documentar todo conocimiento que aporte relevancia al desarrollo general del equipo o a la realización de tareas en forma mas eficiente y eficaz.
Mantenerse en capacitación constante para afrontar los desafíos de nuevas tecnologías y poder así crecer como profesional dentro del servicio.
 
 
Requisitos de Calificación / Certificación / Experiencia:

 

Como parte del equipo, aprenderás tecnologías actuales para datawarehousing y gestión de la información, comprendiendo entre otras cosas:
Tengan formación académica relacionada a sistemas o finanzas.
2 o + años de experiencia en desarrollo de DWH, datalakes o desempeñando tareas de data engineer o similar.
Deseable tener experiencia en empresas de tecnologías digitales.
Experiencia previa en tecnologías Cloud (Google, AWS, Azure, etc.)
Tener conocimientos de SQL, scripting Python, Spark o Scala.
Se valorara conocimiento en Google DataFlow, CloudFunction, DataProc, BigQuery, Composer.
Estén orientadas 100% a resultados, pero sin perder visibilidad de la calidad, escalabilidad y robustez de las soluciones aplicadas.
Cuenten con capacidad analítica y trabajen de forma metódica.
Tener ganas de crecer y desarrollarse.
Habilidades de comunicación, colaboración y presentación.
 Contamos con una plataforma educativa virtual y atendemos requerimientos del extranjero, por lo que es deseable que tengas conocimiento del idioma Inglés.";['comunicación', 'trabajo en equipo', 'proactividad']
112;en;"AgileEngine is a top-ranking provider of software solutions to Fortune 500, Global 500, and Future 50 companies. Listed on Inc. 5000 among the fastest-growing US companies, we are always open to talented software, UX, and data experts in the Americas, Europe, and Asia.

If you like a challenging environment where you’re working with the best and are encouraged to learn and experiment daily, there’s no better place — guaranteed! :)

What you will do

Perform analysis on existing relational and non-relational structures from various sources and business groups; 
Consolidate and Normalize the data and map to the destination data model; 
Identify new attributes, build technical requirements while mapping to the business context and usage of the attribute; 
Recommend incremental updates to data model accommodating additional data attributes and entities; 
Work with technical team implementing changes to data model; 
Evaluate the data for integrity and accuracy; feedback and work with business and technical teams to backfill gaps, if any; 
Leverage in-depth master data management and PIM knowledge combined with technical data analysis to gain significant insights to maintain and improve the master data; 
Support content syndication to all retail partners & channels (Brand.com, Retailer.com, TR, 3rd party product feeds)including basic product content, retailer attributes, images, 360 spins, videos and enhanced/A+ content, etc; 
Identify, track and report new data attributes across brands; 
Summarize and report the work progress on daily basis; 

Must haves

Bachelor’s degree in technology / engineering with computer science or related field; 
5+ years’ experience in implementing database driven projects; 
2-3 years of experience in architecting database, data warehousing or data migration; 
Must be extremely detail-oriented, deadline driven and have the ability to manage multiple projects at once; 
Tech savviness with an initiative to learn new software systems quickly; 
Strong problem-solving skills, analytical and critical-thinking skills to be able to proactively resolve issues and continuously improve results; 
Outstanding written and verbal communication skills required; 
Strong knowledge relational databases like Oracle, MySQL or Microsoft SQL Server; 
Good written and verbal communication skills required. 

Nice to haves

Experience in working with data interchange formats like JSON and bulk data formats like CSV and Excel; 
Experience in business analytics tools like PowerBI is preferred; 
Knowledge of InRiver and/or Adobe Creative Suite is a plus; 
Knowledge in eCommerce testing is added advantage. 

The benefits of joining us

Professional growth 

Accelerate your professional journey with mentorship, TechTalks, and personalized growth roadmaps.

Competitive compensation 

We match your ever-growing skills, talent, and contributions with competitive USD-based compensation and budgets for education, fitness, and team activities.

A selection of exciting projects 

Join projects with modern solutions development and top-tier clients that include Fortune 500 enterprises and leading product brands.

Flextime 

Tailor your schedule for an optimal work-life balance, by having the options of working from home and going to the office – whatever makes you the happiest and most productive.";['communication', 'problem solving', 'creativity', 'attention to detail', 'leadership', 'analytical skills', 'mentoring/teaching']
113;en;"It's fun to work in a company where people truly BELIEVE in what they're doing!

We're committed to bringing passion and customer focus to the business.

The Role

Proofpoint is looking for a seasoned engineer to work on designing, building and deploying large-scale threat detection services.

Our team employs cutting-edge technology to detect, analyze and produce intelligence for the latest threats from sophisticated cyber threat actors. Our detection services are the foundational components which are leveraged across Proofpoint’s cybersecurity product offerings to protect our customers from threats delivered through e-mail, social media and SaaS applications.

We are looking for an engineer with technical expertise in multiple domains, internalized critical thinking skills, passion for coding and engineering best practices.

We are a fast-paced, high-energy team where you will be given the opportunity to make a significant impact. The team has a solid engineering culture that values the craftsmanship of writing great code, enjoys learning, and solving big problems. Engineers on the team, work up and down the software stack to tackle challenges of scaling, reliability, security and usability for our users.

 

Your day-to-day

 Be member of a high-performing team of engineers responsible for building critical threat detection and analysis services
 Contribute to develop resilient and scalable components/features and get them integrated into the service
 Write custom code or integrate open source technologies and AWS services as needed to find solutions to problems
 Contribute innovative ideas for the service to stay ahead of threat actors
 Collaborate with teammates and colleagues in partner teams

 

What You Bring To The Team

 2+ years of experience developing scalable and efficient through some of the following languages Python, JAVA or GO code.
 Unit testing, cloud-native development (K8s), secure development foundations, RESTful APIs
 Experience automating service deployments (AWS or others), and test automation
 Strong motivation and ability to learn new technologies and domains
 A positive can-do attitude and bring a passion for excellence to the workplace
 Excellent collaboration and communication skills
 Knowledge of cybersecurity, malware analysis, threat detection is a bonus
 Bachelor’s degree in computer science or Information Systems

Why Proofpoint

As a customer focused and driven-to-win organization with leading edge products, there are many exciting reasons to join the Proofpoint team. We believe in hiring the best the brightest and cultivating a culture of collaboration and appreciation. As we continue to grow and expand globally, we understand that hiring the right people and treating them well is key to our success! We are a multi-national company with locations in 10 countries, with each location contributing to Proofpoint’s amazing culture!";['communication', 'teamwork', 'creativity']
114;en;"About Us

e2f helps people and machines communicate naturally regardless of language, content, or culture.

With expertise in data science - and deep roots providing agile translation in 200+ languages and dialects - e2f uniquely provides high-quality linguistic datasets of multilingual speech, text, annotation, and quality data required to help machines understand people.

e2f customers include several of the world’s most successful artificial intelligence (AI) and natural language processing (NLP) deployments.

About the Role:

e2f is seeking a talented and experienced Senior Python Engineer to enhance our dynamic team. In this role, you will focus on developing and maintaining advanced Python applications.

Responsibilities:

Developing robust Python applications using FastAPI to ensure high performance and responsiveness to requests from the front-end.
Writing comprehensive tests with Pytest to maintain code quality and reliability.
Working proficiently with SQLAlchemy for database interactions, particularly with PostgreSQL.
Collaborating with cross-functional teams to define, design, and ship new features.
Troubleshooting, debugging, and upgrading existing systems.

Requirements:

Proven experience in Python development (4+ years) with a strong understanding of FastAPI, Pytest, and SQLAlchemy.
Solid experience with AWS services such as S3, RDS, Cognito, Lambda, and SNS.
Deep understanding and experience with Machine Learning (ML) and Large Language Models (LLM).
A strong sense of curiosity and interest in Artificial Intelligence (AI), staying abreast of the latest advancements in the field.

Nice to Have:

Previous experience with LLMs and their practical applications.
Familiarity with other cloud services and technologies.
Experience in a fast-paced, agile development environment.

If you are passionate about Python development and AI, and you meet our requirements, we would love to hear from you.";['communication', 'project management', 'proactivity']
115;en;"Purpose Of The Position

We are looking for a Social Data Analyst to join our team in BA. Able to apply a combination of technical skills, analytical thinking, working together with the creative, content and brand team, proactively identify best practices and opportunity areas for our clients' communication and content platforms, and formulate analysis, learning and recommendations based on an excellent mastery of data.

Key Responsibilities


Perform data analysis and identify trends that can be turned into actionable insights.
Perform performance analysis and social listening reports (weekly, monthly, quartely, campaign or specific)
Partner with the creative team and client to define their reporting and analytics needs and develop solutions for delivering against them.
Monitor daily conversation related to the brands to detect communication opportunities or potential crises.
Champion the use of data and analytics technologies to drive efficiencies in the production and consumption of management reporting
Assist in development and delivery of new data sets, metrics and analytics content to support creative strategic decisions.
Set up tools and processes for effective data management.


Requirements


3+ years of experience in content and digital data analysis
Experience performing reports and social listening for social networks.
Platform and data knowledge (FB, TW, IG, YT, TT, Twitch)
Experience with data visualization tools
Knowledge of Google Suite, Facebook suite and Ads Manager, Youtube Analytics
Experience in Social Listening tools (Brandwatch, social studio, sentione, brand24 or similar).
Strong Excel, PowerPoint skills
Strategic thinking focused on results";['communication', 'problem solving', 'creativity', 'analytical skills']
116;en;"Halo Media LLC Exciting Job Opportunity⭕

🤝 Position: 𝗔𝗻𝗴𝘂𝗹𝗮𝗿 & 𝗡𝗼𝗱𝗲.𝗷𝘀 𝗧𝗲𝗰𝗵 𝗟𝗲𝗮𝗱 
🌍 Location: 𝗔𝗹𝗹 𝗟𝗔𝗧𝗔𝗠 𝗖𝗼𝘂𝗻𝘁𝗿𝗶𝗲𝘀
🏡 Work Mode: 𝗙𝘂𝗹𝗹𝘆 𝗥𝗲𝗺𝗼𝘁𝗲

𝗔𝗯𝗼𝘂𝘁 𝗬𝗼𝘂:
🌐 2+ years in a technical leadership role in software development.
🤝Strong leadership skills, adept at managing and motivating teams.
🧠 Demonstrated experience in technical strategy, policies, and procedures.
💻 Tech Stack: MongoDB, Express, Angular, Node.js.
🗣 Advanced English level.";['leadership']
117;es;"Buscamos desarrollador web con competencias para programar y configurar sitios web basados en Drupal, con el fin de proporcionar soluciones basadas en requerimientos de nuestros clientes en Colombia y LATAM.

Ubicación: Remoto

Categoria:

REQUISITOS
Formación
Formación en sistemas de información, programación web o afines.
Experiencia
Experiencia laboral comprobada de mínimo 1 año de trabajo con Drupal.
Técnicos
Programación orientada a objetos en PHP
Lenguajes HTML, CSS y JavaScript
Desarrollo de módulos personalizados Drupal
Conocimiento en construcción de plantillas y/o temas en Drupal
Conocimiento del motor de plantillas Twig
Familiaridad con herramientas y conceptos Drupal tales como Drush, Drupal Console, Configuration Management, Views, etc.

FUNCIONES:
Proveer desarrollo, programación y configuración en la creación de aplicaciones personalizadas y actividades de soporte.
Participar en la planificación o estimación de proyectos con el jefe de proyecto y Líder Técnico.
Analizar las especificaciones escritas y configurar las funcionalidades dentro del CMS Drupal según el alcance del proyecto.
Realizar prueba unitaria de los requerimientos asignados para garantizar la funcionalidad adecuada, antes de solicitar despliegues a la rama de desarrollo.
Comunicar estimaciones y cambios en el alcance.
Configurar, personalizar e integrar software de código abierto (OSS) para clientes.
Desarrollar e implementar componentes a la medida en Drupal.
Ofrecer soluciones técnicas a los clientes y al líder técnico cuando se produzcan desafíos o imprevistos durante los sprints de desarrollo.
Documentar los componentes desarrollados.
Mantener y apoyar los sistemas existentes y sitios web.
Proporcionar capacitación técnica y apoyo a los clientes cuando sea necesario.
Proporcionar comentarios oportunos a los gerentes de proyectos, arquitectos y clientes sobre el estado de las tareas asignadas.
Asistir a reuniones de seguimiento para dialogar con las partes interesadas del proyecto sobre el estado de los entregables asignados.
Mantener una comunicación fluida con el equipo de trabajo asignado para alcanzar los objetivos propuestos.
Mantenerse informado sobre las mejores prácticas de desarrollo de Drupal y los estándares de codificación.

COMPETENCIAS:
Comunicación abierta
Trabajo en equipo
Vocación de servicio
Orientación al cliente
Planificación y coordinación
Responsabilidad y compromiso

PLUS:
Conocimientos en twig
Manejo de Frameworks JS (angular, vue, react)
Conocimientos en otros frameworks PHP
Idioma Inglés

OFERTA Y BENEFICIOS:
Trabaja de forma remota desde casa a tiempo completo.
Contrato a termino indefinido con todas las prestaciones legales.
Salario competitivo.
Plan de incentivos y compensación.
Plan carrera con oportunidades de crecimiento y desarrollo profesional.
Capacitación y formación permanente.
Suministro de portátil Apple o Linux con los recursos que necesita para hacer su trabajo al más alto nivel.";['comunicación', 'trabajo en equipo']
118;es;"Precisamos de programadores en el equipo de Teipe! Imprescindible conocimientos demostrables en SHOPIFY.

Tareas

Desarrollar y mantener ecommerce
Crear y actualizar las páginas web de la tienda en línea
Implementar y optimizar las funcionalidades del carrito de compras y el proceso de pago
Colaborar con el equipo de diseño para mejorar la apariencia y la usabilidad del sitio web
Realizar pruebas de rendimiento y solucionar problemas técnicos relacionados con el comercio electrónico
Mejoras funcionales según convenga
Requisitos

absoluto conocimiento de Shopify. No vamos a tomar entrevistas de programadores que no conozcan esta plataforma! (sorry!: )

Beneficios

Trabajo super flexible, remoto, bien ambiente laboral de todo el equipo. Todos trabajamos en remoto! no importa donde estés!";['trabajo en equipo']
119;es;"Buscamos desarrollador web PHP con competencias para dar soporte a sitios web, con el fin de proporcionar soluciones basadas en requerimientos de nuestros clientes en Colombia y LATAM.

Ubicación: Remoto

Categoria:

REQUISITOS

Formación
Formación en sistemas de información, programación web o afines.


Experiencia
Experiencia laboral comprobada de mínimo 2 años en desarrollo PHP.


Técnicos
Programación orientada a objetos en PHP
Lenguajes HTML, CSS y JavaScript
Diseño responsive / Mobile First
Manejo de herramientas de desarrollo en browsers
Manejo de herramientas de control de versiones
Funciones:
Brindar soporte preventivo, correctivo y evolutivo a las aplicaciones web personalizadas basadas en php.
Analizar las especificaciones escritas y configurar las funcionalidades dentro del CMS Drupal según los requerimientos de los clientes.
Realizar prueba unitaria de los requerimientos asignados para garantizar la funcionalidad adecuada, antes de solicitar despliegues a la rama de desarrollo.
Comunicar estimaciones y cambios en el alcance en la asignación de tareas.
Configurar, personalizar e integrar software de código abierto (OSS) para clientes.
Ofrecer soluciones técnicas a los clientes y al líder técnico cuando se produzcan desafíos o imprevistos durante la realización de las tareas.
Documentar los componentes desarrollados.
Mantener y apoyar los sistemas existentes y sitios web.
Proporcionar capacitación técnica y apoyo a los clientes cuando sea necesario.
Proporcionar comentarios oportunos a los gerentes de proyectos, arquitectos y clientes sobre el estado de las tareas asignadas.
Asistir a reuniones de seguimiento para conocer el estado de los entregables asignados.
Mantener una comunicación fluida con el equipo de trabajo asignado para alcanzar los objetivos propuestos.

Competencias:
Comunicación abierta Trabajo en equipo
Vocación de servicio
Orientación al cliente
Planificación y coordinación
Responsabilidad y compromiso

Plus:
Conocimientos en twig
Manejo de Frameworks JS (angular, vue, react)
Conocimientos en otros frameworks PHP
Idioma Inglés

Beneficios:
Trabaja de forma remota desde casa a tiempo completo.
Contrato a termino indefinido con todas las prestaciones legales.
Salario competitivo.
Plan de incentivos y compensación.
Plan carrera con oportunidades de crecimiento y desarrollo profesional.
Capacitación y formación permanente.
Suministro de portátil Apple o Linux con los recursos que necesita para hacer su trabajo al más alto nivel.
";['comunicación', 'trabajo en equipo']
120;en;"About Telnyx

Telnyx is an industry leader that's not just imagining the future of global connectivity—we're building it. From architecting and amplifying the reach of a private, global, multi-cloud IP network, to bringing hyperlocal edge technology right to your fingertips through intuitive APIs, we're shaping a new era of seamless interconnection between people, devices, and applications.

We're driven by a desire to transform and modernize what's antiquated, automate the manual, and solve real-world problems through innovative connectivity solutions. As a testament to our success, we're proud to stand as a financially stable and profitable company. Our robust profitability allows us not only to invest in pioneering technologies but also to foster an environment of continuous learning and growth for our team.

Our collective vision is a world where borderless connectivity fuels limitless innovation. By joining us, you can be part of laying the foundations for this interconnected future. We're currently seeking passionate individuals who are excited about the opportunity to contribute to an industry-shaping company while growing their own skills and careers.

The Role

We’re looking for a Frontend JavaScript engineer with familiarity building real-time experiences using WebRTC technologies, to create the next version of our audio & video SDK. Telnyx’s WebRTC SDKs are building blocks from which customers create voice, video and data applications of the future, leveraging our world-wide network for the highest quality real-time streaming. Consider your favorite video and live streaming platforms -- these are the customers we’ll be able to capture with the state-of-the-art WebRTC SDK that you help us build.

In This Role You Will

Build robust JavaScript SDKs for our WebRTC product, with a focus on developer experience and ease of use.
Create proof of concept and sample projects that leverage all the capabilities of our SDKs. 
Collaborate with product managers, designers, and frontend engineers to develop drop-in UI solutions to exciting real-time streaming use cases.
Architect composable, intuitive components that our engineers can assemble to build powerful software workflows that drive their businesses.
Work with latest React, ES6, and HTML/CSS to build and maintain new Telnyx features.
Maintain the testing infrastructure to ensure high-availability of our services and the stability of our codebase.

You’d Be A Good Fit If You Have

Deep experience with other modern frontend JavaScript frameworks and technologies under WebRTC -- as interaction with STUN/TURN servers, audio & video codecs, and cross-browser compatibility.
You take a thoughtful approach to decision making, knowing when to move fast and when to long-term optimize.
You want to work in a fast-paced, product-driven environment.
You keep up to date with the latest frontend technologies and patterns, and enjoy sharing what you’ve learned.
You’re interested in creating proof of concepts with cutting edge technologies.
You have strong UX sensibilities and enjoy polishing the details that matter, without falling into rabbit holes.

What It Is Like To Work At Telnyx

Telnyx is a complex machine with a simple purpose: connect people. We are an intelligent telephony engine, the beating heart of the Telnyx service that routes data along the pathways of our global, private network. We are drop-in APIs for hooking applications into our products, and an administrator portal that puts unprecedented control of configuring and orchestrating the Telnyx service into our customers’ hands.

We’re also an organization of industry experts and engineers focused on solving problems and building solutions. We’re a concierge customer success team and a 24/7 support team. We’re a communications partner, focused on agile and endless innovation, not a telecom slogged in antiquated processes and anti-competitive regulation. We keep the conversation going: the always-on, omnichannel, enriched conversation that the modern world demands.

Communications are coming untethered from devices, and more and more, they’re migrating into our everyday platforms: our social media, our work applications, and our collaboration tools. But, that move started before there was infrastructure to support it—the modern internet will never offer the speed and consistency that real-time communications require. So, we built a network that does and a cloud platform tuned for real-time communications at every layer. Telnyx is the connective matrix, a worldwide nervous system, a high-speed rail tunneling through the information superhighway. We’re the foundation for calls, texts and messaging today, for the internet of things, augmented reality and “communitainment” tomorrow, and for whatever enterprising imaginations can dream up after that.

We’re Telnyx. We’re the future of communications.

At Telnyx, we're looking for people with passion, grit, and integrity. You're encouraged to apply even if your experience doesn't precisely match the job description. Your skills and passion will stand out—and set you apart—especially if your career has taken some extraordinary twists and turns. At Telnyx, we welcome diverse perspectives and people who think rigorously and aren't afraid to challenge assumptions. Join us.

Bring Your Authentic Self to Telnyx

Telnyx is committed to building a team full of diverse perspectives, various backgrounds and different minds. We believe diversity drives innovation. We are committed to building a culture where difference is valued and creating avenues of equity for underserved groups. While we are still a work in progress, we are actively seeking folks who are passionate about building a place of belonging for everyone. 

We're looking for people with passion, grit, and integrity. We believe in transparency, proactivity, and mutual respect. We provide the high-grade tools that help you do your best work, and keep up the collaborative habits that help everyone stay in the loop. No matter where you're based or which team you’re on, you’re plugged in, supported, and helping to shape the future of communications. 

You're encouraged to apply even if your experience doesn't precisely match the job description. Your skills and passion will stand out—and set you apart—especially if your career has taken some extraordinary twists and turns. At Telnyx, we welcome diverse perspectives, rigorous thinkers and assumption challengers. Are you ready to join us?";['communication', 'teamwork', 'creativity', 'project management', 'proactivity']
121;es;"SOPORTE INFORMATICO JR (PRESENCIAL - URUGUAY)
Búsquedas IT
Montevideo, Departamento de Montevideo

Descripción de tareas:

Mantenimiento y reparación del equipamiento informático de la compañía.
Soporte técnico y operativo a nivel de usuario, administrando computadoras, telefonos, redes u otros.
Realiza escalamiento y seguimiento de accidentes hasta su resolución.
Atención y soporte a usuarios internos y externos. Infrastructura, Data Center, Soporte, Help Desk, crear usuarios, mail, VPN, Active Directory, DNS.
Intalación y mantenimiento de CCTV IP. Instalación de aplicaciones propias y a terceros.
Gestión, administración y verificación de los respaldos de la empresa.
Actualizacion del antivirus. Administración de red (networking)
Administración de la infrasteuctura virtual. Administración de red wifi y DataCenter
Instalación y mantenimiento de telefonia IP, PBX, Troncales SIP, internos.
Instalación y mantenimiento de PC, Impresoras, Servidores, Control de accceso.

Requerimientos

Operador PC, Redes TCP/IP, Windows y Servidores Windows, Linux.
Estudiante de informatica.
Trabajo en equipo, ordenado, metodico, dispuesto a insertarse en el equipo.
No requiere experiencia laboral previa, si conocimiento tecnico.
Ofrecemos

La oportunidad de sumarte a una de las empresas líderes del sector médico.

Modalidad de trabajo presencial 35 h semanales de lunes a viernes de 14 a 20 h y sábados de 08 a 13 h.
Beneficios completos para la persona.
Servicio de comida y telefonía para el colaborador/a";['trabajo en equipo']
122;es;"Trasnacional Educativa con presencia en todo Latam solicita Programdor Jr

Tareas

Funciones del cargo:
Efectuar análisis y programación de sistemas para satisfacer necesidades requeridas por los clientes internos y externos de la organización, manteniendo un enfoque de calidad en los servicios, trabajo en equipo y de satisfacción al cliente.

Funciones y Responsabilidades Principales:
1\. Realizar análisis y diseño de sistemas nuevos, mejoras a sistemas existentes y mantenimiento a aplicaciones y procesos en producción para los sistemas de la empresa, de acuerdo a los procedimientos técnicos, operativos y de seguridad establecidos.

2\. Brindar soporte técnico relacionado al análisis de información técnica y mantenimiento de aplicaciones como apoyo a la comunidad de usuarios de los servicios de la empresa, según sea requerido.

3\. Brindar soporte técnico en pruebas y/o certificaciones de instituciones, servicios, procesos y dispositivos, nuevos o existentes, realizadas por el área de Control de Calidad y en conjunto con el usuario final o proveedores.

4\. Brindar soporte técnico en el desarrollo o ejecución del plan de contingencia de los sistemas de la empresa

5\. Sugerir procedimientos operativos y de control para optimizar el funcionamiento de las aplicaciones.

6\. Brindar apoyo en el proceso de instalación de programas, nuevos o existentes o en la configuración de programas o equipos realizados por el área de Infraestructura Tecnológica.

7\. Organizar y ejecutar todas las actividades necesarias para el ingreso de nuevas instituciones a los servicios que ofrece la empresa.

8\. Elaborar y/o actualizar la documentación requerida según los procedimientos de documentación establecidos para los programas que desarrollen o modifiquen.

9\. Reportar cualquier falla, anomalía técnica, operativa o de seguridad a las áreas correspondientes, asegurando su debido seguimiento y solución.

10\. Informar y/o instruir al personal del área de Procesos, u otro personal involucrado, en las instalaciones, cambios y mejoras hechas a los sistemas y equipos.

11\. Apoyar en la solución a problemas encontrados en el ambiente de producción.

12\. Reportar periódicamente a su supervisor inmediato sobre las funciones realizadas.

13\. Realizar cualquier otra función relacionada al puesto.

FACTORES DETERMINANTES

Contenido Organizacional

COMPLEJIDAD DE FUNCIONES

Nivel de dificultad, complejidad o diversidad de las funciones desempeñadas en el puesto.

Mediano (Mediano Alto)

IMPACTO ORGANIZACIONAL

Forma en la que impactan las funciones del puesto a la organización en el logro de sus metas estratégicas.

Mediano (Mediano Alto)

Conocimientos y Habilidades

Requisitos :
Conocimientos básicos requeridos para ocupar el cargo y realizar las funciones en forma eficiente. Pueden ser adquiridos por medio de la educación formal y/u otros medios de instrucción.

Licenciatura en el área correspondiente, o tener conocimientos técnicos y/o administrativos equivalentes. Pleno dominio del idioma inglés.

EXPERIENCIA

Experiencia requerida para hacer el trabajo de manera satisfactoria. Puede ser adquirida dentro y fuera de la Institución. Incluye experiencia total o indispensable.

De 3 a 5 años

Requisitos

CONOCIMIENTOS TÉCNICOS ESPECIALIZADOS

Conocimiento técnico especializado requerido para cumplir determinadas funciones. Por ejemplo: Programación y análisis de sistemas, manejo del moodle imprescindible , familiarización. con crm , html , ccs, JavaScript y MySQL

De 1 a 3 años en puestos que requieren de conocimiento técnico especializado.

Beneficios

Capacitacion , rapida posibilidad de ascenso ., excelente ambiente laboral.

Si tienes el perfil postulate ahora!!!";['comunicación', 'trabajo en equipo']
123;es;"IQVIA™ es The Human Data Science Company™ enfocada en utilizar la información y la ciencia para ayudar a los clientes del cuidado de la salud a encontrar mejores soluciones para sus pacientes. IQVIA™ ofrece un amplio rango de soluciones que aprovecha los avances en la información, tecnología, análisis de datos y el ingenio humano para impulsar el cuidado de la salud hacia adelante.
En IQVIA™ buscamos una #BraveMind que será responsable de:
Responsabilidades:
Desarrollar, analizar y depurar aplicaciones/programas usando VB.Net;
Manejar código vía control de versión;
Leer e interpretar documentos de requerimientos para crear programas estables y eficientes;
Crear requerimientos y documentación técnica;
Crear y ejecutar queries SQL para el análisis de data;
Mantener comunicación oral y escrita con clientes internos;
Habilidades/Skills:
VB.NET;
HTML, SQL Server, SQL Server Management Studio (SSMS), JavaScript;
Ingles : nivel intermedio (valorado)
Conocimiento de procedimientos almacenados; experiencia en roles similares de 6 meses a un año .
Capaz de trabajar en equipo;
Excelente capacidad analítica y de resolver problemas;
Buenas habilidades de comunicación verbal y escrita
IQVIA is a leading global provider of advanced analytics, technology solutions and clinical research services to the life sciences industry. We believe in pushing the boundaries of human science and data science to make the biggest impact possible – to help our customers create a healthier world. Learn more at
https://jobs.iqvia.com";['comunicación', 'trabajo en equipo', 'habilidades analíticas']
124;es;"Project Manager JR- Búsqueda Activa
Grupo Mirgor
Capital Federal, Buenos Aires
Ubicación
Capital Federal, Buenos Aires
En Mirgor desafiamos la tecnología, para convertirla día a día en experiencias que generen progreso y bienestar para las personas.
A través de nuestras unidades de negocio Manufactura, Retail, Logística, Distribución, Innovación, Agropecuario y Servicios, y áreas soporte, hacemos que las cosas sucedan.

Si te interesa formar parte de una compañía de vanguardia en innovación tecnológica, ¡esta es tu oportunidad!

¡Súmate a nuestro equipo como Project Manager JR para el área de IT!

Te invitamos a construir futuro siendo responsable de:
Responsable del seguimiento de proyectos, planificando las distintas actividades para la ejecución en tiempo y forma de los objetivos trazados.
Identificar los riesgos asociados al proyecto, clasificarlos y planificar las acciones de mitigación
Facilitar las reuniones internas entre áreas de forma sistemática y ordenada.
Presentación a los clientes externos del avance del proyecto.
Seguimiento económico-financiero en la ejecución del proyecto.
Buscamos a una persona que tenga pasión por más, y que cumpla con los siguientes requisitos:

Estudiantes finalizando la carrera de Ingenieria (cualquier especialidad).
Contar con experiencia en gestión de proyectos dentro de la industria automotriz. (Excluyente).
Dominio intermedio/avanzado de idioma ingles. Debera mantener conversaciones telefónicas y escritas con proveedores (Excluyente).
Experiencia en Metodologias Agiles (Deseable).
Conocimiento en Jira (Deseable).
Disponibilidad para viajar.
Buscamos una persona con actitud, orientación al cliente, proactividad, buena comunicación, relaciones interpersonales, trabajo en equipo, adaptabilidad a los cambios, capacidad de trabajo metódica y ordenada.
Lugar de Trabajo: Caba (Belgrano)
Horario flex: 08 a 17hs/09 a 18hs
Modalidad: Hibrido (3 Home Office- 2 presencial)
En Mirgor somos conscientes del rol que cumplimos en el mundo y actuamos en consecuencia, promoviendo la ética y el respeto en todas nuestras relaciones con las personas y con las comunidades en las que nos encontramos.
¡Súmate a esta gran experiencia!";['comunicación', 'trabajo en equipo', 'creatividad', 'adaptabilidad', 'gestión de proyectos', 'proactividad']
125;es;"QA Engineers JR
Somos Lamansys, una organización especializada en brindar soluciones de software personalizadas utilizando procesos ágiles, sofisticados y las tecnologías más innovadoras del mercado; nos especializamos en hacer crecer el negocio de nuestros clientes combinando investigación, desarrollo y calidad de servicio.

Trabajamos todo el ciclo de vida del desarrollo del software, bajo metodologías ágiles y equipos interdisciplinarios.

En esta oportunidad, nos encontramos en la búsqueda de QA Engineers JR para sumar a nuestro increíble equipo

Las personas ideales para esta posición, deberán contar con conocimientos en tecnologías de la información y estar interesadas en desarrollar sus habilidades en el área de QA.

La posición es 100% remota, con horarios flexibles, por lo que puedes planificar tu día y trabajar desde cualquier lugar

Si te consideras detallista, disfrutas de los retos y trabajas para ser un poco mejor cada día, esta es una buena oportunidad de crecimiento para vos.

En este rol, serás responsable de asegurar la calidad de las aplicaciones web desarrolladas por nuestros equipos de desarrollo, prevenir fallos y procurar su correcto funcionamiento de principio a fin.

Funciones específicas:
Aprender y familiarizarse con las metodologías ágiles, herramientas de pruebas manuales y automatizadas.

Participar en el diseño y elaboración de planes de prueba para diferentes proyectos.

Ejecutar pruebas manuales y automatizadas para validar el correcto funcionamiento de las funcionalidades y características de los productos o servicios.

Identificar, documentar y reportar los problemas o errores encontrados en el proceso de prueba.

Participar en reuniones de equipo para discutir el progreso del proyecto.

Coordinar con el equipo de desarrollo para garantizar que los problemas se solucionen de manera oportuna.

Ayudar a mantener y mejorar nuestros procesos de control de calidad.

Generar informes escritos y documentación de las pruebas realizadas a largo del desarrollo.

Formación Académica:
Estudiantes de Tecnicaturas Universitarias en Desarrollo de Aplicaciones Informáticas, Ingeniería en Sistemas o carreras afines.

Requerimientos:
Inglés intermedio avanzado (B2).

Conocimientos en programación orientada a objetos.

Conocimientos en base de datos relacionales.

Soft Skills:
Compromiso

Comunicación efectiva

Honestidad

Organización

Orientación al detalle

Proactividad

Resolución de problemas

Responsabilidad

Trabajo en equipo";['comunicación', 'trabajo en equipo', 'resolución de problemas', 'creatividad', 'atención al detalle', 'proactividad']
126;en;"Are you interested in teaching next-gen AI models about biology and deepening your domain expertise?

Earnings:

Hourly rate: US$ 21.00 - 29.00, depending on your level of expertise
About the Opportunity: 

Cutting-Edge Projects: Work on challenging projects that push the boundaries of AI.
Flexibility: Set your own hours and work remotely from any of the approved locations! 
Weekly payouts: Get paid conveniently on a weekly basis.
Professional growth: Gain valuable experience in AI while honing your writing skills and deepening your domain expertise.
Collaborative environment: Join a team of talented professionals who share your passion for AI and biology.
Duration: Variable depending on project length, flexible hours.
Location: Remote from India, the Philippines, Mexico, or Argentina.
Responsibilities:

You will train AI models by crafting and answering questions related to your field.
You will evaluate and rank responses generated by AI systems.
You will use your domain expertise to assess the factuality and relevance of text produced by AI models
Qualifications:

Bachelors, Master, PhD or equivalent proficiency in Biology or related-field.
Complete fluency in the English language is required.
Excellent attention to detail and ability to maintain consistency in writing and spot errors or inconsistencies.
Excellent written and verbal communication skills in English.
Nice to Have:

Professional writing experience as a researcher, journalist, technical writer, editor, or similar roles.
Teaching credentials.
Solid subject matter knowledge in other biology subfields.
Interest in AI and machine learning concepts.";['communication', 'adaptability', 'attention to detail', 'mentoring/teaching']
127;es;"Acerca del empleo
En Baufest queremos mejorar la vida con tecnología, por lo que nos encontramos en la búsqueda de un Python Developer para sumar a nuestro equipo.
 
Responsabilidades:

 

Desarrollar y probar la calidad de las unidades de software con el fin de generar entregables que cumplan con los estándares, plazos, especificaciones técnicas y requisitos funcionales definidos en la plataforma tecnológica del servicio.
Participar activamente en las ceremonias que se lleven a cabo dentro del servicio.
Colaborar con la formación de los compañeros del equipo técnico ayudando a conseguir las competencias necesarias en el servicio.
Capacitarse en nuevas tendencias y metodologías para mejorar sus habilidades técnicas.


Requisitos Principales:



Experiencia con venv, el entorno virtualizado de python.
Experiencia con mocks conocer unittest-mock, pytest-mock o mockito.
Pruebas unitarias
Conocimiento en pytest o unittest, si se usa o se va a cambiar al framework fastapi.
Conocimiento en el uso de testclient combinado con pytest.
Conocimiento de los módulos de pytest, unittest o tox.
Calidad de código: pylint y en IDEs el uso de sonarlint.
Seguridad de código: bandit.
Performance test: locust.
Base de datos relacional, postgresql: psycopg2.
Base de datos no relacional.
Mongo: pymongo.
Cassandra: cassandra-driver.
(para temas de logging): elasticsearch.
Temas de token validacion de token, jwt y demás: pyjwt, python-jose, jwcrypto, authlib.
Request o llamadas a terceros.
Conocimiento del módulo requests (llamadas sincronas)
Conocimiento del módulo aiohttp (asíncronas).
Conocimiento de asyncio
Microservicios
Conocimiento en el ciclo de vida de un microservicio, saber qué implicaciones tiene a realizar cambios, como probarlos, con qué módulos, uso de github Action.
A nivel de framework, conocimiento en flask, fastapi o starlite que se usa para generar apis, en especial fastapi.
Request o llamadas a terceros: Conocimiento del módulo requests (llamadas síncronas) y conocimiento del módulo aiohttp (asíncronas), conocimiento de asyncio.


Requisitos Deseables:



Metodologías Agiles como SCRUM y Kanban
Comunicación oral y escrita en inglés.
Capacidad analítica";['comunicación', 'trabajo en equipo', 'gestión de proyectos']
128;en;"Jr. Machine Learning Engineer
The Plum Tree Group
Required Skills
Bachelor’s degree in Computer Science, Mathematics, Statistics, or a related field with a focus on machine learning or artificial intelligence.
Knowledge of machine learning frameworks (like TensorFlow, PyTorch) and Python. Familiarity with data processing and visualization tools.
Strong analytical skills with the ability to collect, organize, and analyze significant amounts of information with attention to detail and accuracy.
Strong problem-solving skills and the ability to work under pressure.
Good communication skills to effectively collaborate with team members and stakeholders and to present findings and models clearly.
Eagerness to learn new technologies and adapt to changing technological landscapes.
Ability to take initiative and find solutions in a proactive manner.
Ready to work in a fast-paced environment with changing priorities.";['communication', 'teamwork', 'problem solving', 'adaptability', 'attention to detail', 'proactivity', 'fast-paced environment']
129;es;"Descripción de la compañía



GMAT Maestro es una institución educativa con visión de futuro que ofrece clases diseñadas para identificar y superar las debilidades del GMAT de los estudiantes. Nuestro objetivo es aprovechar el poder de Machine Learning para que la preparación de exámenes sea efectiva y eficiente para todos. Estamos ubicados en Parque Patricios, pero ofrecemos flexibilidad para algunos trabajos remotos.


Descripción del rol



Buscamos un científico de datos junior para trabajar por contrato. El científico de datos junior será responsable de analizar datos, crear modelos estadísticos, desarrollar visualizaciones de datos y realizar análisis de datos. Este es un rol híbrido que implica trabajar desde nuestra ubicación en Parque Patricios, CABA, así como algo de trabajo remoto.


Calificaciones requeridas



Estudiante avanzado o recién graduado en Ciencia de Datos/Análisis de Datos o campo relacionado
Experiencia en el uso de Python (bibliotecas básicas generalmente utilizadas para el aprendizaje automático, como numpy, pandas, matplotlib, seaborn, scikit-learn, etc.)
Experiencia con Excel o GSheets
Experiencia en estadística.
Experiencia en inspección, preparación de datos y modelado de aprendizaje automático.
Fuertes habilidades de comunicación y colaboración.


Cualificaciones deseadas



Habilidades de visualización de datos.
Excelentes habilidades analíticas y de resolución de problemas.
Experiencia en enseñanza/aprendizaje.
Nivel intermedio alto o superior de inglés.
Experiencia con PNL (Procesamiento del Lenguaje Natural)
Conocimiento de sistemas de bases de datos (SQL Server/MySQL)
Experiencia con API de datos";['comunicación', 'trabajo en equipo', 'resolución de problemas', 'adaptabilidad', 'habilidades analíticas']
130;es;"Te presentamos la oportunidad de unirte a DeepAgro, una empresa que está revolucionando el agro con Inteligencia Artificial, como Machine Learning Engineer. Si buscas un desafío emocionante, esta posición te brinda la oportunidad de desarrollar modelos de IA.
DeepAgro desarrolla soluciones que buscan ser parte del futuro del agro a nivel mundial. Nuestro producto SprAI, le permite a los productores agropecuarios reducir hasta un 90% el uso de herbicidas, a partir de detectar, ubicar y controlar cada maleza del campo en tiempo real. No sólo es capaz de tomar y procesar imágenes de alta calidad en diversos escenarios y situaciones, sino que también puede recopilar información de distintos sensores ubicados en la máquina, almacenarla y subirla a la nube desde cualquier punto.


Entre las responsabilidades del puesto, se encuentra la de mejorar continuamente el modelo de detección de malezas en cultivos, mantener los modelos actuales de detección de malezas en cultivos, realizar pruebas para analizar rendimiento de modelos, investigar nuevas arquitecturas e implementaciones para modelos de detección de maleza sobre distintos cultivos y otras aplicaciones de inteligencia artificial. También podrá ser responsable del prototipado de proyectos de inteligencia artificial para nuevas soluciones.


Buscamos una persona con base en conocimientos en Inteligencia Artificial y Machine Learning. Lenguajes de programación, específicamente C++ y/o Python. Comprensión de estructuras de datos, modelado de datos y arquitectura de software. Conocimiento profundo de matemáticas, probabilidad, estadísticas y algoritmos. Excelentes habilidades de comunicación. Habilidades analíticas y de resolución de problemas excepcionales. Uso de frameworks para desarrollo de IA (PyTorch, sklearn). Uso de librerías de procesamiento de datos e imágenes (OpenCV, NumPy, Pandas, Airflow).
Además, es deseable que cuente con habitualidad con metodologías ágiles, uso de software de versionado de código, conocimiento de herramientas cloud (AWS, Azure, IBM), experiencia en investigación, conocimiento de procesamiento de imágenes clásico. Se valorará experiencia en el puesto, ya sea en la industria o de forma independiente, de desarrollo de modelos así como de manejo de datos a gran escala.


El perfil es para una persona con estudios universitarios finalizados, o en marcha, en carreras tales como Ingeniería Electrónica, Licenciatura en Ciencias de la Computación, Matemáticas o afines. Con capacidad de aprender y aplicar conceptos y herramientas de forma dinámica, de trabajar en equipo y, a veces, de forma independiente, con enfoque en el cliente.
En DeepAgro te vas a encontrar con muchos beneficios, que van desde almuerzos gratuitos en oficina, bonos anuales por objetivo, créditos mensuales en Pedidos Ya, Gympass, clases de idioma, y mucho más.


Si queres formar parte de esta gran transformación, postulate a esta búsqueda o envíanos tu CV a rrhh@deepagro.com.ar, lo estaremos esperando.";['comunicación', 'trabajo en equipo', 'resolución de problemas', 'proactividad']
131;es;"Somos una empresa mexicana en búsqueda de Desarrolladores PHP Laravel Senior para trabajar de manera remota, titulado en Sistemas Computacionales, Tecnologías de la Información o afín, entre 25 a 50 años, con al menos 5 años de experiencia con PHP y Laravel
Se trata de una oferta de trabajo con un sueldo competitivo y el trabajo es totalmente a distancia. Utilizamos herramientas tales como Workpuls/Insightful para el monitoreo del trabajo.
Tendrás por misión el desarrollo de los nuevos sistemas, ayudar en la ampliación de los sistemas existentes, así como la creación de nuevas funcionalidades con el objetivo de incrementar y fidelizar la base de usuarios.
Nos gusta sentirnos orgullosos de nuestro trabajo, de aprender, de enfrentarnos a dificultades que parecen imposibles de resolver… y resolverlas. Nos gusta que nos guste el trabajo (además del ingreso $$$) y que sea posible ver el impacto positivo que creamos, destacando y creciendo como empresa, desarrolladores, personas.
Debes ser una persona que entiende y está interesada en la dinámica de un equipo remoto, apasionada en el desarrollo con PHP y Laravel. Debes sentirte cómodo con la toma de decisiones y autonomía, listo para trabajar en un entorno donde nada es constante, con variables y retos nuevos cada día.
No es un trabajo para quienes buscan rutinas o una zona de confort, donde todo se repite mes con mes, proyecto tras proyecto y cliente tras cliente. Aquí cada día y cada tarea es diferente. Esta es una oportunidad única en donde tu trabajo impactará a miles de personas.
Somos una empresa pequeña (por elección) donde decidimos que desarrollar para nuestros usuarios, no lo que decide un cliente. No somos una maléfica agencia de reclutamiento, una empresa que desarrolla para otras empresas o un gris corporativo donde eres un número.
Experiencia y habilidades requeridas:
• PHP sin frameworks, al menos 5 años
• Laravel, al menos 5 años
• MySQL
• Javascript
• JQuery
• Ajax
• HTML5 y CSS3
• Inglés básico
Buscamos que realices desarrollo estructurado y orientado a objetos. Todas las actividades se desarrollan bajo el enfoque Lean y ciclos de iteraciones de build-measure-learn.
Habilidades opcionales:
• Bootstrap
• AngularJs
• Inglés más que básico
Beneficios
• Días inhábiles y esquema de vacaciones similar al de México (12 días el primer año con incrementos anuales)
• Aguinaldo similar al de México
• Pago neto, en USDT
Qué esperamos de ti
Que seas autónomo y autodidacta; que te guste estar aprendiendo constantemente y compartas tu conocimiento, así como tus ideas. Que te apasione lo que haces, siendo detallista, ágil y autocrítico.
Que ya seas un buen desarrollador y que quieras ser todavía mejor";['gestión de proyectos', 'proactividad', 'orientación a resultados']
132;en;"WHAT TO DO:

develop and improve tools for Virtual Production in Unreal Engine 5, Maya, Substance Painter, Blender, Nuke, After Effects editors;
develop custom plugins for these editors;
develop plugins for deep integration of various web services;
develop and improve the company’s microservices;
to ensure the stability and quality of the development of tools, the quality of architecture and code;
develop and improve existing tools, develop and implement new ones;
realistic assessment of tasks taking into account possible risks;
write technical documentation;
participate in the formation and development of the team (conducting technical interviews, live-coding);
interact with project managers, artists, UI/UX designers, game designers, analysts and programmers.


WE EXPECT:

confident knowledge of Python, practical experience - 3 years;
knowledge of Python data structures, algorithms for working with them;
following the principles of DRY, SOLID;
ability to write clean, understandable code using EP-8, Docstrings;
preparation of documentation in English;
understanding of the principles of OOP, experience in their application;
knowledge of design patterns;
knowledge of data formats (JSON, YAML, XML, etc.);
experience with Git.


IT WILL BE A PLUS:

experience with Digital Content Creation tools (DCC): Unreal Engine, 3Ds Max, Maya, Blender (experience writing plugins, knowledge of the API of the listed programs);
experience with Perforce, ShotGrid;
experience working with PyQt, PySide or other GUI frameworks.


WHY WORK WITH US?

become a part of a highly skilled, passionate, and friendly team that loves what they do;
create innovative and unique games for the global market, and work with well-known existing IPs, worlds and stories;
ability to work full time remotely;
opportunities for advancement - we’ll work with you to help achieve your desired career trajectory;
assistance with computer equipment or other necessary hardware;
competitive salary;
yearly company retreats with our amazing team;
reimbursement for gym membership (if desired).";['communication', 'creativity', 'proactivity']
133;en;"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, Trilogy. Have you got what it takes?

We do not believe in hiring consultants. Imagine taking your car to the repair shop for a fix, and they only have a consulting mechanic who recommends that you replace your carburetor. Who is going to do that? When we have problems with our business, we value people who can fix them and not just make pitch decks and general recommendations.

Trilogy has an ever-growing portfolio of 100+ software products spanning multiple industries and geographies. We have different business units that own these products, and Trilogy hosts business-critical functions such as finance, customer support, and hiring for all these business units. In this role, you will work with the senior stakeholders across the business units and functions to help solve the problems they face. For instance, you may work with the SVP of Finance to hire qualified accountants in one week and work with the CIO to evaluate M&A targets using a scalable model the following week.

We are looking for exceptional problem solvers and brilliant thinkers to join our team. Unlike other companies, we do not judge you by arbitrary stamps, such as whether you graduated from X university or worked in a 'top' consulting firm. We want problem solvers who enjoy taking on the challenge of solving complex problems, dive deep to find the root causes of these issues, and propose and implement fixes that solve them.

If you are interested in solving complex problems while gaining unparalleled experience working across business functions and units, apply today!

What You Will Be Doing

Conduct research and analysis to find creative solutions for issues with real business impact.
Use generative AI tools to execute assignments aiming to improve the efficiency of different functions, such as Operations, Hiring, M&A, and more.

What You Won’t Be Doing

Provide high-level insights and recommendations - we want implementers, not consultants.
Develop theoretical scenarios and try to sell potential insights to management - you will work on real business problems with real solutions.

Data Analyst Key Responsibilities

Solve the most complex issues facing the organization.

Basic Requirements

Bachelor’s degree in a quantitative field (e.g., Economics, Finance, Mathematics, Engineering)
5+ years of work experience
Experience using generative AI tools to boost productivity at work
";['creativity', 'proactivity']
134;en;"We are looking for a self-starter engineer who loves building new products 0 to 1 in a fast-moving environment. Aptford helps businesses streamline their internal operations, sales and marketing with custom AI solutions. Our mission is to empower 10 000 founders to grow their businesses, bringing value with empathy and speed.

We are looking for someone with immense potential and obsession with learning & skill development. To start, you must be an engineering jack-of-all-trades, with proven experience in system design, full-stack development and end-to-end product delivery. As the team grows, you will have the opportunity to specialize over time or take on management responsibilities.

You must be self-motivated, data-obsessed, and accept nothing less than the highest levels of performance from yourself and your team.

What This Job Entails

Own the development of new customer-facing AI solutions and product experiences
Talk to users to understand their problems and design solutions to address them
Collaborate with a cross-functional team of engineers, product managers & designers
Optimize applications for speed and scale

Your background looks something like:

3+ years of relevant engineering experience at tech and product-driven companies
Proficiency with JavaScript / TypeScript, React, Next, and other web dev
Proficiency with some backend language (we use Python and Rust)
Some experience with relational databases like Postgres/MySQL
Interest in AI/ML (direct experience not required)
Willingness and skill to take extreme ownership of a solution in an environment where scopes are sometimes have unclear shape and may have competing priorities or deadlines";['communication', 'interpersonal skills', 'teamwork', 'proactivity']
135;en;"TrovaTrip is a trip management platform dedicated to making travel safer and more accessible to all. Our mission is to enhance lives via meaningful connections, learning, and exploration. Our team of travel enthusiasts lives out our mission daily.


We are determined to make TrovaTrip one of the best places to work by building trust, respecting personal boundaries, valuing work-life balance, and promoting diversity and inclusiveness. Our commitment to instilling a true sense of ownership and belonging among every employee that will transcend from delighting customers to creating true market value. We believe in an environment where creativity, curiosity, and continuous improvement are encouraged and nurtured.


If you seek to develop your career and thrive off a fast-paced, collaborative culture where you can make an impact, you may be a fit for this position within the TrovaTrip Analytics Team.


About this position:

TrovaTrip is searching for a Data Engineer to be a member of our Analytics Team! We are looking for an experienced data practitioner who is driven to increase the impact of analytics and insights across the organization. You’ll have the opportunity to help the organization level up on the data maturity curve and build models using our best-in-class data stack and leadership support, including FiveTran, Snowflake, dbt, and Sigma.

Your work will directly support Analytics projects and have a measurable impact on the organization. Through ongoing operational learning, you’ll develop an expert understanding of the organization’s data, and partner closely with the Product Engineering, Sales, Marketing, and Trip Experience departments and report to the Director of Analytics.


Essential Functions:

Establish a best-in-class analytics program and further our data-driven philosophy for growth and expansion
Mature the department using data modeling best practices, version control, and documentation for async collaboration
Design and build new ELT-based data models using SQL and dbt
Write reusable SQL queries and transformations to support iterative analytics and data science development
Collaborate with analysts and stakeholders to understand business requirements
Guide the ongoing development of data technical needs and data architecture
Join data from disparate sources to enable better dashboarding, in particular sales/marketing data and events data for product analytics
Design and build internal and consumer facing dashboards for sales, marketing, trip experience, and product engineering.
Design and build centralized reporting data model (Kimball, Inman, lakehouse, vault, etc) that is agile and self-service oriented.
Build automations for manual data processes and improve data literacy amongst department groups.

Qualifications:

Advanced SQL abilities and experience with python, R, etc.
Understanding of the modern data stack and experience managing it - from Insights tools like Sigma, Looker, QuickSight to more under-the-hood infrastructure like BigQuery, Segment, dbt, FiveTran, Airbyte, Snowflake, etc.
A passion for travel, learning and exploration
Strong work ethic and works well independently
Efficiency and ability to succeed in a fast-paced environment
Experience working cross-functionally with various teams internally
Integrity and a dedication to excellence
Exceptional async and collaborative communication skills
Track record of achieving success
Tenacity and resilience

Perks and benefits

Direct contractor mode with Trovatrip Inc. - Payment 100% in USD.
Stock options.
Opportunities to grow your career along with the company.
Flexible hours
USD$1,000 for equipment
Multicultural work environment.";['communication', 'interpersonal skills', 'teamwork', 'problem solving', 'creativity', 'leadership', 'project management', 'fast-paced environment']
136;en;"Finalis is building the largest investment banking platform in the world.

What does Finalis do?

Finalis is the leading platform enabling the securities brokerage landscape to operate legally and compliantly. The firm delivers a white-labeled regulatory affiliation and compliance back-office solution that supports a wide range of private market dealmaking including M&A, capital raising, private placements, direct participation programs, fintech marketplaces, and alternative investment sponsors.

Finalis provides additional leverage to securities brokers with the Finalis Platform, which delivers a hassle-free deal management solution and a Marketplace that connects brokers with one another to gain insights and explore collaborations.

Launched in 2020 and growing rapidly, the SF- and NYC-based firm is on a mission to power dealmakers by building the world’s largest dealmaking platform.

Join us in disrupting the securities industry, for good.


How does Finalis work?

We are a fully-remote company with Finalists distributed between the time zones of Eastern Standard Time and Eastern European Time .

If you’re located outside this time zone range, depending on the needs of your team, you may be requested to be available during specific hours.

Although we don’t have an official physical place to work, we promote gathering with your team or other colleagues whenever possible.


What about your team?

We are looking for a Data Scientist to join our Connect team within the Delivery department and help us scale up our broker-dealer platform, which connects bankers across the globe to work on collaborative deals. You will be responsible for developing and implementing data-driven solutions to optimize deal origination, qualification, and assignment processes. You will also collaborate with other data professionals and business stakeholders to provide insights and recommendations based on data analysis.


What will you be doing?

Collect, clean, and analyze data from various sources, such as internal databases, external APIs, web scraping, etc.

Build and deploy machine learning models to automate and improve deal origination, qualification, and assignment tasks, such as matching bankers with potential clients, scoring deals based on various criteria, and assigning deals to the most suitable bankers

Evaluate and monitor the performance and accuracy of the machine learning models and data pipelines

Analyze customer behavior data to enhance customer segmentation, targeting, and personalization strategies.

Provide recommendations for improving customer satisfaction and retention

Communicate and present the results and findings of the data analysis and machine learning models to both technical and non-technical audiences

Keep up-to-date with the latest trends and developments in data science, machine learning, and the broker-dealer industry


The Connect Data Scientist will report to the Connect Manager


Who are we looking for

Bachelor's degree or higher in computer science, statistics, mathematics, or a related field

Experience in data analysis and machine learning, preferably in the financial sector or a similar domain

Experience in working with relational and non-relational databases, such as SQL, MongoDB, etc.

Proficiency in Python, R and its data science libraries, such as pandas, numpy, scikit-learn, tensorflow, etc.

Experience in using data visualization tools and frameworks

Strong communication and presentation skills, both written and verbal

Ability to work independently and collaboratively in a fast-paced and dynamic environment

Experience in using cloud platforms and services, such as AWS, Azure, Google Cloud, etc.

You have exceptional written and spoken English

You have a minimum of 4+ years of relevant work experience

You have Google Workspace experience

You have excellent communication skills

You have strong organizational skills

You can handle confidential information

You have the ability to work swiftly with a high sense of urgency and be comfortable with shifting priorities and deadlines

You are a self-starter, quick learner and highly organized with attention to detail

You have the ability to follow up; know what's going on at all times and respond quickly

You are flexible, patient, persistent and have a team spirit attitude

Bonus Track!

Capital Markets / Investment banking knowledge or interest


What do we offer?

100% Remote work (Work from wherever you want!)

Competitive USD salary

High-Speed Internet expenses allowance

Generous Paid time-off (Vacation Time!)

Additional 17 Flex Days (to use in national holidays or personal matters)

Professional Growth Benefits in our E-Learning Platform (Coursera) (take your skills to the next level!)

People Team Partner (to target your roadblocks and customize an action plan for your career path)

Buddy Program

Virtual After-Office Activities

Diverse Culture & Inclusive environment

Why work with Finalis?

We are a fast-paced startup which will enable you to develop skills quickly and work in an entrepreneurial culture where pushing limits and taking risks is everyday business. As we have Finalists from different countries and cultures, we encourage our team members to develop their soft skills, boosting their ability to adapt themselves to different backgrounds.

Finalis’ core values:

Embodying the trust we deliver

Exercising extreme proactivity

Redefining, uniting and evolving

Showing passionate engagement

Practicing Stewardship

Finalis provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity, or gender expression. We are committed to a diverse and inclusive workforce and welcome people from all backgrounds, experiences, perspectives, and abilities.

";['communication', 'teamwork', 'adaptability', 'attention to detail', 'analytical skills', 'proactivity']
137;en;"Intermediate Data Engineer
Remote - Canada | Contract

Our Canadian client is a fast-growing Snowflake Services Partner working across North America, looking for an Intermediate Data Engineer to join their team for a long-term contract opportunity. It’s a fully remote engagement, successful candidates can be located anywhere in Latin America, but you'll need to be available for significant overlap with PST time zone. You'll need to have good English communication skills (at least B2 or higher) for this role.

This is a great opportunity for an up-and-coming data engineer interested in training, certifications, and gaining international experience and English language proficiency. We want to hear from you if you are ready to break boundaries in the data world, work with innovative clients, and love to continuously research and learn new technologies like DBT, Airbyte and Airflow, or Terraform.

What you’ll get to do:

Interact with internal technical teams and potentially purely business-oriented clients: analyze customer data requirements and participate in crafting suitable solutions.
Collect data from various sources, such as databases, APIs, and logs, and integrating it into a unified data ecosystem.
Perform data cleaning, structuring, and transformation tasks to ensure that raw data is in a usable format for analysis.
Manage databases, including creating and maintaining database structures, optimizing query performance, and ensuring data consistency and integrity.
Work on developing and maintaining ETL pipelines, which involve extracting data from source systems, transforming it into the desired format, and loading it into a destination database or data warehouse.
Monitor data quality, implement data validation checks, and troubleshoot data-related issues to maintain data accuracy and reliability.

Requirements:

Passion for data and engineering excellence
Strong command of SQL, hands-on experience in writing complex queries, optimizing database performance, and designing efficient database schemas.
Proven skills in creating and maintaining data models, including conceptual, logical, and physical models.
Intermediate level ETL experience
Familiarity with data warehousing concepts and have hands-on experience with data warehousing solutions such as Amazon Redshift, Google BigQuery, or Snowflake (preferred)
Intermediate level hands-on experience building data solutions using a variety of traditional and/or big data technologies
Software engineering experience is an asset

What we work with:

Modern Data Workflows (DBT, Airflow, Prefect, Dagster)
CI/CD (Gitlab, GitHub Actions, Jenkins)
Programming Languages (Python, JavaScript, Kotlin or Java)
Big Data Platforms (Apache Spark, Presto, Amazon EMR)
Cloud Data Warehouses (Snowflake Data Cloud, Google BigQuery, DataBricks Lakehouse, Azure Synapse)
Databases (SQL Server, PostgreSQL, MySql, Oracle, Vertica)
Container Management Systems (Kubernetes)
Visual Analytics (Tableau, Looker, PowerBI)
Artificial Intelligence / Machine Learning (Amazon Sagemaker, Azure ML Studio)
Streaming Data Ingestion and Analytics (Amazon Kinesis, Apache Kafka)

Of Note:

You will be required to provide you own laptop, basic software tools, and cell phone.
Completed background checks will be required prior to the start date if you are selected as a winning candidate.
You will be required to sign our standard non-moonlighting agreement prior to the start date if you are selected as a winning candidate.
As a winning candidate you will be required to disclose your engagement with DevEngine as a primary client on your professional LinkedIn profile.

While we strive to respond to all applicants, please understand that due to the high volume of applications we receive, it may not be feasible to provide individual feedback or responses to every candidate. Rest assured that your application will be carefully reviewed and considered. We appreciate your understanding and interest in joining our team.";['communication', 'problem solving', 'creativity', 'proactivity']
138;es;"Si sos un apasionado por el análisis de datos y por transformar ideas en soluciones, te invitamos a formar parte de nuestra compañía con visibilidad internacional y un excelente ambiente laboral!


Buscamos a una persona proactiva, con gran capacidad analítica, que se enfrente a problemas de marketing y decida la mejor forma de atacarlos. El profesional deberá ser capaz de implementar y trabajar con librerías de Python para Data Science y crear prototipos que luego sean llevados a producción.


Responsabilidades:

Gestionar las relaciones con los clientes para hacerlos parte del equipo, comprendiendo sus necesidades para traducirlas en soluciones analíticas.
Desarrollo de la solución al proyecto punta a punta en Python, con un ojo puesto en la estandarización del código para poder atacar problemas diversos.
Diseño del camino hacia el MVP: definición de plazos, tareas y entregables para cada proyecto del que la persona sea dueña.
Implementación de prototipos de cara interna a la compañía que estarán en el roadmap de producto.
Experiencia programando en Python con las siguientes librerías (pandas, numpy, seaborn/matplotlib, scikit-learn, pytorch/tensorflow, nltk).
Experiencia con desarrollo de código en Github.
Capacidad para bajar conceptos complejos a tierra con ejemplos sencillos.
Se valorará:

2-4 años de experiencia laboral en problemas de Machine Learning y Data Science.
Graduados de las carreras de Matemática, Física, Estadística, Ciencias Económicas o carreras afines.
Conocimientos de industria de marketing.
Experiencia atacando problemas de optimización o en reconocimiento de imágenes.
Curiosidad intelectual y alta capacidad analítica.

Beneficios:

Valoramos tu tiempo fuera del trabajo, flexibilidad full para trabajar desde donde quieras, lo importante es que cumplas las metas de cada proyecto en el que participes

Tu cumpleaños es especial para nosotros, nuestro regalo es que te tomes el dÍa libre para que lo disfrutes como quieras.

Capacitaciones constantes para que puedas continuar creciendo profesionalmente con estudios complementarios.

Somos un equipo multicultural, conformado por personas de 12 nacionalidades diferentes.";['adaptabilidad', 'habilidades analíticas', 'proactividad']
139;en;"AI Applications Engineer

Have you created a successful career in tech and are ready to do something good with your skills and experience? If yes, then join us in our Earthshot mission to build open source digital systems and solutions to battle environmental threats.

OpenEarth Foundation (OEF) is a California-based research and deployment non-profit developing open innovative technology to increase planetary resilience and avoid a catastrophic climate crisis.

We are building open infrastructure in support of the UNFCCC Paris Agreement, solutions in city decarbonization, climate finance, biodiversity tracking and other critical climate challenges.

We are a diverse international team, working remotely with a network of collaborators and partners globally, from the United Nations to climate tech startups.

We have funding and a team of experts focused on Earth systems and digital innovation.

Your mission, should you choose to accept it:

As an AI Applications Engineer at OpenEarth Foundation, you will be key to our mission of applying the latest AI technologies to the world’s most important task: slowing and halting the climate crisis. You will leverage your AI engineering, software experience and analytical skills to build open digital infrastructure, with a particular focus on our newly launched .

You will work with a team of software professionals to create software that helps track the world’s progress towards the Paris Agreement goals, and improve the data infrastructure for analyzing this. A key implementation to develop is the use of AI Large Language Models (LLM) to harmonize climate datasets and drive interoperability across carbon and Environmental, Social and Corporate Governance (ESG) disclosure standards. Everything we do is Open Source, shared freely with the world, to maximize the impact of our work.

The position is remote and international candidates are welcome, but prefer those willing to work with time zones compatible with PST. We're working on the planet's problems and we need the planet's best people to fix them.

The following requirements describe our ideal candidate. If you don't meet some of the requirements, you're encouraged to apply anyway.

Essential Functions and Specific Duties:

Design, architect and build AI functionality for OpenEarth’s Open Source software, such as CityCatalyst
Use large language model (LLM) APIs to make software more intelligent and efficient
Participate in AI technical process standards for the foundation
Build machine learning models for deriving insights from images, videos, documents or structured data
Other:

Actively participate in team building and culture development activities at OpenEarth Foundation
Encourage and mentor Open Source contributors to OEF’s projects
Represent OEF at standards discussions about the use of AI for improving global climate accounting
Qualifications & Experience Requirements:

Bachelor’s degree in computer science or related field, or equivalent work experience
Minimum 3 years of total experience in professional software development, with 2 shipped products
Minimum 1 years of experience in machine learning models, with 1 shipped project
Minimum 1 year of experience creating API clients, with 1 shipped project
At least 1 shipped product using an LLM API, such as ChatGPT
Other competencies:

Training, updating and maintaining an LLM model, such as LLaMA
Use of low-code/no-code and other tools for rapid prototyping
Using Python for data pipelines and data analysis
Using NodeJS for building APIs
Using Git for collaboration and version control
Using Jira for project management
Using Docker and Kubernetes for software deployment
Interpersonal skills:

Ability to work in an agile software development environment with a mix of data engineers, full-stack developers, product designers and product managers
Ability to estimate and track time worked on tasks
Communications skills necessary to document and present work
Other qualities:

Dedication to fighting climate change
Focus on impact
Interest in non-profit work
Compensation and benefits:

This position is full-time with compensation of $60,000-$90,000 (USD) per year, commensurate with location and experience
Open Earth offers unlimited paid time off, paid holidays and paid sick leave
You will work remotely within a dynamic and international environment
We celebrate our achievements during our in-person annual team retreat";['communication', 'interpersonal skills', 'teamwork', 'problem solving', 'creativity', 'analytical skills', 'project management', 'proactivity', 'mentoring/teaching']
140;en;"Launchpad, a people-first technology company, is a leader in North America´s rapidly growing tech sector. Through two solutions, Launchpad supports its clients with digital transformation:

PaasportTM, our iPaaS solution, streamlines software integration and automates workflows. 
Nearshore Staff Augmentation, our managed IT staffing service, connects top IT talent across various geographical regions, bringing industry expertise to leading clients. 

Based in Vancouver, Canada, our operational footprint spans across North and South America, with a second headquarters in Santiago, Chile.

In 2023, our unwavering dedication to innovation garnered recognition as a Deloitte Technology Fast 50™ Program Company. Our clientele boasts industry leaders such as Walmart, GM, TIME Magazine, Salesforce, Tableau, Splunk, Bolt.com, Freedom House, and more.

At Launchpad, we genuinely care about our people as individuals. If you are looking for a team that values growth, drive, and passion for your craft, if you’re seeking a place to achieve your goals and dreams with fairness and integrity, then we’d love to hear from you.

Are you a skilled Artificial Intelligence / Machine Learning specialist eager to explore new opportunities? We want to introduce you to our AI/ML specialist talent pool. While we may not have an immediate opening, we are building a selected pool of professionals for upcoming projects. At Launchpad, we value innovation and expertise. By being part of our Talent Pool, you're positioning yourself for exciting opportunities in the future.

Why join our Talent Pool?

Stay ahead: By becoming a part of our Talent Pool, you'll be first in line for consideration when a suitable role opens up. 
Showcase your expertise: Share your skills, projects, and experience with us, so we can match you with the right role. 

What are we looking for?

At least 2 years of proven experience as an AI/ML Specialist or Data Scientist, with a focus on machine learning. 
Proficiency in programming languages such as Python or R for machine learning and data analysis. 
Strong understanding of machine learning algorithms, deep learning, and statistical modeling. 
Experience with machine learning frameworks and libraries (e.g., TensorFlow, PyTorch, scikit-learn). 
Familiarity with data preprocessing techniques and tools. 
Knowledge of data visualization and exploration tools (e.g., Matplotlib, Seaborn). 
Strong problem-solving skills and attention to detail. 
Excellent communication skills and the ability to work collaboratively in a team environment. 
Experience with cloud platforms (e.g., AWS, Azure, GCP) for AI/ML deployment is a plus. 
Advanced english level

Why work for Launchpad?

100% remote
People first culture
Excellent compensation in US Dollars
Hardware setup for working from home
Work with global teams and prominent brands based in North America, Europe, and Asia
Training allowances
Personal time off (PTO) for vacations, study leave, personal time, etc. 
...and more!

At Launchpad, we genuinely care about our people as individuals. If you are looking for a team that values growth, drive, and passion for your craft, if you’re seeking a place to achieve your goals and dreams with fairness and integrity, then you are the future of Launchpad. Launchpad is committed to fostering a diverse and representative workforce and an inclusive work environment where all employees are respected and treated equally.

Are you ready to elevate your career at Launchpad? We want to hear your story! Contact us today.";['communication', 'creativity', 'attention to detail', 'analytical skills', 'proactivity']
141;es;"Nuestra misión como equipo de Machine Learning Engineering es diseñar y construir sistemas de machine learning que entreguen continuamente una experiencia agradable y segura para nuestros comerciantes.

Estamos buscando Machine Learning Engineers talentosos/as y motivados/as para unirse a nuestro equipo y ayudarnos a cumplir nuestra misión.

Como equipo, nos esforzamos por diseñar y construir sistemas que sean confiables, escalables y mantenibles. Además, tenemos propiedad de extremo a extremo del ciclo de vida de machine learning.

Algunas de las características que promovemos dentro del equipo son la propiedad, la curiosidad, la transparencia y una fuerte cultura de escritura. Esperamos que ayudes a dar forma a nuestra dirección de producto y fortalezcas la cultura del equipo.

Colaborarás estrechamente con equipos de producto, data science y data engineering, ingenieros de software y diseñadores para lanzar productos impactantes que puedan mejorar la vida de millones de personas.

Jugarás un papel clave en el diseño y construcción de uno o varios sistemas:

Un sistema de recomendación para impulsar la personalización en todo el ecosistema. 
Un sistema de clasificación de búsqueda para mostrar los resultados más relevantes a nuestros clientes internos y externos . 
Un sistema de prevención y detección de fraude en tiempo real. 
Una plataforma de experimentación para crear, ejecutar y administrar experimentos controlados en la aplicación y otros canales. 

Requirements

Requisitos:

No es indispensable que tengas experiencia profesional en un rol de Machine Learning Engineer; sin embargo estos son algunos de los requisitos que debes cumplir:

5 años a más de experiencia utilizando Python como lenguaje de programación principal, en un rol de data science o ingeniería de software. 
Fuerte mentalidad de producto y disfrutas trabajando en colaboración. 
Utilizas prácticas de ingeniería sólidas y escribes código mantenible. 
Te desempeñas bien en un entorno de ritmo rápido. 
Disfrutas dar mentoría a otros, e introduces y promueves las mejores prácticas en todo el equipo. 
Inglés (Lectura a nivel técnico - Avanzado)
Eres capaz de ser dueño de todo el ciclo de vida de un proyecto de machine learning. 
No necesitas ser un experto en cada aspecto, pero debes ser un aprendiz rápido para recoger las cosas y profundizar cuando sea necesario. 

Deseable/valorado:

Experiencia construyendo sistemas de recomendación que impulsan productos que deleitan a los clientes. Experiencia con aplicaciones intensivas en datos. 
Experiencia trabajando con Airflow, Apache Spark, MLflow, Metaflow y/o Kedro. 
Maestría o doctorado en Computación Aplicada, Machine Learning, Computer Science, Física, Matemática o un campo relacionado. ";['comunicación', 'trabajo en equipo', 'liderazgo', 'mentoría/enseñanza']
142;en;"Bring your people analytics, social science research and data mining/science skills to a unique team seeking to understand, and shape, the future of the digital workplace. We are interested in technology, of course, but we are also interested in the human mission of enabling the world's brightest and hardest working people to live where they want and work from anywhere. Most of our colleagues could move to a tech hub but they choose Canonical because of our mission and our approach to the workplace.

We'd like to understand what really makes a distributed, remote-first workplace work. We think we're pretty good at this (being remote first for almost 20 years), but we know there is a lot still to understand, and the frontier of possibility continues to move outward. We'd like to invest in research, analytics and tooling which raises the bar even further for remote collaboration and organisation.

If we are able to build tools that meaningfully improve our cooperation and our satisfaction, then we intend to share our insights with the world, both as a narrative and as SAAS or open source that helps other companies follow in our footsteps.

The role of a People Data Analyst at Canonical

Support analytics and data mining in a cross-disciplinary team of organisational psychologists, web front end engineers, back end engineers and statistics / analytics experts to help us build a new definition for the 21st century digital workplace. Collaborate to figure out what really drives productivity, effectiveness and happiness in a remote-first globally distributed company.

In addition to your existing people analytics work experience, this role will combine your skills in psychology, data analytics and visualisation, to help create a more effective workplace.

Location: This role will be based remotely in the AMER region.

All applicants applying must be legally authorized to work in the United States, as we cannot offer visa sponsorship for this job position.

What your day will look like

Utilize advanced data analytics to understand how we hire and how we work (productivity, happiness and effectiveness) across a global, remote first organisation
Focus on quantitative and qualitative data analytics to find insights and meaningful business outcomes
Tell the story from the insights through dashboards, visualizations and presentations
Design and conduct research into trends shaping talent science and remote work
Collaborate with stakeholder teams (ex., engineering, information systems, etc) to improve the data and tool ecosystem supporting our digital workplace

What we are looking for in you

Background in data science, mathematics, actuarial science, or engineering
First work experience in People Analytics is an asset
Knowledge in advanced statistics, data sciences, coding/scripting languages (Python, R, etc), and databases (SQL, etc)
Strength in data analytics and visualization (Looker Studio, Tableau, etc)
Ability to translate business questions to key research objectives
Ability to identify the best methodology to execute research, synthesize and analyse findings
Excellent writing and communication skills
Willingness to examine the status quo and resilient in the face of challenges

What we offer you

Your base pay will depend on various factors including your geographical location, level of experience, knowledge and skills. In addition to the benefits above, certain roles are also eligible for additional benefits and rewards including annual bonuses and sales incentives based on revenue or utilization. Our compensation philosophy is to ensure equity right across our global workforce.

In addition to a competitive base pay, we provide all team members with additional benefits, which reflect our values and ideals. Please note that additional benefits may apply depending on the work location and, for more information on these, you can ask in the later stages of the recruitment process.

🏠 Fully remote working environment - we've been working remotely since 2004!

📚 Personal learning and development budget of 2,000USD per annum

💰 Annual compensation review

🏆 Recognition rewards

🏝 Annual holiday leave

👶 Parental Leave

🧑‍💼 Employee Assistance Programme

🧳 Opportunity to travel to new locations to meet colleagues at 'sprints'

✈️ Priority Pass for travel and travel upgrades for long haul company events

About Canonical

Canonical is a pioneering tech firm that is at the forefront of the global move to open source. As the company that publishes Ubuntu, one of the most important open source projects and the platform for AI, IoT and the cloud, we are changing the world on a daily basis. We recruit on a global basis and set a very high standard for people joining the company. We expect excellence - in order to succeed, we need to be the best at what we do.

Canonical has been a remote-first company since its inception in 2004. Work at Canonical is a step into the future, and will challenge you to think differently, work smarter, learn new skills, and raise your game. Canonical provides a unique window into the world of 21st-century digital business.

Canonical is an equal opportunity employer

We are proud to foster a workplace free from discrimination. Diversity of experience, perspectives, and background create a better work environment and better products. Whatever your identity, we will give your application fair consideration.
";['communication', 'teamwork', 'problem solving', 'proactivity']
143;en;"Remote is solving global remote organizations’ biggest challenge: employing anyone anywhere compliantly. We make it possible for businesses big and small to employ a global team by handling global payroll, benefits, taxes, and compliance. Check out remote.com/how-it-works to learn more or if you’re interested in adding to the mission, scroll down to apply now.

Please take a look at remote.com/handbook to learn more about our culture and what it is like to work here. Not only do we encourage folks from all ethnic groups, genders, sexuality, age and abilities to apply, but we prioritize a sense of belonging. You can check out independent reviews by other candidates on Glassdoor or look up the results of our candidate surveys to see how others feel about working and interviewing here.

All of our positions are fully remote. You do not have to relocate to join us!

About Remote

Remote is solving global remote organizations’ biggest challenge: employing anyone anywhere compliantly. We make it possible for businesses big and small to employ a global team by handling global payroll, benefits, taxes, and compliance (learn more about how it works). We're backed by A+ investors and our team is world-class, literally and figuratively, as we're all scattered around the world.

Please check out our public handbook to learn more about our culture. We encourage folks from all ethnic groups, genders, sexuality, age and abilities to apply. You can also check out independent reviews by other candidates on Glassdoor. If this job description resonates with you, we want to hear from you!

All of our positions are fully remote. You do not have to relocate to join us!

How we work

We love working async and this means you get to do your own schedule.

We empower ownership and proactivity and when in doubt default to action instead of waiting.

The position

This is an exciting time to join Remote and make a personal difference in the global employment space as a Data Analyst, joining our Operations Data Analytics team. You will be the link between data producers and data consumers at Remote. You'll primarily focus on building out our data pipeline to unify our various data sources in a compliant manner. That being said, you should be committed to transforming data into readable insights, and help deliver goal-driven reports for continued innovation and growth.

Requirements

2-4 years work experience in statistics, data analytics, software engineering or a related field; ideally in a fast-paced environment.
Strong ability to collaborate and build effective relationships with your colleagues.
Excellent communication skills and ability to document processes for both business and technical audiences.
A self-starter mentality and the ability to thrive in an unstructured and fast-paced environment.
Strong experience in SQL and previous experience with dbt.
Strong experience with Metabase or other data visualisation tools.
Proficiency with Git.
It's not required to have experience working remotely, but considered as a plus.


Key responsibilities

Data Exploration & Quality: contribute to a culture of higher standards by discovering, documenting and working towards improving the quality of our data.
Data Modelling: collaborate with data engineers and other data analysts and contribute to building the modelling layer of our data warehouse.
Data Analysis: support Operational Analytics team by creating an ad hoc data reports and dashboards.
Collaboration: collect requests from stakeholders and translate them into meaningful data. Collaborate with data engineers and other data analysts to create high-quality reports.


Our current core data stack (among other tools) contains Metabase, Retool, dbt, Redshift, Meltano, Airflow and GitLab.

Remote Compensation Philosophy

Remote's Total Rewards philosophy is to ensure fair, unbiased compensation and fair equity pay along with competitive benefits in all locations in which we operate. We do not agree to or encourage cheap-labor practices and therefore we ensure to pay above in-location rates. We hope to inspire other companies to support global talent-hiring and bring local wealth to developing countries.

For U.S. applicants: Across all US locations, the base salary range for this full-time position is $28,660 - $60,000 plus eligibility for equity. Our salary ranges are determined by role, level and location, and our job titles may span more than one career level. The actual base pay for the successful candidate in this role is dependent upon many factors such as location, transferable or job-related skills, work experience, relevant training, business needs, and market demands. The base salary range is subject to change and may be modified in the future.

We offer a generous benefits package to all full-time employees. In the U.S. this includes: a 401(k) plan + 4% employer match, unlimited paid time off, paid sick leave in excess of local requirements, paid parental leave, FSA, HSA, health, dental and vision plans for you .Click here for more information on our global employee benefits.

Practicals

You'll report to: Manager, Data Analytics
Team: Operations Data Analytics, ****Data, Engineering
Location: Anywhere in the World
Start date: As soon as possible


Application process

(async) Profile review
Interview with recruiter
Interview with future manager
(async) Small challenge
(async) Challenge Review
Interview with team members (no managers present)
Prior employment verification check(s)
(async) Offer


Benefits

Our full benefits & perks are explained in our handbook at remote.com/r/benefits. As a global company, each country works differently, but some benefits/perks are for all Remoters:

work from anywhere
unlimited personal time off (minimum 4 weeks)
quarterly company-wide day off for self care
flexible working hours (we are async)
16 weeks paid parental leave
mental health support services
stock options
learning budget
home office budget & IT equipment
budget for local in-person social events or co-working spaces


How You’ll Plan Your Day (and Life)

We work async at Remote which means you can plan your schedule around your life (and not around meetings). Read more at remote.com/async.

You will be empowered to take ownership and be proactive. When in doubt you will default to action instead of waiting. Your life-work balance is important and you will be encouraged to put yourself and your family first, and fit work around your needs.

If that sounds like something you want, apply now!

How To Apply

Please fill out the form below and upload your CV with a PDF format.
We kindly ask you to submit your application and CV in English, as this is the standardised language we use here at Remote.
If you don’t have an up to date CV but you are still interested in talking to us, please feel free to add a copy of your LinkedIn profile instead.


We will ask you to voluntarily tell us your pronouns at interview stage, and you will have the option to answer our anonymous demographic questionnaire when you apply below. As an equal employment opportunity employer it’s important to us that our workforce reflects people of all backgrounds, identities, and experiences and this data will help us to stay accountable. We thank you for providing this data, if you chose to.";['communication', 'teamwork', 'problem solving', 'creativity', 'analytical skills', 'proactivity', 'fast-paced environment']
144;es;"En INVAP seguimos creciendo ¡y te estamos buscando para que nos acompañes!

Orgullosos y orgullosas de ser la empresa argentina referente en innovación en la industria aeroespacial y reconocida a nivel mundial en tecnología nuclear, nos motiva haber hecho realidad sueños que van desde la constelación de satélites más importante de Latinoamérica, pasando por la provisión llave en mano de instalaciones nucleares y centros de medicina nuclear, hasta la red de radares meteorológicos más importante del país. Pero más nos motiva encontrar que, a través del desarrollo de proyectos tecnológicos complejos, tenemos llegada y aportamos beneficios directos a las personas a nivel nacional e internacional.

Hoy nos encontramos en búsqueda de un/a Analista de Datos para sumar a nuestro equipo de Sistema de Información.

¿Cuáles serán sus principales desafíos?

Análisis y seguimiento de indicadores de gestión corporativos.
Generación de reportes para diferentes áreas de la compañía.
Armado y publicación de informes de distintos sectores de la empresa.
Desarrollar y mantener tableros de gestión integral y KPI’s para la toma de
decisiones.
Apoyar la mejora continua, automatizando procesos y utilizando herramientas de
visualización dinámicas.
Crear informes y visualizaciones claras y concisas para los stakeholders.
Contribuir en la estrategia de crecimiento y toma de decisiones basada en datos.
Armado de reportes y dashboard con Microstrategy.
Confeccionar y mantener tableros ejecutivos de información accionable.
¿Qué oportunidades te ofrecemos con este puesto?

Trabajar en una empresa referente en proyectos tecnológicos a nivel mundial y protagonista del desarrollo en Argentina.
Participación en equipos multidisciplinarios dinámicos, calificados y diversos.
Desenvolverse en entornos de innovación con posibilidades de crecimiento profesional.
¿Qué habilidades y actitudes buscamos en los perfiles para este puesto?

Una personalidad dinámica, metódica y proactividad. Capacidad de trabajo en equipo y de gestión de tareas.
Orientación a resultados.
Facilidad para las relaciones interpersonales y con criterio profesional. Capacidad de comunicación efectiva y manejo de la información.
Organizado/a y orientado/a al detalle. Capacidad analítica.
Flexibilidad y notable capacidad para aprender.
¿Qué conocimientos son requisito para desarrollar este rol?

Estudiantes/graduados/as en Sistemas o carreras afines.
Nivel de inglés intermedio.
Experiencia de 1 a 3 años ocupando posiciones de analista de datos.
Conocimiento de herramientas de visualización de datos, Microstrategy
(Excluyente).
Conocimiento en base de datos relacionales (Oracle, Postgrest, SQL Server) y NoSql (MongoDB)
Experiencia en armado de KPI’s y evaluación de indicadores de gestión.
Conocimientos avanzados de SQL.
Conocimiento de Python (Deseable).
Conocimientos Generales en BI (Business Intelligence)
Modalidad: Remota.";['comunicación', 'trabajo en equipo', 'creatividad', 'adaptabilidad', 'atención al detalle', 'proactividad']
145;es;"En Mercado Libre trabajamos para promover una cultura inclusiva, que busca la equidad y valora las diferentes perspectivas. Esto se traduce en género, religión, personas con discapacidad, LGBTQ+, raza, etnia y diversidad de experiencias. Trabajamos todas nuestras búsquedas con base en esta premisa. ¡Súmate a nuestro equipo!
Estamos democratizando el comercio, el dinero y los pagos en América Latina.
Nuestro negocio Fintech ofrece, a escala regional, una propuesta de valor integral que busca democratizar los servicios financieros y satisfacer las necesidades de las más de 60 millones de personas que utilizan nuestras soluciones.
Brindamos una plataforma online que permite cobrar ventas electrónicas realizadas tanto dentro como fuera de Mercado Libre, y un sistema de códigos QR y dispositivos Point para cobrar ventas realizadas en el mundo físico. Así, damos la posibilidad a millones de comerciantes, emprendimientos y profesionales de procesar de manera segura sus operaciones, a través de más de 50 medios de pago en América Latina.
También, otorgamos acceso gratuito a una cuenta digital, que permite pagar, enviar y recibir dinero, generar rendimientos y operar con tarjetas para hacer compras o extracciones.
A través de Mercado Crédito, ofrecemos créditos para satisfacer las necesidades de las personas que utilizan nuestros servicios y para ayudar a potenciar el negocio a quienes venden a través de nuestra plataforma.

Tenemos un desafío para quienes:

Vibran energía emprendedora: se mueven por la curiosidad, nunca se rinden y se enfocan en superar sus propios límites.
Dan el máximo porque les gusta trabajar con compromiso y dedicación.
Viven los cambios como oportunidades y aprenden de sus errores.
La excelencia y la ejecución son claves en su forma de hacer las cosas.
Promueven el buen clima, aportan alegría y diversión.
Saben cómo construir con otras personas y disfrutan trabajando en equipo.
Imaginate emprendiendo proyectos desafiantes, dinámicos e innovadores y siendo responsable de:

Colaborar en la definición, la construcción y el seguimiento de los diferentes KPIs del área, que contribuyan a la toma de decisiones.
Crear, desarrollar e implementar soluciones nuevas y escalables para problemáticas de negocio relacionadas a fintech.
Trabajar en conjunto con los diferentes equipos técnicos, para asegurar la calidad, el correcto registro y la disponibilidad de los datos.
Obtener, procesar y analizar grandes volúmenes de datos provenientes de diversas fuentes y extraer insights de interés.
Desarrollar procesos de ETL y modelos de datos.

Requisitos:

Contar con experiencia de trabajo con grandes volúmenes de datos, preferentemente con indicadores financieros y riesgo crediticio.
Tener experiencia en crear soluciones de datos, punta a punta; análisis, desarrollo e implementación.
Contar con conocimientos avanzados en SQL y habilidad de programación en Python, es deseable.
Tener experiencia en metodologías ágiles, es deseable.

Te proponemos:

Ser parte de una compañía con espíritu emprendedor en la que nos encanta pensar en grande y a largo plazo.
Ser protagonista de tu desarrollo en un ambiente de oportunidades, aprendizaje, crecimiento, expansión y proyectos desafiantes.
Compartir y aprender en equipo junto a grandes profesionales y especialistas.
Un excelente clima de trabajo, con todo lo necesario para que vivas una gran experiencia. :)";['trabajo en equipo', 'creatividad', 'habilidades analíticas']
146;en;"Junior Data Analyst (REPS)
LATAM
Description
About Team International

We're a global IT consulting company and a software development service provider that helps organizations operate at their best. With 30+ years of experience, +6 Global locations, and +1000 employees, TEAM combines technology expertise, valuable insights, business intelligence, and a client-centered approach to address challenges in business operations, digital transformation, risk management, compliance, business continuity, and more.

TEAM provides you with flexible engagement models, top IT talent, and full compliance.

Your business and specific project needs are unique and require a customized approach to IT and software development outsourcing.

Partner with TEAM to design the ideal engagement model to fit your business and technical needs, and quickly find the talent required to build your innovative IT solution in record time – all while ensuring full security and regulatory compliance.



Our guiding values

Customer-Centric -“Win-win is our partnership strategy”

Trust & Transparency -“We say what we mean, do what we say, and do what is right.”

Flexible & Adaptable -“Solving challenges creatively”

Teamwork & Celebration –“Work hard and enjoy our victories together”

Social Responsibility -“We envision a better world and take action to make things happen”



Requirements
· 1 – 2+ years of experience.

· SQL skills: Experience extracting data across multiple sources, joining together, performing transformations, checking for quality, etc.

· PowerBI skills: Experience building production grade dashboards and collaborating with business leaders on design.

· English: B2 or more.

Benefits
Being a part of TEAM International gives you the chance to work on challenging projects with great professionals, international clients, and the latest technologies.



We have a great benefits package that includes:

· English lessons.

· Private Health Insurance.

· 20+ Paid time off.

· Education allowance, etc.";['teamwork', 'creativity']
147;en;"Become an Outcoder as a Machine Learning Engineer

We seek a Machine Learning (ML) Engineer to help us create artificial intelligence products.

Machine Learning Engineer responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming. We want to meet you if you know data science and software engineering.

Your ultimate goal will be to shape and build efficient self-learning applications.

What you’ll need to be successful: 

Study and transform data science prototypes
Design machine learning systems
Research and implement appropriate ML algorithms and tools
Develop machine learning applications according to requirements
Select appropriate datasets and data representation methods
Run machine learning tests and experiments
Perform statistical analysis and fine-tuning using test results
Train and retrain systems when necessary
Extend existing ML libraries and frameworks
Keep abreast of developments in the field


About us:  EX² Outcoding is a premier solution provider of a broad range of outsourcing services, combining proven expertise in technology and project execution for companies searching for high-quality software development solutions. We specialize in delivering the best technical solution and enhancing that solution creatively by working closely with stakeholders to understand the business context.";['proactivity']
148;en;"Factored was conceived in Palo Alto, California by Andrew Ng and a team of highly experienced AI researchers, educators, and engineers to help address the significant shortage of qualified AI & Machine-Learning engineers globally. We know that exceptional technical aptitude, intelligence, communication skills, and passion are equally distributed around the world, and we are very committed to testing, vetting, and nurturing the most talented engineers for our program and on behalf of our clients.

We are seeking a skilled and experienced Data Engineer proficient in Flink, Kubernetes, AWS, and Scala to join our dynamic team. As a Data Engineer, you will play a crucial role in designing, developing, and maintaining our data infrastructure and pipelines. Your expertise in Hadoop MapReduce and Scala will be essential in building scalable and efficient data solutions that enable data-driven decision-making across the organization.

What you will be doing:

Create and maintain optimal data pipeline architecture across multiple data sources, including licensed and scraped data.
Design and develop optimal data processing techniques: automating manual processes, data delivery, data validation and data augmentation.
Design, develop, and optimize data pipelines and ETL processes using Flink, Kubernetes, AWS, and Scala.
Manage analytics tools that provide actionable insights into usage, customer acquisition, operational efficiency and other key business performance metrics.
Design and develop a API integrations in order to feed different data models.
Architect and implement new features from scratch, partnering with AI/ML engineers to identify data sources, gaps and dependencies.
Identify bugs and performance issues across the stack, including performance monitoring and testing tools to ensure data integrity and quality user experience.
Build a highly scalable infrastructure using SQL and AWS big data technologies.
Keep data secure and compliant with international data handling rules.

What you must bring:

7+ years of professional experience shipping high-quality, production-ready code.
Strong computer science foundations, including data structures & algorithms, OS, computer networks, databases, algorithms, and object-oriented programming.
Experience in data pipelines, Flink, Kubernetes, AWS, and Scala.
Experience setting up data pipelines using relational SQL and NoSQL databases, including Postgres, Cassandra, or MongoDB.
Experience with cloud services for handling data infrastructure such as: Databricks, Snowflake, GCP, Azure, or AWS.
Proven success manipulating, processing and extracting value from large heterogeneous datasets.
Strong analytic skills related to working with unstructured datasets.
Expertise with version control systems, such as Git.
Excellent verbal and written communication skills in English.

Nice to have:

BSc in Computer Science, Mathematics or similar field; Master’s or PhD degree is a plus.
Experience with design of ETLs using Apache Airflow.
Experience with real-time scenarios, low-latency systems and data intensive environments is a plus.

At Factored, we believe that passionate, smart people expect honesty and transparency, as well as the freedom to do the best work of their lives while learning and growing as much as possible. Great people enjoy working with other passionate, smart people, so we believe in hiring right, and are very selective about who joins our team. Once we hire you, we will invest in you and support your career and professional growth in many meaningful ways. We hire people who are supremely intelligent and talented, but we recognize that intelligence is not enough. Perhaps more importantly, we look for those who are also passionate about our mission and are honest, diligent, collaborative, kind to others, and fun to be around. Life is too short to work with people who don’t inspire you.

We are a transparent workplace, where EVERYBODY has a voice in building OUR company, and where learning and growth is available to everyone based on their merits, not just on stamps on their resume. As impressive as some of the stamps on our resumes are, we recognize that human talent and passion exist everywhere, and come from many backgrounds, so stamps matter much less than results. All of us are dedicated doers and are highly energetic, focusing vehemently on execution because we know that the best learning happens by doing. We recognize that we are creating OUR COMPANY TOGETHER, which is not only a high-performing fast-growing business, but is changing the way the world perceives the quality of technical talent in Latin America. We are fueled by the great positive impact we are making in the places where we do business, and are committed to accelerating careers and investing in hundreds (and hopefully thousands) of highly talented data science engineers and data analysts.

In short, our business is about people, so we hire the best people and invest as much as possible in making them fall in love with their work, their learning, and their mission. When not nerding out on data science, we love to make music together, play sports, play games, dance salsa, cook delicious food, brew the best coffee, throw the best parties, and generally have a great time with each other.";['communication', 'problem solving', 'proactivity']
149;en;"Overview

We're looking for a Data Engineer. Headquartered in Los Angeles, California, Right Balance applies the latest technology and best engineering practices to help businesses grow. We’re in the top 50 companies to watch in LA.

Engagement Details

We're a digital platform for total well-being. We help our community feel their best in body and mind through on-demand yoga, meditation, Pilates, and fitness classes with world-class teachers. Data Engineer plays an important role in our mission and vision to connect people through self-care so that, together, we can heal ourselves and our planet. Support the company's data strategy and work with the Data Team implementing data pipelines, dashboards, models, and AI/ML projects as needed. This role will be responsible for enabling data-driven decisions across the company by sourcing accurate data, building scalable infrastructure, and delivering analytics with predictive modeling. Use various methods to transform raw data into useful data systems, ultimately supporting the team to implement methods to improve data reliability, quality, and relevance.

What’s in it for you

Learn and evolve your skills using the latest and greatest technology tools in a rapidly growing company.
Learn from the best engineers. We constantly challenge the status quo and invent new ways of building a great product.
Flexible hours. Just join daily standups, sprint planning, and retrospective meetings. Other than that, you’re in control of your own schedule.
100% remote. Work anywhere, whether it is remotely in the comfort of your home, in a shared co-working space, in an RV on the beach, or while being a nomad in another country.
Work on challenging problems, innovate, impacting lots of people's lives for the better while having fun doing it.


Required Qualifications

Upper-intermediate to fluent speaking and writing English. Able to have a real-time conversation.
6+ years of full-time hands-on Data Engineering experience.
4+ years of full-time hands-on SQL experience.
4+ years of full-time hands-on Python experience.
Experience designing, developing, and maintaining Extract, Transform, Load (ETL) pipelines, ensuring data quality and integrity throughout the ETL process.
Experience managing and maintaining data warehouse performance to meet organizational requirements.
Deep understanding of conversion, retention, and engagement metrics.
Experience with data visualization tools such as Tableau, MixPanel, Google Looker.
Knowledge of data engineering and data warehousing concepts, including RedShift, Redshift Spectrum, AWS Glue, AWS Lambda.
Excellent communication and presentation skills to convey technical concepts to non-technical stakeholders.
Ability to work collaboratively in cross-functional teams and lead projects from ideation to implementation.
Experience mentoring junior data engineers and guiding best practices in modeling and analysis.
Ability to communicate clearly, and proactively with the team.
Able to respect and support cultural policies, values and processes.
Always strives to support colleagues through positive collaboration.
Ability to treat each team member with respect.
Receptive to change and open to feedback.


Nice to haves

PySpark experience.
Experience in user subscription data.
Bachelor's or Master's degree in Computer Science, Statistics, Mathematics, or a related field.
Experience in Data Science, Machine Learning, and Statistical Modeling
SAS experience.
Knowledge and experience in utilizing advanced table formatting such as Delta, Hudi, or Iceberg.
Experience building ML Models for new Product Features & Fraud.
Experience with Open Source Data Visualization tools.
Experience with Databricks, Reverse ETL.
Bachelor’s degree in Computer Science or equivalent demonstrated ability.


Frequently Asked Questions

What are your typical clients?

The majority of our clients are venture-backed startups in the growth stage. Usually, at this stage, the company already achieved a product-market fit and is looking to expand rapidly. That’s where we bring the best engineering practices, strong architecture, and the latest technologies to help companies scale.

What’s your company size?

The Right Balance team is 60+ engineers going to 100 by the end of the year. The current client size team is 340+ people. The timing is great to be a part of a rapidly growing team making meaningful contributions.

What happens if the engagement is completed?

Most of our engagements are long-term in nature. That said, if the current engagement is ramping down, we’ll present you with more long-term opportunities to transition into.

What are your core values?

Client First: we only win when our clients win. We treat client challenges as our own.

Ownership: we embrace responsibility, taking on challenges, getting them to completion, and enjoying getting things done.

Quality: we’re passionate about achieving quality outcomes by applying meticulous attention to detail.
";['communication', 'teamwork', 'problem solving', 'creativity', 'attention to detail', 'leadership', 'proactivity', 'mentoring/teaching']
150;en;"We are currently seeking a Senior AI / ML engineer with Python expertise, whose skills will be fundamental in building intelligent products that are not only reactive but proactive in fulfilling user needs. In this role, you will spearhead initiatives to harness machine learning to strengthen risk management frameworks and enhance customer experiences.

As part of this role, You’ll establish strong relationships with data scientists and ML Engineers around the world in a scalable way, by crafting great resources to help them build, including open source demos, MVP, code samples, documentation, and how-to guides. You’ll foster developer communities, championing their interests and translating their feedback into actionable product insights.

Requirements

The Ideal Candidate should understand the needs of the applications/product developments and client challenges and how integrating AI capabilities can help lead to solutions
Should manage and develop coding tasks and R&D (research and development) to meet the needs of our AI strategy
Must work with cross-functional teams in identifying and prioritizing key areas of a partner’s business where AI solutions can drive significant business benefits
Analyze and implement AI and machine learning (ML) coding solutions while setting and maintaining high ethical standards
Work on functional design, process design (including scenario design and flow mapping), prototyping, testing, training, and defining support procedures, in collaboration with an advanced engineering team and executive leadership
Articulate and document the development tasks,solutions architecture tasks and lessons learned for each exploration and accelerated incubation
Must manage development team tasks in conducting assessments of the AI and automation market and competitor landscape
Should serve as the liaison between stakeholders and project teams, delivering feedback and enabling team members to make necessary changes in product future developments tasks
Up to date with the latest advancements in AI and ML technologies
Must have the zeal to experiment with new algorithms and techniques to enhance the capabilities of our AI/ML systems

Qualifications

The Ideal candidate should have 8+ years of experience in applying AI to practical and comprehensive technology development solutions
Must be an expert in the development of ML, deep learning, TensorFlow, Python, and NLP
Need hands-on for 3+ years of experience with Python, Streamlit, and FastAPI
Should have skills like program leadership, governance, and change enablement
Must have hands-on experience in ChatGPT, and LLMs
Required knowledge of basic algorithms, object-oriented and functional design principles, and best-practice patterns
Must have hands-on experience using Flask, OOPs concepts, GIT, and basic Unix and Knowledge of reporting tools like Power BI
Experience with cloud computing platforms (e.g., AWS, Azure, Google Cloud Platform) for model deployment
Should be experienced with LLMs, Gen AI, Langchain, transformers
Hands-on experience with vector databases (Milvus, FAISS, Pinecone, Vespa, etc.,)
Must have experience in REST API development, NoSQL database design, and RDBMS design and optimizations

Benefits

We are a collaborative, supportive, and diverse bunch of people, who enjoy working together and treat each other with the utmost respect. Here everyone has the opportunity to share their experience, learn, and grow. Here are some of the perks we offer:

Get your salary in USD,
Choose your contract: Contract or B2B,
Long-term engagement,
Unlimited working-from-anywhere policy,
PTO,
Referral Bonuses,
Certifications & access to e-learning platforms,
Professional development budget,
Working on international projects,
Virtual Knowledge Sharing Sessions, Events and team hangouts

Our values

We are a company that seeks the best for both our employees and clients, reaching beyond expectations in turning dreams into reality. Our way of working is rooted in our core values (Integrity, Excellence, Proactivity, Innovation, and People), with an expectation that our future colleagues will make these their second nature in their everyday work and life. We don’t ask for perfection, but we do appreciate people motivated to better themselves in every conceivable aspect.

About IT Labs

Founded in 2005, IT Labs is an international software tech company, specializing in purpose and process-driven teams for high-performance, innovation, transformation, and efficiency. Our HQ is in Palm Beach Gardens, Florida, and we have teams and offices around the world - the UK, the Netherlands, Belarus, Serbia, and North Macedonia. We are constantly growing, and we would love for you to become part of our team!";['communication', 'teamwork', 'creativity', 'leadership', 'proactivity']
151;es;"Data Scientist (LATAM)
Descripción del puesto
Si sos un apasionado por el análisis de datos y por transformar ideas en soluciones, te invitamos a formar parte de nuestra compañía con visibilidad internacional y un excelente ambiente laboral!


Buscamos a una persona proactiva, con gran capacidad analítica, que se enfrente a problemas de marketing y decida la mejor forma de atacarlos. El profesional deberá ser capaz de implementar y trabajar con librerías de Python para Data Science y crear prototipos que luego sean llevados a producción.


Responsabilidades:

Gestionar las relaciones con los clientes para hacerlos parte del equipo, comprendiendo sus necesidades para traducirlas en soluciones analíticas.
Desarrollo de la solución al proyecto punta a punta en Python, con un ojo puesto en la estandarización del código para poder atacar problemas diversos.
Diseño del camino hacia el MVP: definición de plazos, tareas y entregables para cada proyecto del que la persona sea dueña.
Implementación de prototipos de cara interna a la compañía que estarán en el roadmap de producto.
Requisitos
Experiencia programando en Python con las siguientes librerías (pandas, numpy, seaborn/matplotlib, scikit-learn, pytorch/tensorflow, nltk).
Experiencia con desarrollo de código en Github.
Capacidad para bajar conceptos complejos a tierra con ejemplos sencillos.
Se valorará:

2-4 años de experiencia laboral en problemas de Machine Learning y Data Science.
Graduados de las carreras de Matemática, Física, Estadística, Ciencias Económicas o carreras afines.
Conocimientos de industria de marketing.
Experiencia atacando problemas de optimización o en reconocimiento de imágenes.
Curiosidad intelectual y alta capacidad analítica.

Beneficios:

Valoramos tu tiempo fuera del trabajo, flexibilidad full para trabajar desde donde quieras, lo importante es que cumplas las metas de cada proyecto en el que participes

Tu cumpleaños es especial para nosotros, nuestro regalo es que te tomes el dÍa libre para que lo disfrutes como quieras.

Capacitaciones constantes para que puedas continuar creciendo profesionalmente con estudios complementarios.

Somos un equipo multicultural, conformado por personas de 12 nacionalidades diferentes.

";['adaptabilidad', 'habilidades analíticas', 'proactividad']
152;en;"We’re looking for a Data Engineer. Headquartered in Los Angeles, California, the company applies the latest technology and best engineering practices to help businesses grow. We’re in the top 50 companies to watch in LA.
We’re a digital platform for total well-being. We help our community feel their best in body and mind through on-demand yoga, meditation, Pilates, and fitness classes with world-class teachers. Data Engineer plays an important role in our mission and vision to connect people through self care so that, together, we can heal ourselves and our planet.
Support the company’s data strategy and work with the Data Team implementing data pipelines, dashboards, models, and AI/ML projects as needed. This role will be responsible for enabling data-driven decisions across the company by sourcing accurate data, building scalable infrastructure, and delivering analytics with predictive modeling. Use various methods to transform raw data into useful data systems, ultimately supporting the team to implement methods to improve data reliability, quality, and relevance.

What’s in it for you?
Learn and evolve your skills using the latest and greatest technology tools in a rapidly growing company.
Learn from the best engineers. We constantly challenge the status quo and invent new ways of building a great product.
Flexible hours. Just join daily standups, sprint planning, and retrospective meetings. Other than that, you’re in control of your own schedule.
100% remote. Work anywhere, whether it is remotely in the comfort of your home, in a shared co-working space, in an RV on the beach, or while being a nomad in another country.
Work on challenging problems, innovate, impacting lots of people’s lives for the better while having fun doing it.
Required qualifications:
Upper-intermediate to fluent speaking and writing English. Able to have a real-time conversation.
5+ years of full-time hands-on Data Engineering experience.
4+ years of full-time hands-on SQL experience.
4+ years of full-time hands-on Python experience.
Experience designing, developing, and maintaining Extract, Transform, Load (ETL) pipelines, ensuring data quality and integrity throughout the ETL process.
Experience managing and maintaining data warehouse performance to meet organizational requirements.
Deep understanding of conversion, retention, and engagement metrics.
Experience with data visualization tools such as Tableau, MixPanel, Google Looker.
Knowledge of data engineering and data warehousing concepts, including RedShift, Redshift Spectrum, AWS Glue, AWS Lambda.
Excellent communication and presentation skills to convey technical concepts to non-technical stakeholders.
Ability to work collaboratively in cross-functional teams and lead projects from ideation to implementation.
Experience mentoring junior data engineers and guiding best practices in modeling and analysis.
Ability to communicate clearly, and proactively with the team.
Always strives to support colleagues through positive collaboration.
Nice to have:
PySpark experience.
Experience in user subscription data.
Bachelor’s or Master’s degree in Computer Science, Statistics, Mathematics, or a related field.
Experience in Data Science, Machine Learning, and Statistical Modeling.
SAS experience.
Knowledge and experience in utilizing advanced table formatting such as Delta, Hudi, or Iceberg.
Experience building ML Models for new Product Features & Fraud.
Experience with Open Source Data Visualization tools.
Experience with Databricks, Reverse ETL.
Bachelor’s degree in Computer Science or equivalent demonstrated ability.";['communication', 'teamwork', 'problem solving', 'creativity', 'leadership', 'mentoring/teaching']
153;en;"Our client is a subscription-based VOD platform global leader for language learning. The web-based software provides users with television shows and movies combined with interactive language-learning tools.


Is the Netflix of language learning, serving a vast and thriving community of language enthusiasts. They're passionately committed to transforming language learning into an enjoyable, accessible, and highly successful endeavor for everyone.
Their platform offers a curated catalog of real foreign TV shows, movies from around the world. from various providers, including Netflix.


We are actively seeking a highly skilled ML/AI/NLP developer to join our team and drive the development of consumer-oriented features. We're looking for someone who possesses strong technical and analytical skills and has a knack for devising innovative and efficient solutions to address product challenges. In this role, the ideal candidate will not only collaborate with stakeholders to gain insights into the product and its objectives but will also independently conduct research on existing ML/AI/NLP solutions. Their primary responsibility will be to identify opportunities for product improvement by leveraging the latest advancements in ML/AI/NLP technologies that could benefit our company.


Once these opportunities are identified, the candidate will autonomously craft solutions and work closely with other developers and product managers to implement and deploy these improvements to end-users. Additionally, they will continuously monitor and optimize the feature's performance based on data collected from users. We are seeking a proactive team player who is eager to take the lead in advancing our ML/AI/NLP initiatives and is committed to staying up-to-date with the latest developments in the field to bring valuable enhancements to our products.


Responsibilities:



In the capacity of the ML/AI/NLP Developer at our organization, you will hold a pivotal position in integrating ML/AI/NLP technologies into our products to enhance the customer experience and drive retention. Your key duties will encompass:


Take a leadership role in advancing our ML/AI/NLP initiatives by proactively seeking opportunities to continuously analyze the existing product, identifying areas where the implementation of ML/AI/NLP features can enhance the customer experience.
Conduct ongoing research on existing ML/AI/NLP solutions and emerging technologies, identifying technologies that the company can leverage for innovation.
Independently conceive and propose creative ML/AI/NLP-based solutions to enhance the customer journey and drive product improvements. 
Collaborate closely with cross-functional teams, including developers, designers, content managers, and product managers, to implement, monitor, optimize, and deploy ML/AI/NLP-driven solutions effectively for maximum customer benefit and enhanced retention through data-driven insights.
Evaluate and integrate third-party ML/AI/NLP tools and services to complement our in-house capabilities, expanding the potential for enhancing the customer experience.


This is a full remote position. This position requiered to start at 6am or 7am Argentinian Time.




Requisites

3+ Years of hands-on experience in developing and deploying Machine Learning / Artifitial Intelligence / NLP models for real-world applications, including knowledge of data preprocessing, feature engineering, and model evaluation techniques.
Demonstrated success in independently identifying opportunities for Machine Learning / Artifitial Intelligence / NLP enhancements, conducting research, and delivering tangible improvements to products or services.
Proficiency in programming languages and familiarity with ML libraries like TensorFlow, PyTorch, or scikit-learn
Experience with cloud platforms like AWS, Azure, or Google Cloud for deploying and scaling Machine Learning / Artifitial Intelligence / NLP enhancements models is a plus.
Excellent English communication skills (upper-intermediate).
Strong analytical and data-driven mindset, with a passion for improving customer experiences.
A keen interest in staying updated with the latest advancements in Machine Learning / Artifitial Intelligence / NLP enhancements technologies and their applications.


Benefits



- 100% remote position
- Salary in USD
- Computer is provided by the company";['communication', 'teamwork', 'problem solving', 'creativity', 'leadership', 'proactivity']
154;en;"🔥At Acsys we are looking a AI Engineer for a multicultural IT team.🔥


Company Description
Acsys is an innovative Argentine technology company founded in 2005 with offices in Argentina, Uruguay, Mexico, and the United States. Acsys integrates technologies to solve daily challenges in companies and provides development, consulting, and project implementation in technology infrastructure to create value for their clients.


Responsabilities:
Develop and implement GPT models to generate human-like text for chatbots, question-answering systems, and other natural language processing applications.
Optimize the GPT models for accuracy, performance, and speed, using various algorithms such as deep learning, natural language processing, and unsupervised learning.
Work closely with data scientists to design and implement the data pipeline required for GPT model development.
Use data analysis to evaluate the performance of GPT models and proactively identify areas for improvement.
Stay up-to-date with the latest research and advancements in GPT models and propose new solutions to improve the product.
Develop unit and automated tests to ensure the models are performing as expected.
Work with product managers to ensure that GPT models align with the overall product strategy, and that all requirements are defined and satisfied.


Qualifications
At least 3 years of experience with artificial intelligence and machine learning, with specific experience in developing GPT models.
Expertise in programming languages such as Python, C++, and R, as well as machine learning frameworks like PyTorch, TensorFlow or Keras.
Strong knowledge of natural language processing techniques and algorithms such as transformers, attention mechanisms, and language modeling.
Experience working with large datasets and distributed systems.
Familiarity with software engineering practices and principles, including Agile development methodologies and version control.
Excellent communication skills with team members at different levels with different technical backgrounds.
Ability to work in a fast-paced, highly collaborative environment and manage multiple projects simultaneously.
English: upper/advanced";['communication', 'creativity', 'analytical skills', 'project management', 'proactivity']
155;es;"En Scanntech nos encontramos en búsqueda de desarrolladores con conocimientos en estadística para integrarse a nuestro equipo de Data Science. 



Requisitos excluyentes:

 • Estudiante avanzado o egresado de la carrera de Ingeniería en Computación, Licenciatura en Estadística o equivalente. 

 • Experiencia programando en Python.
 • Machine Learning. 

 • Conocimientos en estadística. 

 • Conocimientos en SQL.
 • Experiencia en manipulación de grandes volúmenes de datos.


Requisitos deseables:

 • Conocimientos de pandas y/o polars.
 • Experiencia en tecnologías como Hadoop y Spark. 



Nuestros beneficios:

Excelente Clima Organizacional: estamos entre las mejores GPTW, entre las mejores para trabajar para Millennials y entre las mejores para trabajar para Mujeres.
Oportunidades de crecimiento y desarrollo.
Remuneraciones compatibles con el mercado.
Capacitaciones internas (Universidad Scanntech).
Capacitación en idiomas (inglés y portugués) 100% gratis para colaboradores y dentro del horario laboral.
Momentos de comunicación de estrategia (reuniones Total Compañía, entre otros).
Diversas actividades de integración, after offices, fiesta de fin de año, entre otros.
Integración de equipos de trabajo con personas de diversos países.
Opción 100% remota.
Flexibilidad de horarios.
Part of day para cumpleaños.";['comunicación', 'adaptabilidad']
156;en;"BA Global Talent is seeking a talented Data Scientist with expertise in the pharmaceutical and medical domain to join our dynamic team. As a Data Scientist, you will play a crucial role in leveraging Azure AI technologies, crafting robust architectures, optimizing ETL processes, and developing APIs for seamless integration. Your responsibilities will extend to shaping effective data models, implementing metadata creation and filtering strategies, and enhancing search functionalities.

You would be joining a fantastic group of people who not only demonstrate their belief in BA and its mission but also deliver fantastic results. If you are a self-starter and can thrive in a fast-paced environment, then this is the role for you! Apply now for an opportunity to start or further your career with a young, fast-growing company that values its front line.

Responsibilities:

Utilize Azure AI technologies to extract valuable insights from complex data sets.
Design and implement efficient ETL processes to ensure data accuracy and integrity.
Develop and maintain robust data models to support business requirements.
Architect data solutions aligned with organizational objectives.
Create and integrate APIs for effective data communication and interoperability.
Implement metadata strategies to enhance data discoverability and filtering.
Collaborate with cross-functional teams to address data-related challenges and opportunities.


Requirements:

Proven experience in data science with a focus on pharmaceutical or medical domains.
Proficiency in Azure AI technologies and tooling.
Strong background in architecting data solutions and ETL processes.
Experience in developing APIs and integrating data across diverse systems.
In-depth knowledge of metadata creation, filtering, and search strategies.
Excellent problem-solving skills and ability to work in a collaborative environment.
";['communication', 'teamwork', 'fast-paced environment']
157;es;"Buscamos Analista de Datos (DA) para la industria de medicina prepaga.

Entre sus tareas esperamos que realice:

Recolección de Datos: Recopilar datos de diversas fuentes, como bases de datos, archivos, APIs, data warehouse o data lakes.
Limpieza y Preparación de Datos: Procesar y limpiar los datos para eliminar errores o inconsistencias y prepararlos para el análisis.
Análisis Exploratorio de Datos: Realizar un análisis inicial para entender las características y patrones en los datos, utilizando estadísticas descriptivas y visualizaciones. Aplicar reglas de negocio para la interpretación de estos datos y la detección de los patrones.
Modelado y Análisis Estadístico: Aplicar técnicas estadísticas y de modelado para interpretar los datos y extraer insights. Creación de modelos predictivos (en conjunto con el Ingeniero ML) y pruebas de hipótesis.
Visualización de Datos: Crear representaciones gráficas de los datos, como gráficos, tableros de control (dashboards) y mapas, para comunicar los hallazgos de manera clara y efectiva (estos reportes sirven de soporte para la operatoria diaria y la toma de decisiones basadas en datos)
Reporte y Presentación de Hallazgos: Elaborar reportes y presentaciones para compartir los resultados del análisis con stakeholders, explicando las conclusiones y recomendando acciones basadas en los datos.
Trabajo Colaborativo con Otros Equipos: Colaborar con otros departamentos o equipos, para entender sus necesidades de datos y proporcionarles insights relevantes (apalancado en objetivos corporativos).
Aprendizaje Continuo: Mantenerse actualizado con las últimas herramientas, técnicas y arquitecturas que se implementen en la compañía.
Si estas interesado en conocer más informacion y participar de la propuesta, postulate!";['comunicación', 'trabajo en equipo', 'habilidades analíticas']
158;en;"Who we are?

Clip is changing the way payments work in Mexico! We are empowering people to exchange value directly from a mobile device. Clip enables anyone to accept card payments, at any time, and anywhere by turning your smartphone or tablet into a card terminal. We're a well-funded quickly growing FinTech startup. We are the leaders in our market and are accelerating to extend our lead and move into new markets.

The Role:

We are looking for a Data Engineer to be part of this amazing and fast – growing fintech and will be part of the team responsible for all of the data in the company used to support and implement Clip's mission. This Data Engineer work will be focused closely with product managers within the Product & Technology department as well as other leaders throughout the company to turn data into critical information and knowledge, he/she needs to be a creative thinker with a strong desire to learn and improve. A successful Data Engineer at Clip would propose innovative ways to look at problems by using data manipulation and engineering techniques, while proving that their projects bring value to the company, and they will directly impact business and product decisions for the future of Clip. This candidate must have strong written and verbal communications skills in both English and Spanish and be willing to continue learning and loving technology.

What will I do?

Work as part of a team developing in Python using Agile development methods.
Contribute to team and organizational improvements in process and infrastructure.
Work in the Data team and with the Architecture and DevOps teams to design and build efficient and fault tolerant data pipelines.
Create and populate data lakes and a data warehouse to facilitate data analysis and data science projects. 
Effectively use tools and ingenuity to identify and fix defects before they become a problem.
Invent new things and create world-changing software

Ideal Candidate:

Skills and experience in using Spark and Databricks.
Proficient in Python.
Proficient in OO methodologies, Agile development, design patterns, unit testing, and other software engineering principles and processes. 
Experience with AWS tools such as Redshift, Athena, Lambda, and Kinesis is a plus.
Experience with developing data pipelines, data lakes, and data warehousing solutions.";['creativity', 'attention to detail', 'analytical skills', 'project management']
159;en;"RYZ is looking for a Data Analyst who will be responsible for analyzing product performance, optimizing user engagement, and identifying insightful trends. You will partner effectively with Product and Engineering stakeholders and use a statistical hypothesis-driven approach to testing and optimization, and assist with the launch of new product features by analyzing the results of A/B tests (where applicable) and sharing insights & recommendations to launch new features. You will work with leaders, peers, and stakeholders to identify process improvement opportunities, system modification proposals and create data governance strategies. Also, your responsibilities will include measuring engagement with features in order to produce insights and drive future product decisions, as well as building dashboards/reports and monitoring/analyzing various Product KPIs and metrics.

Basic Qualifications:

 4+ years of experience in an analytics role at a public company or high-growth start-up - previous experience in product analytics/product management is preferred but not required
 Advanced skills in SQL with the ability to write complex and optimized queries
 Proficiency in Tableau or other data visualization tools
 Experience with Experiment design and Test analysis
 Experience in Python and/or R is a big plus
 Ability to prioritize and respond to analytics requests in a fast-paced environment
 Intellectually curious, results-oriented individual with the ability to identify dependencies, and leverage multiple sources of information at once


About RYZ Labs:

RYZ Labs is a startup studio built in 2021 by three lifelong entrepreneurs. The founders of RYZ have worked at some of the world's largest tech companies and some of the most iconic consumer brands. They have lived and worked in Argentina for many years and have decades of experience in Latam. What brought them together is the passion for the early phases of company creation and the idea of attracting the brightest talents in order to build industry-defining companies in a post-pandemic world.

Our teams are remote and distributed throughout the US and Latam. They use the latest cutting edge technologies in cloud computing to create applications that are scalable and resilient. We aim to provide diverse product solutions for different industries, planning to build a large number of startups in the upcoming years.

At RYZ, you will find yourself working with autonomy and efficiency, owning every step of your development. We provide an environment of opportunities, learning, growth, expansion and challenging projects. You will deepen your experience while sharing and learning from a team of great professionals and specialists.

Our values and what to expect:

 Customer First Mentality - every decision we make should be made through the lens of the customer
 Bias for Action - urgency is critical, expect that the timeline to get something done is accelerated
 Ownership - step up if you see an opportunity to help, even if not your core responsibility. Humility and Respect - be willing to learn, be vulnerable, and treat everyone that interacts with RYZ with respect
 Frugality - being frugal and cost conscious helps us do more with less
 Deliver Impact - get things done in the most efficient way
 Raise our Standards - always be looking to improve our processes, our team, our expectations. Status quo is not good enough and never should be";['problem solving', 'fast-paced environment']
160;en;"The OpenShift Sales Specialist for AI (AI SSP) assumes a pivotal role in providing expert sales support for the seamless execution of Go-To-Market (GTM) strategies related to Red Hat OpenShift AI (RHOAI) within a designated Geographic territory. This role involves leveraging AI strategically to help our customers make the most of their unique data, giving them a competitive edge. It includes tasks like training, building, and managing AI models to achieve significant business outcomes. The successful candidate must possess a unique blend of domain expertise, adept relationship management, and technical prowess to effectively bolster sales initiatives.

The ideal candidate will boast a track record of leadership in steering successful AI initiatives within enterprise settings, whether through direct sales, ownership as a product lead/technical expert, or engagement in consulting projects. Demonstrating the ability to usher these initiatives into production while showcasing tangible business value and outcomes is paramount. This remote role assumes GEO-level ownership, encompassing both business and technical responsibilities.

What You Will Do

Consult on and enable successful execution of RHOAI GTM
Be the virtual leader for in GEO RHOAI sales tactics 
Educate customers and stakeholders alike on the value of Red Hat’s RHOAI solution
Lead and enable on hyper-competitive sales situations for RHOAI
Be a geo-level bi-directional conduit of GTM for RHOAI between sales, P&GE, marketing, enablement, customer success, and SRE/CEE
Work closely with AI business unit and engineering teams by providing feedback and identifying gaps in the offering
Build lasting relationships with cloud providers, ISVs, and other 3rd parties for joint GTM
Interface with regional sales leadership for account planning and GTM

What You Will Bring

Subject matter expertise and experience in AI applications (e.g., deep learning, LLM, NLP, computer vision, or pattern recognition).
Experience in statistical programming language (e.g., Python), applied machine learning techniques, and using OSS frameworks (e.g., TensorFlow, PyTorch).
Experience with CI/CD solutions in the context of MLOps and LLMOps including automation with Infrastructure as Code (IaC) solutions (e.g. Ansible).
Experience delivering technical presentations and leading business value sessions.
Experience in AI systems design, with the ability to architect and explain data pipelines, ML pipelines, and ML training and serving approaches.
Executive presence with public speaking skills
Expert Practitioner of the Challenger Sales Model
Entrepreneurial mindset

Preferred Qualifications

Computer Science or other technical degree w/ MBA
Previous experience as a sales engineer, technical sales, or similar role (preferably Technical and/or Sales role experience working directly for hyperscalers or in partner ecosystem)
5+ years of Data Science/AI application development experience, including leadership roles 
2+ years of consulting experience with major SI
Product management or ownership role
Extensive community brand in circles such as AI User Group or other AI Communities
Ability to facilitate demonstrations of Red Hat AI solutions and products and cloud services unassisted
Industry vertical experience with Data Science projects. IE - expertise in FSI, medical, defense, and intelligence verticals
Recognized thought leadership in AI/MLOps
";['communication', 'leadership']
161;en;"Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, IgniteTech. Have you got what it takes?

Are you a C# and .NET whiz with an interest in using cutting-edge technology like generative AI tools? Do you thrive on the challenge of enhancing product performance and customer satisfaction? We have an exciting opportunity for you to join our team!

IgniteTech is not just another workplace; it's a hub of innovation and growth. As a Software Support Specialist, you will play a pivotal role in driving the success of Everest, our ERP business management solution, by leveraging advanced technologies such as ChatGPT. You'll be at the forefront of shaping the market impact of our products and directly influencing customer satisfaction. IgniteTech offers a unique and dynamic environment where your skills will be put to the test, and your contributions will make a lasting impact.

This role isn't just about support; it's a unique blend of maintaining and upgrading Everest software, addressing customer issues with precision, implementing customer-driven features, and optimizing databases using SQL Server. It's an opportunity to take the lead enhancing task efficiency and product quality. This role sets itself apart by providing an advanced technology engagement for impactful solo product support.

As a Software Support Specialist, you'll be a key player in ensuring the efficiency and effectiveness of Everest, working independently to solve challenging software problems. Your proficiency in C#, .NET, JSON, and SQL Server will be crucial in maintaining software excellence. The role uniquely integrates GenAI, setting you on a path to directly impact the success of our flagship product. If you're excited by the prospect of making a difference in a dynamic environment, we encourage you to apply and be a part of our innovative team.

IgniteTech is where your expertise meets innovation. Apply now to ignite your career!

What You Will Be Doing

Regularly updating and optimizing Everest software to ensure peak performance and user satisfaction
Promptly resolving any problems or queries that Everest users encounter, maintaining high standards of customer service
Continuously adding and refining features in Everest based on customer feedback and market trends
Employing GenAI tools to increase the efficiency and effectiveness of tasks, including maintenance, feature implementation, and customer issue resolution

What You Won’t Be Doing

Monotonous tasks; this role offers dynamic challenges and diverse problem-solving opportunities
Getting lost in bureaucracy; instead, you'll have the autonomy to make important business decisions

Artificial Intelligence Engineer Key Responsibilities

Making sure our 50+ customers love Everest, our ERP business management solution

Basic Requirements

At least 5 years of professional experience working with C# in a software development or support role
At least 5 years of experience utilizing the .NET framework
Experience with GenAI technologies (e.g., ChatGPT, Bard, Claude, etc.)
At least 3 years of experience with SQL Server database management

About IgniteTech

If you want to work hard at a company where you can grow and be a part of a dynamic team, join IgniteTech!

Through our portfolio of leading enterprise software solutions, we ignite business performance for thousands of customers globally. We’re doing it in an entirely remote workplace that is focused on building teams of top talent and operating in a model that provides challenging opportunities and personal flexibility.

A career with IgniteTech is challenging and fast-paced. We are always looking for energetic and enthusiastic employees to join our world-class team.

We offer opportunities for personal contribution and promote career development. IgniteTech is an Affirmative Action, Equal Opportunity Employer that values the strength that diversity brings to the workplace.

There is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!

Working with Crossover

This is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $30 USD/hour, which equates to $60,000 USD/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com/help-and-faqs for more details on this topic.

What to expect next:

You will receive an email with a link to start your self-paced, online job application.
Our hiring platform will guide you through a series of online “screening” assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.

Important! If you do not receive an email from us:

First, emails may take up to 15 minutes to send, refresh and check again.
Second, check your spam and junk folders for an email from Crossover.com, mark as “Not Spam” since you will receive other emails as well.
Third, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.
If all else fails, just reset your password by visiting https://www.crossover.com/auth/password-recovery if you already applied using LinkedIn EasyApply.

Crossover Job Code: LJ-5194-AR-BuenosAi-ArtificialInte";['creativity', 'adaptability', 'customer service']
162;en;"Do you possess an undoubtedly tech-savvy personality? Do you feel comfortable in a fast-paced, results-driven environment? Are you seeking an opportunity to demonstrate your strong analytical and problem-solving skills? Our client is a unique company that acquires entire teams of talent and IT assets from global organizations, MSPs, and data center operators. They need you ASAP! Apply today.
BetterPros unlocks human potential by offering competitive compensation, flexibility, constant learning and growth, and the opportunity to work anywhere you want with one of our +130 active clients across the United States.


What you’ll do: 
Develop and deploy
Create cutting-edge machine learning models to address diverse business applications.
Deploy machine learning solutions that make a real impact on our products and services.
Collaborate:
Work closely with data scientists to preprocess and clean large datasets for analysis.
Collaborate with cross-functional teams to integrate machine learning models into production systems seamlessly.
Optimize:
Implement and optimize machine learning algorithms to ensure performance and scalability.
Fine-tune models for enhanced accuracy and efficiency.
Innovation:
Stay at the forefront of advancements in machine learning and artificial intelligence.
Explore new technologies and methodologies to enhance our machine learning capabilities.


What you must have:
Overall:
Proven experience in developing and deploying machine learning models.
Excellent problem-solving and analytical skills.
Effective communication skills to collaborate with cross-functional teams.
Programming Skills:
Strong proficiency in programming languages such as Python, R, or Java.
Ability to write clean, efficient, and well-documented code.
C++.
Frameworks:
Hands-on experience with popular machine learning frameworks, including TensorFlow, PyTorch, and scikit-learn.
Strong understanding of Jupyter Notebooks.
Understanding of Kearas.
Data Expertise:
Knowledge of data preprocessing, feature engineering, and model evaluation techniques.
Familiarity with best practices in handling large and complex datasets.
Ability to input data into unsupervised and supervised data sets for data training.
Cloud and Distributed Computing:
Strong understanding of Microsoft Azure (Dev Ops)
Understanding of cloud platforms (e.g., AWS, Azure, Google Cloud) and distributed computing concepts.
Experience leveraging cloud resources for machine learning tasks.
";['communication', 'teamwork', 'problem solving', 'creativity', 'adaptability', 'proactivity']
163;en;"Hiring Python Developers to work on AI projects with our renowned client in the U.S. (no prior AI experience needed)

As a Python developer, you'll be vital in code review, feedback, and collaborating with researchers to make the innovative vision a reality.

What You'll Do:

Develop Python scripts for complex challenges.
Discuss project progress with the research team.
Create clear Jupyter Notebook documentation.
Fix software glitches and document your solutions.

Role Requirements:

Holding a bachelor's or master's in Engineering/Computer Science or equivalent experience.
3+ years in data science; 2+ years in data analysis.
Skilled in Python with at least 2 years of use.
A strong background in Data Science/Analysis.
Fluent in English, both spoken and written.
Familiarity with SQL and databases.

Perks of joining us:

Team up with world-class experts and innovators from all over the map, and expand your network as far as your aspirations go.
This is the ultimate opportunity for freedom-seekers who prefer to work remotely from any location they like.
Get a great compensation in US dollars, aligning with a worldwide earning standard.
Engage in groundbreaking ventures that challenge and advance the tech frontier, ensuring you’re always leading at front

Apply today and leave your mark on how we connect with devices. Raise your career prospects by finishing the tests and MCQs fast, increasing your chance of matching with the forward-thinking projects. """;['communication', 'creativity', 'analytical skills', 'proactivity']
164;en;"About The Position

Mid Data Engineer

Are you a skilled Data Engineer with a passion for creating compelling digital experiences? Join our prestigious content brand at the forefront of delivering engaging stories to a global audience. We are seeking a Mid Data Engineer with 2 to 5 years of experience in Python, Apache Airflow, and SQL to contribute to our dynamic team.

About Us:

We are dedicated to creating digital experiences that captivate and inform audiences worldwide. Our network of digital properties spans various content verticals and global territories, ensuring that our stories resonate across devices and cultures. We are laser-focused on achieving excellence in revenue, reach, and building lasting relationships with our readers.

Requirements:

2 to 5 years of experience in data engineering
Proficiency in Python
Experience with Apache Airflow and SQL
Ability to build, troubleshoot, and maintain pipelines

Responsibilities:

Build robust data pipelines to support our content delivery and analysis
Troubleshoot pipeline issues efficiently to ensure continuous data flow
Maintain and optimize existing pipelines for improved performance

Soft Skills:

Attention to Detail: Demonstrate precision and accuracy in your work to ensure data integrity. 
Great Attitude: Approach challenges with enthusiasm, contributing positively to the team environment. 
Initiative: Take the lead in identifying and solving problems, demonstrating a proactive approach to your work. ";['attention to detail', 'proactivity']
165;en;"Senior Machine Learning Engineer
IT Labs is a cutting-edge technology company specializing in delivering innovative solutions to clients across various industries. As a prominent player in the technology landscape, we are at the forefront of driving digital transformation. Our team at IT Labs is passionate about pushing the boundaries of what's possible with technology!

For one of our clients who is a leader in digital and biometric identification, we are looking for a Senior Machine Learning Engineer.

As a Senior Machine Learning Engineer, you will be responsible for owning and driving the foundational work of ML systems, designing, building, and deploying ML models for various applications such as document and image processing, as well as fraud detection. Your role will involve developing and implementing robust data pipelines at different scales, covering collection, pre-processing, transformation, and feature engineering. Additionally, you will collaborate with product teams and other stakeholders to uncover requirements, drive innovation, and solve complex problems. With a strong sense of ownership, you will be accountable for making architectural decisions and continuously striving for improvement in technology and processes.

Requirements

6+ years of experience in constructing, managing, and expanding ML models tailored for consumer applications, with a specific focus on developing end-to-end systems
Proficient in Python for machine learning tasks, with a focus on effective model development
Extensive experience with Postgres, showcasing expertise in designing and optimizing databases for large-scale data in ML applications
Familiarity with Snowflake and AWS cloud for seamless integration into ML workflows, ensuring a comprehensive understanding of cloud-based ML infrastructure
Demonstrate a track record in designing, implementing, and scaling intricate data pipelines for ML models while proficiently assessing their performance
Showcase expertise in adhering to best practices concerning feature engineering, model development/deployment, and monitoring to ensure optimal outcomes
Proficiently communicate technical concepts to a diverse audience comprising both technical and non-technical stakeholders, fostering effective collaboration and understanding
Actively engage in collaborative efforts, offering guidance and mentorship to less experienced team members, thereby contributing to the team's overall growth

Soft skills:

Independent thinker
Strong analytical skills and detail oriented
Known to deliver on your promises
Fluent in spoken and written English as well as the local language of the job description

Our vetting process leads to admission to our database which qualifies you to be chosen and connected to some of our client! The steps are quite easy!

 30 min Video interview
 100 min Online Technical Test
 10-15 min Online soft skills test";['communication', 'teamwork', 'problem solving', 'creativity', 'attention to detail', 'leadership', 'proactivity', 'mentoring/teaching']
166;en;"BA Global Talent is seeking a talented Data Scientist with expertise in the pharmaceutical and medical domain to join our dynamic team. As a Data Scientist, you will play a crucial role in leveraging Azure AI technologies, crafting robust architectures, optimizing ETL processes, and developing APIs for seamless integration. Your responsibilities will extend to shaping effective data models, implementing metadata creation and filtering strategies, and enhancing search functionalities.



You would be joining a fantastic group of people who not only demonstrate their belief in&nbsp;BA and its mission but also deliver fantastic results. If you are a self-starter and can thrive in a fast-paced environment, then this is the role for you! Apply now for an opportunity to start or further your career with a young, fast-growing company that values its front line.



Responsibilities:


Utilize Azure AI technologies to extract valuable insights from complex data sets.
Design and implement efficient ETL processes to ensure data accuracy and integrity.
Develop and maintain robust data models to support business requirements.
Architect data solutions aligned with organizational objectives.
Create and integrate APIs for effective data communication and interoperability.
Implement metadata strategies to enhance data discoverability and filtering.
Collaborate with cross-functional teams to address data-related challenges and opportunities.
Requirements:


Proven experience in data science with a focus on pharmaceutical or medical domains.
Proficiency in Azure AI technologies and tooling.
Strong background in architecting data solutions and ETL processes.
Experience in developing APIs and integrating data across diverse systems.
In-depth knowledge of metadata creation, filtering, and search strategies.
Excellent problem-solving skills and ability to work in a collaborative environment.";['communication', 'teamwork', 'fast-paced environment']
167;en;"Do you possess an undoubtedly tech-savvy personality? Do you feel comfortable in a fast-paced, results-driven environment? Are you seeking an opportunity to demonstrate your strong analytical and problem-solving skills? Our client is a unique company that acquires entire teams of talent and IT assets from global organizations, MSPs, and datacenter operators. They need you ASAP! Apply today.


BetterPros unlocks human potential by offering competitive compensation, flexibility, constant learning and growth, and the opportunity to work anywhere you want with one of our +130 active clients across the United States.


What you’ll do: 



Design and Implement AI Solutions:

Create robust and scalable AI solutions tailored to address business challenges.
Develop innovative approaches to solve complex problems using artificial intelligence.
Develop and Deploy AI Models:

Build, train, and deploy AI models and algorithms in real-world applications.
Optimize and fine-tune models for performance and efficiency.
Collaborate with Cross-Functional Teams:

Work closely with cross-functional teams to seamlessly integrate AI solutions into existing systems.
Communicate effectively with stakeholders to understand requirements and deliver solutions that meet or exceed expectations.
Conduct Experiments and Tests:

Design and execute experiments to enhance the performance of AI models.
Continuously evaluate and refine algorithms based on experimental results.
Stay Updated on AI Advancements:

Keep abreast of the latest advancements in artificial intelligence and machine learning.
Proactively apply new techniques and methodologies to improve existing solutions.




What you must have:

Proficiency in Programming Languages:

Demonstrated proficiency in one or more programming languages such as Python, Java, or C++.
Ability to write clean, efficient, and maintainable code.
Experience with AI Frameworks and Libraries:

Hands-on experience with popular AI frameworks and libraries, such as TensorFlow, Keras, and OpenCV.
Familiarity with implementing and customizing pre-existing models.
Strong Understanding of Machine Learning:

In-depth knowledge of machine learning algorithms and techniques.
Ability to apply machine learning concepts to real-world problems.
Problem-Solving Skills and Creativity:

Strong problem-solving skills with a creative mindset to devise innovative AI solutions.
Ability to think critically and adapt solutions to evolving challenges.";['communication', 'teamwork', 'problem solving', 'creativity', 'adaptability']
168;en;"CHEP LATAM is seeking a Data Scientist to assist with continued development and implementation of data-driven optimization strategy for the region. The Data Scientist will work cross-functionally with teams across LATAM to develop automated advanced tools leveraging advanced data analytics techniques (algorithms to predict indicators evolution, diagnose issues and optimize current processes). The scientist will be working with large sets of structured and unstructured data (internal and external) to perform analysis, develop tools and provide actionable insights. Scope • LATAM. 



Degree in Computer Science, Statistics, Mathematics, Engineering, or related fields.
English 80% advanced level
At least 3 years of experience in a data science role.
Mandatory Knowledge in :
• Strong programming skills(Python, R)
• Knowledge of major data science topics, models, and methods (from logisitic regression to advanced neural networks)
• Strong knowledge in statistics, mathematics, and machine learning algorithms.
• Experience with machine learning frameworks such as TensorFlow or PyTorch.
• Knowledge in SQL and NoSQL databases.
• Experience with data visualization tools like Tableau or PowerBI.
• Familiarity with big data platforms like Hadoop, Spark.
• Experience using version control tools 

• Strong analytical and problem-solving skills.
• Ability to work in a fast-paced and collaborative environment.
• Excellent communication and presentation skills.


Key Accountabilities 

• Design and develop advanced machine learning models and predictive analytics. 

• Collaborate with business teams to understand their needs and translate them into data-driven solutions. 

• Manage and process large datasets for analysis. 

• Implement best practices in data management and manipulation. 

• Present analysis results to non-technical stakeholders. 

• Lead and mentor junior members of the data science team. 

• Stay up-to-date with emerging trends and technologies in data science and machine learning.
 • Monitoring the external environment, using this information to assess implications and strategic options for our business, and recommending appropriate competitive and commercial strategies.
 • Evaluate how to use data to extract key trends, predict key indicators and identify business opportunities/risks. 

• Ensure accuracy on predictions.
• Ensure solutions created are aligned with LATAM strategy.
• Ensure solutions are delivered on a timely manner.
• Internal customers satisfaction.
• Develop solutions in a scalable way, standard and automated.
• Develop processes to efficiently manage data.";['communication', 'teamwork', 'problem solving', 'mentoring/teaching']
169;en;"We are on the lookout for a Data Analyst with a specialization in marketing analytics. In this critical role, you will harness the power of tools like Google Data Studio, BigQuery, and Power BI to derive actionable insights that drive our marketing decisions. Your expertise in analyzing complex datasets and turning them into understandable and strategic information will be essential in shaping our marketing strategies. This position is ideal for someone who thrives on data-driven challenges and has a passion for leveraging technology to inform business decisions.

What You’ll Be Doing

Data Analysis and Interpretation: Utilize tools like Google Data Studio, BigQuery, and Power BI to analyze marketing data and extract meaningful insights. 
Developing Reporting Dashboards: Create dynamic dashboards and reports that provide real-time insights into marketing performance. 
Collaborating with Marketing Teams: Work closely with marketing teams to understand their data needs and provide insights that inform strategy and decision-making. 
Data Integration and Management: Integrate data from various sources to provide a comprehensive view of marketing performance. 
Performance Tracking: Monitor key performance indicators (KPIs) to measure the effectiveness of marketing campaigns and strategies. 
Predictive Analysis: Use data to predict trends and market movements, aiding in proactive strategy development. 
Training and Support: Provide training and support to team members in using data analysis tools and understanding reports. 

Who You Are

Proficient in Data Analysis Tools: You have strong experience with tools such as Google Data Studio, BigQuery, and Power BI. 
Analytical and Insightful: You possess the ability to analyze complex datasets and turn them into actionable insights. 
Collaborative in Nature: You work well with marketing teams, understanding their needs and communicating data insights effectively. 
Skilled in Data Integration: You are adept at integrating and managing data from various sources. 
Detail-Oriented: You have a keen eye for detail and accuracy in data analysis and reporting. 
Proactive and Predictive: You are capable of conducting predictive analyses to inform future marketing strategies. 
Excellent Communicator: You can clearly convey data insights and their implications to non-technical team members. 

What Success Looks Like

30 Days

Establish a comprehensive, organized online database in BigQuery to store all client and marketing data and integrate lead data from CRMs, digital advertising data, customer opt-ins, and purchasing data to provide meaningful insights that inform marketing decisions. 
Create and maintain data dashboards in Looker Studio for easy data visualization, analysis, and automated reporting. 

60 Days

Develop statistical models for data analysis, including linear regression modeling and predictive lead scoring, that effectively guide marketing actions. 

90 Days

Automated the generation of actionable insights and trends over time from data analysis to inform our marketing strategy.";['problem solving', 'attention to detail', 'analytical skills', 'proactivity']
170;en;"Job Title: Machine Learning Engineer - Image/Video Classification and Recommendation Systems


Responsibilities:
1. Develop and implement machine learning models for image and video classification, ensuring high accuracy and efficiency in handling large datasets.
2. Design and optimize recommendation systems to enhance user experience through personalized content suggestions.
3. Collaborate with cross-functional teams to understand business requirements and integrate machine learning solutions into existing systems.
4. Stay abreast of the latest advancements in machine learning and computer vision to continually improve algorithmic approaches.
5. Evaluate and preprocess data to ensure its suitability for training and testing machine learning models.
6. Conduct thorough testing and validation of models to ensure robust performance and scalability in production environments.
7. Work on feature engineering, model tuning, and optimization to improve overall system performance.
8. Collaborate with software developers to deploy and integrate machine learning solutions into production systems.
9. Provide technical expertise and support to team members, fostering a collaborative and innovative environment.
10. Stay informed about industry trends and emerging technologies in image and video processing.


Requirements:
1. Bachelor's/Master's/Ph.D. degree in Computer Science, Machine Learning, or a related field.
2. Proven experience in developing and deploying machine learning models, with a focus on image and video classification.
3. Strong programming skills in languages such as Python, and proficiency in machine learning frameworks like TensorFlow or PyTorch.
4. Experience with recommendation systems, including collaborative filtering, content-based filtering, or hybrid approaches.
5. Solid understanding of computer vision techniques and frameworks for image and video processing.
6. Knowledge of deep learning architectures and algorithms for feature extraction and representation.
7. Ability to work in a collaborative team environment and effectively communicate complex technical concepts to non-technical stakeholders.
8. Familiarity with cloud platforms such as AWS, Azure, or Google Cloud for deploying and managing machine learning models.
9. Strong problem-solving skills and a proactive attitude toward addressing challenges in machine learning projects.
10. Excellent analytical and critical-thinking abilities, with attention to detail in all aspects of machine learning development.";['communication', 'teamwork', 'problem solving', 'creativity', 'attention to detail', 'proactivity']
171;es;"Queremos ayudar a construir el futuro a través de la tecnología, aportando soluciones digitales que ayuden a cambiar diferentes sectores de nuestra sociedad. Somos el primer Exponencial Tech Hub basado en España, que trabaja día a día en cambiar como interactuaremos en el mañana.

En Aluxion, estamos buscando un profesional apasionado y altamente capacitado para unirse a nuestro equipo de desarrollo como Ingeniero de Inteligencia Artificial. Esta posición desempeñará un papel fundamental en el desarrollo de soluciones de inteligencia artificial y NLP para una nueva aplicación que estamos creando.

¿Qué estamos buscando?

Buscamos un desarrollador con experiencia en Inteligencia artificial Generativa para unirse a nuestro equipo de innovación. El candidato ideal tendrá conocimientos y habilidades en:

Programación en Python +3 años.
Frameworks de deep learning como TensorFlow, PyTorch o Keras
Modelos generativos como GANs, VAEs o Transformers
Experiencia en aplicaciones de IA generativa como generación de texto, imagen, audio o vídeo, ejemplo, OpenAI, Anthropic o Stable Diffusion
Excelentes fundamentos y conocimiento sobre: Funciones Async, Fastapi, Pydantic, python-env, multithread / threading, uvicorn, microservicios
Patrones de diseño y arquitectura
Conocimientos en Prompt Engineering
Metodologías ágiles de desarrollo de software

Ofrecemos:

Salario competitivo
Formación continua y oportunidades de crecimiento profesional
Proyectos retadores y punteros en el campo de la IA generativa
Ambiente de trabajo dinámico y colaborativo
100% remote job";['trabajo en equipo', 'creatividad', 'proactividad']
172;es;"En JSD estamos buscando un apasionado de los datos y la visualización para sumarse a nuestro equipo como Data Analyst/Visualizer. 

Si sos una persona creativa, con habilidades para trabajar con datos y una mente analítica, este puede ser el proyecto ideal para vos. 



En este rol, vas a ser responsable de crear reportes y paneles en Looker Studio utilizando la información que tenemos almacenada en BigQuery. Estamos buscando a alguien que maneje Looker Studio a la perfección y sea capaz de armar visualizaciones atractivas y personalizadas para comunicar nuestros insights de manera efectiva.


Las tareas principales incluyen:
Armar y mantener reportes y paneles en Looker Studio para análisis de datos.
Colaborar codo a codo con equipos internos para entender sus necesidades de datos y desarrollar soluciones de visualización.
Extraer, transformar y cargar datos desde BigQuery y otras fuentes para su análisis y presentación.
Desarrollar y mantener dashboards interactivos que ayuden a los equipos a tomar decisiones basadas en datos.
Identificar tendencias y patrones a través del análisis de datos y presentar los resultados de manera clara y concisa.


Requisitos clave:
EXCLUYENTE: Experiencia previa en análisis de datos y visualización 
EXCLUYENTE: Amplio conocimiento y experiencia en el uso de Looker Studio para la creación de informes y paneles personalizados.
EXCLUYENTE: Familiaridad con BigQuery y la capacidad de trabajar con datos a gran escala.
Habilidad para comunicar de manera efectiva ideas y resultados a través de visualizaciones y presentaciones.
Pasión por trabajar con datos y encontrar soluciones creativas.


Duración del proyecto: de 1 a 3 meses 



Para ser considerado en el proceso de selección, nos gustaría ver ejemplos de reportes y paneles que hayas creado y trabajado en Looker Studio en el pasado. Los podés enviar a juan@jsdagency.com y vamos a estar en contacto por email.";['comunicación', 'trabajo en equipo', 'creatividad', 'habilidades analíticas', 'proactividad']
173;en;"Teramind is a hybrid, global workforce building the next-generation Insider Risk Management and User Behavior Analytics platform.


Join our team of innovators who are redefining insider risk management through cutting-edge technology. More than 10,000 organizations across the globe have used' Teramind to mitigate insider threats and protect their sensitive company data with the most robust, enterprise-grade software on the market.


As a global team, Teramind embraces an inclusive and flexible work environment and team culture. We win together, learn from each other and respect each other while delivering best-in-class security solutions.


About the role

Teramind, a leader in space of security and user behavior research, is looking for someone to help reshape how insights are delivered and surfaced in our platform. Being at the forefront of Digital Loss Prevent, Insider Threat Detection, and Employee Monitoring, you’ll have access to the richest data in the space, giving you unique challenges and endless opportunities. 



Responsibilities

Design and develop advanced algorithms for object detection, identification, and tracking, leveraging state-of-the-art computer vision techniques
Assist in testing and validation process for Al functionalities in various controlled scenarios
Keep up-to-date with the latest developments in Al and related technological domains
Effectively communicate complex technical details to a diverse team
Work closely with product owners on a feature-focused team to deliver value quickly to Teramind customers


Qualifications

Hands on experience (7 years) in designing, building, and maintaining scalable data pipelines with a focus on ML Vision including OCR
Proficiency in image/video processing and computer vision tools such as PIL/Pillow, GraphicsMagick, FFmpeg, OpenCV, SimpleCV, etc
Experience with modern deep learning techniques in CV including convolutional networks, residual networks, attentional models, etc
Strong proficiency in programming languages such as Python, Java, Scala, C++, with hands-on experience in building distributed systems and streaming applications
Experience analyzing and evaluating state-of-the-art algorithms related to detection, from both academic and industrial research, and implementing and enhancing them in a production environment


Benefits

This is a remote job. Work from anywhere! We’re a global, distributed team looking for the finest talent. We’ve been thriving as a fully-remote team since 2014. To us, remote work means flexibility and having truly diverse, global teams.


At Teramind, we're a collaborative, forward-thinking team where new ideas come to life, experience is valued and talent is incubated.
Competitive salary with a focus on a global market
Career-growth opportunities
Flexible Time Off and Paid Time Off benefits
Ongoing training and development opportunities
";['communication', 'problem solving', 'adaptability', 'proactivity']
174;en;"Join Us at Quales Group!

Are you ready to embark on a transformative journey? At Quales Group, we're redefining how our clients make crucial decisions! 🚀

As a B Corp, we specialize in guiding our clients through the ever-evolving tech landscape while offering top-tier expertise in data strategies and solutions. But here's the twist – PEOPLE are at the core of everything we do, shaping our work culture into a challenging, fun, and incredibly inclusive space! 💪

🌟 Job Opportunity: Jr Data Engineer - ARG

What You'll Be Doing:

Creating and keeping up with the structure of data projects, making sure everything runs smoothly. 
Taking care of tasks like gathering data, analyzing it, and working on system development.
Building dashboards, reports, and apps for diving into the data.
Generating progress reports and project documentation


What You'll Bring:

Advanced student or graduated in Computer Engineering, Software Development, or related field.
Initial work experience in data projects and/or certifications related to SQL and Data Viz tools (Power BI, Tableau, etc)
Knowledge in data modeling, SQL language, design and development of ETL processes, and visualization tools.
Focused on continuous improvement.
Advanced English level.


What Awaits You:

Join a triple-impact company on the rise, bursting with dynamism.
Take center stage in your professional development journey.
Embrace diversity, respect, and inclusion - be your true self!
Collaborate with an incredible, team-oriented group - we love to learn and grow together!
Immerse yourself in challenging, fun, and inclusive work environments - it's all about that startup culture!


Benefits:

A reduced workweek 😉
Vacation days? Absolutely!
In-Company English lessons!!!
Competitive salaries
Travel and work: Go borderless for up to 1 year 🌎
Choose your workplace: Full remote or co-working";['communication', 'teamwork']
175;es;"Somos una empresa nativa digital que brinda productos y servicios a clientes del rubro financiero, seguros, salud y retail.
Dedicada a la provisión de soluciones tecnológicas con fuerte foco en la innovación, diseñamos e implementamos grandes sistemas para ayudar a las organizaciones a alcanzar su máximo potencial.
Estamos buscando un Data Engineer para sumarse a un proyecto con uno de nuestros clientes más grandes.
 
Tendrás la oportunidad de:

Trabajar con profesionales de amplio conocimiento técnico que te ayudarán a superarte día a día.
Ser parte de proyectos altamente desafiantes.
Trabajar con las últimas tecnologías y continuar capacitándote en ellas.
Desarrollar tu carrera tanto técnicamente como a nivel de industria.
Ser parte de una cultura ágil, digital y colaborativa que pregona la cultura de trabajo en equipo.


Tus responsabilidades serán:

Relevar, modelar y disponibilizar información a distintos mercados para poder mejorar la eficiencia del uso de los datos en la organización y fomentar la cultura Data Driven.
Identificar y resolver problemas para garantizar integridad de los datos.
Modelado y estructuración de flujos de datos y arquitecturas de información.


¿Qué buscamos?

Al menos 4 años de experiencia en roles de Ingeniero de Datos.
Experiencia utilizando Python.
Experiencia utilizando Spark sobre entornos Databricks.
Dominio de entornos cloud con GCP y AWS.
Dominio de Azure Data Factory.


Ofrecemos:

Proyección de crecimiento, seguimiento de plan de carrera. 
Días de home office (con posibilidad de esquema 100% remoto). 
Clases de Inglés in-company. 
Capacitaciones a través de plataformas de cursos y certificaciones de Microsoft.";['trabajo en equipo', 'creatividad', 'gestión de proyectos']
176;en;"Role: Machine Learning Lead 

Location: Remote

Duration : Long Term Contract



Resource Type: No CPT, OPT, F1, fresh graduates. 



This is with one of our top clients in the ML space.


· Lead experience is must
· Study and transform data science prototypes
· Design machine learning systems
· Research and implement appropriate ML algorithms and tools
· Develop machine learning applications according to requirements
· Select appropriate datasets and data representation methods
· Run machine learning tests and experiments
· Perform statistical analysis and fine-tuning using test results
· Train and retrain systems when necessary
· Extend existing ML libraries and frameworks
· Keep abreast of developments in the field
Must have experience with LLMs, Chains, advanced LLM methods like RAG, hallucination reduction, etc.
Must have MLOPS experience on the cloud. 



Experience:
5+ years of verifiable ML experience: Tensorflow, Keras, Pytorch, ScikitLearn, and more.";['proactivity']
177;en;"Join Loka and build with the latest tools and collaborate on projects you can be proud of.


Our Machine Learning teams launch for Silicon Valley startups and life-sciences giants alike.


All that, plus 100% remote work AND every other Friday off! 😎
 
Benefits:

Every other Friday off (26 extra days off a year)
LokaLabs™ incubator
Relocation program
Remote and flexible
Explore Program: 3 months abroad
Paid sick days and local holidays
Mental health benefits and more


The Role:

Understand business objectives and develop models that help achieve them, along with metrics to track their progress.
Design and implement complex ML systems using classical ML, DL and Foundation Models by following best practices.
Lead client communications gathering requirements, managing expectations, and communicating deliverables.
Wrangle, explore and visualize data with a careful eye for issues that require data cleaning as well as differences in data distribution that may affect performance when deploying the model in the real world.
Analyze the errors of the model and design strategies to overcome them
Deploy, maintain, and upgrade ML models and pipelines.


Main Requirements:

4+ years of machine learning engineering experience
Bachelor’s Degree in Computer Science or related
Experience with Python, machine learning libraries and AI/ML frameworks (PyTorch, HuggingFace, TensorFlow, Keras, Scikit-learn, Spark etc.)
Strong understanding of statistical, machine learning and deep learning algorithms. Candidates with NLP experience preferred.
Experience building GenAI solutions, namely prompt engineering (e.g: Langchain), fine-tuning and serving LLMs, search and embeddings, etc.
Experience with MLOps, favorably in AWS (e.g: Sagemaker) as well as standards tools (e.g: MLFlow)
Experience visualizing and manipulating big datasets
Ambition to learn and grow into different industries with a modern tech stack
Autonomy, adaptability and positivity (fully remote and globally distributed team)
Proficient in English
";['communication', 'teamwork', 'adaptability', 'proactivity']
178;en;"OfferFit was founded by ex-McKinsey and BCG math PhDs, and we’re funded by leading Silicon Valley VCs. OfferFit replaces A/B testing with automated experimentation, powered by self-learning AI. This allows lifecycle marketers to test & improve the performance of their campaigns much faster than before. Customers include leading brands like Brinks Home (leading home security company) and Engie (multinational electric utility), among many others.


Note for Applicants: 



Data shows that men on average apply for a role if they meet 6/10 requirements while women often only do so if it’s 10/10. We work hard to be clear and specific about what our roles require, and we encourage you to apply even if you don’t check all the boxes! Applying gives you the opportunity to be considered and we look forward to reviewing your application!


As we take on more customers and unique challenges, we are looking for a ML Implementation Engineering Technical Lead who can help scale our data science implementation function to the next level. Come join a team creative technical experts who collaborate with customers to ensure their success with OfferFit!


In particular, you will:



Take a hands on role in the implementation of reinforcement learning use cases on the OfferFit platform
Manage and mentor a team of Machine Learning Implementation Engineers
Manage and lead collaboration with Implementation and Customer Success teams (use case definition, data integration, pipeline and ML model configuration, etc.)
Work closely with the Head of Implementation and Head of Data Science to analyze and improve reinforcement learning algorithms
Participate in sessions with prospective customers as the product SME
Contribute to OfferFit’s product strategy and roadmap
Oversee the continuous support OfferFit provides customers to ensure their success
Be a thought leader and mentor for our team of data scientists and engineers


Technical Landscape:



OfferFit is creating a GUI based auto-ML platform and much of the implementation teams work involves configuring ML systems on this platform
Data Science/Back End: Python (Pandas, TF, Flask, Great Expectations), SQL (GBQ)
Architecture/DevOps: Airflow, GCP
Web (not required for this role): JavaScript (Vue, Node.js), HTML, CSS


Why is it great: 



No toy datasets in notebooks — we’re implementing AI pipelines in production at scale!



Be the face of the company, working alongside our customers to help them succeed.
Learn tons about data architecture, data science, and self-learning AI.
Work in a team that not only talks the talk of development best practices, but walks the walk — unit & integration tests, modular design, CI/CD, pair programming, code reviews — the works.
Join OfferFit’s fast-paced, supportive, and professional team. We make sure all of our team members are empowered and receive great mentorship and coaching.


Who’s a Fit: 



Scientific Problem Solver: You think deeply about the data in your ML problem and rigorously search for optimizations
Solid coder: you write clean, well documented code; you care about good design.
Tinkerer: you regularly explore and learn new technologies and methods
Entrepreneurial: you proactively identify opportunities and risks, work around obstacles, and always seek creative ways to improve processes and outcomes
Structured and organized: you can structure a plan, align stakeholders, and see it through to execution
Clear communicator: you are able to express yourself clearly and persuasively, both in writing and verbally


OfferFit Benefits and Perks:



Generous PTO (starting at 25 days PTO per year) and Parental Leave policy (12 weeks paid)
100% remote work environment with flexible hours 
Quarterly gatherings where we meet in person in a different city to work together, bond as a team and celebrate our progress
Weekly team events (lunch and learns, trivia, virtual escape rooms, town hall and team health “barometer” meetings)
Ability to learn and develop under an experienced leadership team (ex-Amazon, McKinsey, BCG, and IBM, among others) who are focused on building a talented, diverse, and inclusive team
Dedication to building a strong culture (e.g., team resource groups, weekly recognitions, major life event celebrations, mental health/sustainability days off, etc)
[US Only] Competitive benefits (major medical, vision, dental and LTD) and 401K matching program
";['communication', 'teamwork', 'creativity', 'leadership', 'proactivity', 'mentoring/teaching']
179;en;"A Data Scientist at Sophilabs delves into intricate data to unlock insights, trends, and predictive patterns. Utilizing their expertise with Microsoft SQL Server, they analyze vast amounts of data to influence decision-making and propel the business forward.

Responsibilities

Design and implement statistical or machine learning solutions tailored to business needs.
Utilize Microsoft SQL Server for efficient and effective data analysis.
Collaborate with organizational stakeholders to identify opportunities for leveraging company data to drive business solutions.
Mine and analyze data from company databases to optimize and improve product development, marketing techniques, and business strategies.
Coordinate with different functional teams to implement models and monitor outcomes.
Develop processes and tools to monitor and analyze model performance and data accuracy.
Pursue continuous learning about the latest industry trends, tools, and techniques in data science.
Engage in project conceptualizations and provide data-driven recommendations.

To explore more about this opportunity and discover other exciting roles, simply type 'Sophilabs Careers' in your favorite search engine. Dive into a world of possibilities with us!

Qualifications

At least 3 years of relevant Data Science experience.
Proficiency with Microsoft SQL Server
A robust analytical mindset with a knack for dissecting complex data structures.
Demonstrates thoroughness, a passion for problem-solving, and a commitment to excellence.

Preferred Qualifications:

Familiarity with data visualization tools such as Power BI, Tableau, or similar.
A foundation in algorithms, statistics, and machine learning.
Proven ability to drive business results with data-based insights.
Strong interpersonal and communication skills, with the ability to articulate complex data findings in a clear and concise manner.
Full-time and Remote availability.
Proficiency in English (C1 or +).

We Offer:

🚀 An opportunity to sculpt your career path with premium training, English assistance and courses, investment days, literature, conference support, coaching, and all-encompassing feedback.

🌱 Achieve a harmonious work-life balance with our adaptable remote working policy and an array of wellness benefits.

If you share our commitment to delivering excellent client-focused service and putting customers first, enjoy working in teams, and are always looking to improve, join us!";['communication', 'teamwork', 'problem solving', 'analytical skills', 'proactivity']
180;en;"Founded in 2005, tbo. is a global organization that provides translation, talent, training, teams and testing services to a full range of clients in over 40 countries worldwide, from startups to enterprise-level companies.


tbo. aims to facilitate global communication by bridging the gap between peoples and cultures, providing simple solutions to complex problems, and outstanding service in 100+ languages.


tbo. fosters a culture of continuous improvement, creativity, sustainability and community, with a longstanding commitment to providing high-touch human service.


Job Description



 The Machine Learning Engineer role is responsible for the design, development and implementation of machine learning solutions to serve our organization. This includes ownership or oversight of projects from conception to deployment with appropriate AWS services, Docker, MLFlow, and others. 

The role also includes responsibility for following best practices with which to optimize and measure the performance of our models and algorithms against business goals.


Responsibilities



Design and develop machine learning models and algorithms for various aspects of the localization and business workflow processes, including machine translation, LLM fine tuning, and quality assurance.
Take ownership of key projects from definition to deployment, ensuring that they meet technical requirements and maintain momentum and direction until delivery.
Evaluate and select appropriate machine-learning techniques and algorithms to solve specific problems.
Implement and optimize machine learning models and technologies using Python, TensorFlow, and other relevant tools and frameworks.
Perform statistical analysis and fine-tuning using test results.
Deploy machine learning models and algorithms using appropriate techniques and technologies, such as containerization using Docker and deployment to cloud infrastructure.
Use AWS technologies (including but not limited to Sagemaker, EC2, S3) to deploy and monitor production environments.
Keep abreast of developments in the field, with a dedication to learning in the role.
Document diligently and communicate thoughtfully about ML experimentation, design, and deployment.
Project scope: Define and design solutions to machine learning problems. Integration with larger systems done with guidance of more-senior.


Requirements

BSc in Computer Science, Mathematics or similar field.
Master’s degree is a plus.
3+ years experience as a Machine Learning Engineer or similar role.
Effective Model Development: success is evident when the models developed are accurate, efficient, and align with project requirements.
Positive Team Collaboration: demonstrated ability to collaborate effectively with various teams and stakeholders, contributing positively to project outcomes.
Continuous Learning and Improvement: a commitment to continuous learning and applying new techniques to improve existing models and processes.
Clear Communication: ability to articulate findings, challenges, and insights to a range of stakeholders, ensuring understanding and appropriateness.
Ability to write robust, production-grade code in Python.
Excellent communication and documentation skills.
Strong knowledge of machine learning techniques and algorithms, including supervised and unsupervised learning, deep learning, and reinforcement learning.
Hands-on, high proficiency experience with machine learning frameworks such as TensorFlow, PyTorch, and Scikit-learn.
Experience with natural language processing (NLP) techniques and tools.
Strong communication and collaboration skills, with the ability to explain complex technical concepts to non-technical stakeholders.
Experience taking ownership of projects from conception to deployment, and mentoring more junior team members.
Hands-on experience with AWS technologies including EC2, S3, and other deployment strategies. Experience with SNS, Sagemaker a plus.
Experience with ML management technologies and deployment techniques, such as AWS ML offerings, Docker, GPU deployments, etc.


Benefits



National public holidays.
Vacations: 3 weeks per year.
Work laptop provided.";['communication', 'teamwork', 'creativity', 'leadership', 'mentoring/teaching']
181;en;"As a trusted global transformation partner, Welocalize accelerates the global business journey by enabling brands and companies to reach, engage, and grow international audiences. Welocalize delivers multilingual content transformation services in translation, localization, and adaptation for over 250 languages with a growing network of over 400,000 in-country linguistic resources. Driving innovation in language services, Welocalize delivers high-quality training data transformation solutions for NLP-enabled machine learning by blending technology and human intelligence to collect, annotate, and evaluate all content types. Our team works across locations in North America, Europe, and Asia serving our global clients in the markets that matter to them. www.welocalize.com

To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.

The Machine Learning Engineer role is responsible for the design, development and implementation of machine learning solutions to serve our organization. This includes ownership or oversight of projects from conception to deployment with appropriate AWS services, Docker, MLFlow, and other. The role also includes responsibility for following best practices with which to optimize and measure the performance of our models and algorithms against business goals.

Tasks And Responsibilities

Design and develop machine learning models and algorithms for various aspects of the localization and business workflow processes, including machine translation, LLM fine tuning, and quality assurance.
Take ownership of key projects from definition to deployment, ensuring that they meet technical requirements and maintain momentum and direction until delivery.
Evaluate and select appropriate machine-learning techniques and algorithms to solve specific problems.
Implement and optimize machine learning models and technologies using Python, TensorFlow, and other relevant tools and frameworks.
Perform statistical analysis and fine-tuning using test results.
Deploy machine learning models and algorithms using appropriate techniques and technologies, such as containerization using Docker and deployment to cloud infrastructure.
Use AWS technologies (including but not limited to Sagemaker, EC2, S3) to deploy and monitor production environments.
Keep abreast of developments in the field, with a dedication to learning in the role.
Document diligently and communicate thoughtfully about ML experimentation, design, and deployment.
Project scope: Define and design solutions to machine learning problems. Integration with larger systems done with guidance of more-senior.

Success Indicators of a Machine Learning Engineer

Effective Model Development: success is evident when the models developed are accurate, efficient, and align with project requirements.
Positive Team Collaboration: demonstrated ability to collaborate effectively with various teams and stakeholders, contributing positively to project outcomes.
Continuous Learning and Improvement: a commitment to continuous learning and applying new techniques to improve existing models and processes.
Clear Communication: ability to articulate findings, challenges, and insights to a range of stakeholders, ensuring understanding and appropriate.

Skills And Knowledge

Ability to write robust, production-grade code in Python.
Excellent communication and documentation skills.
Strong knowledge of machine learning techniques and algorithms, including supervised and unsupervised learning, deep learning, and reinforcement learning.
Hands-on, high proficiency experience with machine learning frameworks such as TensorFlow, PyTorch, and Scikit-learn.
Experience with natural language processing (NLP) techniques and tools.
Strong communication and collaboration skills, with the ability to explain complex technical concepts to non-technical stakeholders.
Experience taking ownership of projects from conception to deployment, and mentoring more junior team members.
Hands-on experience with AWS technologies including EC2, S3, and other deployment strategies. Experience with SNS, Sagemaker a plus.
Experience with ML management technologies and deployment techniques, such as AWS ML offerings, Docker, GPU deployments, etc.

Education And Experience

BS in Computer Science, Mathematics or similar field.
Master’s Degree is a plus.
3+ years experience as a Machine Learning Engineer or similar role.";['communication', 'teamwork', 'creativity', 'leadership', 'mentoring/teaching']
182;en;"Development of modern tools for working with AI / ML on the GPU. Implementation of algorithms for working with graphic processors. Working with GPU neural network calculations. Work with the AI/ML development team and the open-source community to analyze, develop, test, and deploy performance improvements for neural networks on GPUs with AMD ROCm, working on enabling ROCm HIPSOLVER/cuSOLVER in PyTorch


Responsibilities:

Develop, support and optimize PyTorch project for GPU. Communication with developers, customers, and project managers. Create, document, and execute unit/component/functional tests. This might involve one or more of the following:
• Modifying PyTorch UT code to adapt it for ROCm
• Filing JIRAs on ROCm components that have missing features needed for the UTs


Mandatory Skills Description:

• Proficiency with PyTorch, С/C++ and Python
• Knowledge of GPU computing (HIP or CUDA or OpenCL)
• Experience in CMake, make/ninja build system, docker
• Software Version Control (Git)
• Knowledge in ML/NN
• GDB debugging


The successful candidate should possess the following traits:

• Proficiency in problem-solving and troubleshooting technical issues
• Time management, prioritization and multi-tasking skills
• Ability to handle multiple competing priorities in a fast-paced environment
• Personal initiative, commitment, perseverance and resilience
• Well-developed communication and teamwork skills
• Aspiration to engineering excellence


Nice-to-Have Skills:

• ROCm
• HIP
• Jenkins
• CUDA
• Pytorch internals


Languages:

English: C1 Advanced";['communication', 'interpersonal skills', 'teamwork', 'adaptability', 'fast-paced environment']
183;en;"Join phData, a dynamic and innovative leader in the modern data stack. We partner with major cloud data platforms like Snowflake, AWS, Azure, GCP, Fivetran, and dbt to deliver cutting-edge services and solutions. We're committed to helping global enterprises overcome their toughest data challenges. Even though we're growing extremely fast, we maintain a casual, exciting work environment. We hire top performers and allow you the autonomy to deliver results.


4x Snowflake Partner of the Year (2020, 2021, 2022, 2023) 
#1 Partner in Snowflake Advanced Certifications
600+ Expert Cloud Certifications (Fivetran, dbt, Sigma Award Winners)
7x Best Places to Work 
Inc 5000 Fastest Growing US Companies (2020-2023)


Machine Learning Engineers are the Swiss army knives of machine learning. They’re ready for anything, and they bring all the tools to ensure that data science models see the light of day. They own the infrastructure and deployment plan—from making sure data science models can actually be built using customer data to deploying them into a production environment, and everything in between. They provide thought leadership by recommending the right technologies and solutions for a given use case, from the application layer to infrastructure. Machine Learning Engineers have the team leadership and coding skills (e.g. Python, Java, and Scala) to get their solutions into production — and to help ensure performance, security, scalability, and robust data integration.


What you’ll do in this role:

Design and create environments for data scientists to build models and manipulate data
Work within customer systems to extract data and place it within an analytical environment
Learn and understand customer technology environments and systems
Define the deployment approach and infrastructure for models and be responsible for ensuring that businesses can use the models we develop
Reveal the true value of data by working with data scientists to manipulate and transform data into appropriate formats in order to deploy actionable machine learning models
Partner with data scientists to ensure solution deployability—at scale, in harmony with existing business systems and pipelines, and such that the solution can be maintained throughout its life cycle
Create operational testing strategies, validate and test the model in QA, and implementation, testing, and deployment
Ensure the quality of the delivered product


Required Experience:

At least 4 years experience as a Machine Learning Engineer, Software Engineer, or Data Engineer
4-year Bachelor's degree in Computer Engineering or a related field
Experience deploying data science models in a production setting.
Expertise in Python, Scala, Java, or another modern programming language
The ability to build and operate robust data pipelines using a variety of data sources, programming languages, and toolsets
Strong working knowledge of SQL and the ability to write, debug, and optimize distributed SQL queries
Experience working with Data Science/Machine Learning software and libraries such as h2o, TensorFlow, Keras, scikit-learn, etc. 
Experience with Docker, Kubernetes, or some other containerization technology
Familiarity with multiple data source systems (e.g. JMS, Kafka, RDBMS, DWH, MySQL, Oracle, SAP)
Systems-level knowledge in network/cloud architecture, operating systems (e.g., Linux), storage systems (e.g., AWS, Databricks, Cloudera)
Production experience in core data technologies (e.g. Spark, Pandas)
Development of APIs and web server applications (e.g. Flask, Django, Spring)
Complete software development lifecycle experience including design, documentation, ong analytical abilities; ability to translate business requirements and use cases into a solution, including ingestion of many data sources, ETL processing, data access, and consumption, as well as custom analytics
Excellent communication and presentation skills; previous experience working with internal or external customers


Preferred Experience 

A Master’s or other advanced degree in data science or a related field
Hands-on experience with one or more ecosystem technologies (e.g., HBase, Impala, Solr, Kudu, Streamsets, NiFi, ElasticSearch, Databricks, Snowflake, AWS/Azure/GCP)
Relevant side projects (e.g. contributions to an open source technology stack)
AWS Sagemaker, MLFlow experience
 

 Why phData? We offer:

Remote-First Work Environment 
Casual, award-winning small-business work environment
Collaborative culture that prizes autonomy, creativity, and transparency
Competitive comp, excellent benefits, generous PTO plan plus 10 Holidays (and other cool perks)
Accelerated learning and professional development through advanced training and certifications";['communication', 'problem solving', 'creativity', 'leadership']
184;en;"Responsibilities 
Develop reliable, reusable, automated, and streamlined ETL code. Analyze and organize raw data from multiple sources to produce requested or required data elements. 
Design table structures and ETL to build performant data solutions that are scalable in a fast-growing data ecosystem 
Develop procedures and measures to ensure the accuracy of data reconciliation. Integrate automatic audit, balancing, and controls. 
Building reports/dashboards in Power BI or Snowflake Build Data Catalog 
Assist with production, including being available and providing technical support to end-users and IT workers. 
Explore data and assist business partners with intricate data analysis and impromptu inquiries. 
Performed analysis, design, and implementation of application and technical architecture and confirmed that the BI product fulfilled the requirements. 
Collaborate with data management and database specialists to identify and document issues. 
Create new reporting applications to ensure that the underlying data source can meet reporting requirements. 
Adhere to all requirements for managing metadata and ensuring data quality by overseeing quality management reviews. 
Understand the relationships and interdependencies between data warehouse and business intelligence tools and architectures; address problems in this area based on this understanding. 
Proactively seek, establish, and cultivate ties with business process owners and colleagues. 
Identify changes in project scope or workload that could result in exceeding the budget or missing the delivery date and create and implement contingency measures. 


Qualifications 
Degree in Computer Science, IT, or a similar field; a master’s is a plus 
Expertise in DBT, SQL, and Python 
Preferred five or more years of experience with SQL, Data Modeling, and Dimensional Modeling 
Technical expertise in data models, data mining, and segmentation techniques 
Experience with Microsoft Dataverse, Datawarehouse, Data Factory, Synapse, PowerApps, Project Central 
Hands-on experience building large-scale data pipelines using tools such as Apache Airflow, Azure Data Factory, or other equivalent technology, 
Minimum two years experience with big data technologies such as Apache Spark (or Databricks), Hadoop, or equivalent technology 
Minimum two years experience implementing data solutions in the public cloud (Azure, AWS, or GCP) 
Hands-on experience with NoSQL technologies such as Cassandra, CouchDB, MongoDB 
Strong teamwork, analytical nature, self-motivation, and excellent written and oral communication skills. 
Ability to maintain own workflow and meet deadlines while managing parallel project deliverables with minimal direction 
Ability to create compelling visual models to enable collective understanding of processes, data flow, user interaction, and others as needed. 
Hands-on experience with data model design 
Excellent numerical and analytical skills";['communication', 'teamwork', 'problem solving', 'analytical skills', 'proactivity']
185;en;"EPAM is a leading global provider of digital platform engineering and development services. We are committed to having a positive impact on our customers, our employees, and our communities. We embrace a dynamic and inclusive culture. Here you will collaborate with multi-national teams, contribute to a myriad of innovative projects that deliver the most creative and cutting-edge solutions, and have an opportunity to continuously learn and grow. No matter where you are located, you will join a dedicated, creative, and diverse community that will help you discover your fullest potential.

We are looking for a Senior Machine Learning Engineer who can design and implement standardized processes and technology capabilities for building, deploying and operating ML systems rapidly and reliably. To provide leadership in defining and implementing strategies and tools, working with internal and external stakeholders.

Half of the time is dedicated to the hands-on analysis of data science initiatives, plans, and ML-powered products. In contrast, the other half is spent building data and modelling pipelines, tools, and applications to automate that process.

OUR VALUE, OUR PEOPLE

We aim to deliver truly transformative solutions around the world, with top-notch technologies, in high-performance professional teams. But none of these would be possible without our people, and that’s where you come in.

As an EPAMer you will always be expanding your knowledge, facing and addressing the biggest challenges, and becoming the best version of yourself, both personally and professionally. We care about your development, and to support your growth in the company, there are many career paths you can follow within our Engineering & Advanced Engineering tracks. Plus, you’ll be constantly working in multicultural teams with people from North America & Europe that will bring out the best of you.

Req.#306923195

#REF_HOU_CO

What You’ll Do

Own and contribute to ML pipeline design, development, and operating lifecycle based on best practices
Design, create, maintain, troubleshoot, and optimize ML pipeline steps
Own and contribute to the ML prediction endpoints design and Implementation
Cooperate with Data System Engineers to configure ML lifecycle management environment
Write specifications, documentation and user guides for developed applications
Materialize ML pipelines created by data scientists
Cooperate with data scientists on the design and implementation of predictive models
Collaborate with data scientists and engineering teams to optimize ML pipeline performance
Support improvement of coding practices and repository organization in the data science work cycle
Contribute to the exploration and understanding of new tools and techniques and propose improvements
Establish and configure CI/CD pipelines for Data projects
Define ML Engineering best practices within data science and product teams
Continuously identify technical risks and gaps, devise mitigation strategies
Identify and cover hidden technical debt in ML systems


What You Have 

Experience working as a ML Engineer
Experience working with one of the following MLOps related technologies:
AWS SageMaker
Azure ML
GCP Vertex AI/AI Platform

Experience working with one of the following technologies:
Databricks
MLFlow
Kubeflow
TensorFlow Extended (TFX)
Spark ML
Airflow
Argo Workflow

Expert level in Python, Java, or Scala
Strong sense of leadership and growth mindset
Fluent English (B1+)

 Nice to have

Experience with different types of databases: Relational, NoSQL, Graph, Document, Columnar, Time Series
Experience in CI/CD
Experience with IaC tools such as: Ansible or Terraform
Experience with Docker & Kubernetes
Experience with R Studio and R Language


Benefits

Learning Culture - We want you to be the best version of yourself, that is why we offer unlimited access to learning platforms, a wide range of internal courses, and all the knowledge you need to grow professionally
Health Coverage - Health and wellness are important, that is why we have you and up to four family members in a premiere health plan. We have a couple of options, so you can choose what is best for you and your family
Visual Benefit - Seeing your work for us would be a sight for sore eyes. We want your vision to always be at 100% which is why we offer up to $200.000 COP for any visual health expenses
Life Insurance Plan - We have partnered with MetLife to offer a full-coverage Ife insurance plan. So, your family is covered, even if you are gone
Medical Leave Coverage - We are one of the few companies that cover 100% of your medical leave, for up to 90 days. Your health is the most important thing to us
Professional Growth Opportunities - We have designed a highly competitive and complete development process, where you will have all the tools to get where you have always wanted to be, personally and professionally
Stock Option Purchase Plan - As an EPAMer you can be more than just an employee, you will also have the opportunity to purchase stock at a reduced price and become a part owner of our organization
Additional Income - Besides your regular salary, you will also have the chance to earn extra income by referring talent, being a technical interviewer, and many more ways
Community Benefit - You will be part of a worldwide community of over 50,000 employees, where you can learn, challenge yourself, stand out, and share your knowledge and experience with multicultural teams!
Are you open to relocation? - If you want to relocate to another country and we have the right project, we will assist you every step of the way, to help you and your family, reach your new home


We offer

We trust our people. We believe in team distribution and that you know what you are doing, which is why you will be able to work remotely and have a flexible schedule
We are both proud of working within a diverse and inclusive environment and acting in our role as an equal opportunities’ employer. You are welcome at EPAM for who you are.
You will be challenged while working side-by side with the best talent globally. We work with top-notch technologies, constantly seeking out new industry trends and best practices
We are a global design community eager to share knowledge, experiences, and mentoring. You will learn, contribute, and grow with us.
How does it sound to know you can have a 20+year career with us constantly growing and without the need to look elsewhere? We offer access to learning platforms, classes, and workshops to support your development. You will be set up for success with our clear career paths and support in helping you achieve the goals you set for yourself, both personal and professional
We seek improvement in a proactive manner. You have the freedom to make recommendations, suggestions or simply comment on things without the pressure of adhering to hierarchy or strict processes
We work with a broad range of clients: Media, Entertainment, Life Sciences, Automotive, Finance, Technology, and Travel. You will play a key role in growing their business and potentially work in multiple new industries";['communication', 'teamwork', 'creativity', 'leadership', 'proactivity', 'mentoring/teaching']
